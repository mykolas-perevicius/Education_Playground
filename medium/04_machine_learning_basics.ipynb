{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Machine Learning Basics\n",
    "\n",
    "Learn how to build real machine learning models using Python's scikit-learn library.\n",
    "\n",
    "## What You'll Learn\n",
    "- Introduction to scikit-learn\n",
    "- Supervised vs unsupervised learning\n",
    "- Building your first ML model\n",
    "- Model evaluation and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning\n",
    "\n",
    "- **Supervised Learning**: Learning from labeled examples (like a teacher showing correct answers)\n",
    "  - Classification: Categorizing things (spam vs not spam)\n",
    "  - Regression: Predicting numbers (house prices)\n",
    "\n",
    "- **Unsupervised Learning**: Finding patterns without labels\n",
    "  - Clustering: Grouping similar items\n",
    "  - Dimensionality reduction: Simplifying complex data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your First ML Model: Classification\n",
    "\n",
    "Let's build a model to classify flowers based on their measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need to install scikit-learn:\n",
    "# pip install scikit-learn\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the famous iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: measurements\n",
    "y = iris.target  # Labels: flower species\n",
    "\n",
    "print(\"Dataset info:\")\n",
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Species: {iris.target_names}\")\n",
    "print(f\"\\nFirst sample: {X[0]}\")\n",
    "print(f\"Its species: {iris.target_names[y[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Split data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "\n",
    "# Create and train the model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Now use the trained model to predict flower species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Show first 10 predictions vs actual\n",
    "print(\"Predictions vs Actual:\")\n",
    "for i in range(10):\n",
    "    pred_name = iris.target_names[predictions[i]]\n",
    "    actual_name = iris.target_names[y_test[i]]\n",
    "    match = \"✓\" if predictions[i] == y_test[i] else \"✗\"\n",
    "    print(f\"{match} Predicted: {pred_name:12} | Actual: {actual_name}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression: Predicting Numbers\n",
    "\n",
    "Let's predict house prices based on features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Simple dataset: house size -> price\n",
    "# Sizes in square feet\n",
    "house_sizes = np.array([1000, 1500, 2000, 2500, 3000, 3500]).reshape(-1, 1)\n",
    "# Prices in thousands of dollars\n",
    "prices = np.array([200, 280, 350, 420, 500, 580])\n",
    "\n",
    "# Create and train the model\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(house_sizes, prices)\n",
    "\n",
    "# Predict price for new houses\n",
    "new_houses = np.array([1800, 2700, 4000]).reshape(-1, 1)\n",
    "predicted_prices = regression_model.predict(new_houses)\n",
    "\n",
    "print(\"Price Predictions:\")\n",
    "for size, price in zip(new_houses.flatten(), predicted_prices):\n",
    "    print(f\"House size: {size} sq ft -> Predicted price: ${price:.2f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: Finding Groups\n",
    "\n",
    "Unsupervised learning to find natural groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Customer data: [age, annual_spending_k]\n",
    "customers = np.array([\n",
    "    [25, 40], [27, 45], [30, 50], [35, 48],  # Young spenders\n",
    "    [45, 80], [48, 85], [50, 90], [52, 88],  # Middle-age high spenders\n",
    "    [60, 30], [62, 28], [65, 32], [67, 35]   # Seniors low spenders\n",
    "])\n",
    "\n",
    "# Find 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(customers)\n",
    "\n",
    "print(\"Customer Segments:\")\n",
    "for i, (customer, cluster) in enumerate(zip(customers, clusters)):\n",
    "    print(f\"Customer {i+1}: Age {customer[0]}, Spending ${customer[1]}k -> Group {cluster}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics\n",
    "\n",
    "Different ways to measure model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Using our iris model from earlier\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=iris.target_names))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"\\n(Rows = Actual, Columns = Predicted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Build a spam classifier:\n",
    "1. Create a simple dataset of emails (represented as word counts)\n",
    "2. Label them as spam (1) or not spam (0)\n",
    "3. Train a DecisionTreeClassifier\n",
    "4. Test on new \"emails\" and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Features could be [word_count, has_money_words, has_urgent_words]\n",
    "# Example: [50, 0, 0] = 50 words, no money words, no urgent words -> Not spam\n",
    "#          [30, 1, 1] = 30 words, has money words, has urgent words -> Spam\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
