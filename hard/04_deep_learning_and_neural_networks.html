
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lesson 4: Deep Learning and Neural Networks &#8212; Education Playground</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=0c7f5221" />
    <link rel="stylesheet" type="text/css" href="../_static/css/toc-fix.css?v=9435d31d" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=c73c0f3e"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'hard/04_deep_learning_and_neural_networks';</script>
    <script src="../_static/js/mobile-nav.js?v=66ebaa39"></script>
    <script src="../_static/js/toc-enhancement.js?v=11e67553"></script>
    <script src="../_static/js/onboarding.js?v=e068e0de"></script>
    <link rel="canonical" href="https://mykolas-perevicius.github.io/Education_Playground/hard/04_deep_learning_and_neural_networks.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lesson 5: Advanced Machine Learning and NLP" href="05_advanced_ml_and_nlp.html" />
    <link rel="prev" title="Hard Lesson 03: Algorithms and Complexity Analysis" href="03_algorithms_and_complexity.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
  
  
    <p class="title logo__title">Education Playground</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_calibration_test.html">üéØ Calibration Test - Find Your Level</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner_scripts/README.html">üå± Beginner Scripts (10 Python Files)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../easy/README_EASY.html">üìó Easy Level - Beginner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../easy/01_introduction_to_python.html">1. Introduction to Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../easy/02_variables_and_data_types.html">2. Variables and Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../easy/03_basic_operations_and_conditionals.html">3. Operations and Conditionals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../easy/04_intro_to_ai_and_ml.html">4. Intro to AI and ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../easy/05_computing_fundamentals.html">5. Computing Fundamentals</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../medium/README_MEDIUM.html">üìò Medium Level - Intermediate</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../medium/01_functions_and_modules.html">1. Functions and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../medium/02_data_structures.html">2. Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../medium/03_classes_and_oop.html">3. Classes and OOP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../medium/04_machine_learning_basics.html">4. Machine Learning Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../medium/05_data_analysis_with_pandas.html">5. Data Analysis with Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../medium/06_algorithms_and_problem_solving.html">6. Algorithms and Problem Solving</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="README_HARD.html">üìï Hard Level - Advanced</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_advanced_functions_and_decorators.html">1. Advanced Functions &amp; Decorators</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_generators_and_iterators.html">2. Generators and Iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_algorithms_and_complexity.html">3. Algorithms and Complexity</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4. Deep Learning &amp; Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_advanced_ml_and_nlp.html">5. Advanced ML and NLP</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_computer_systems_and_theory.html">6. Computer Systems and Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_project_ideas.html">7. Project Ideas &amp; Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_classic_problems.html">Lesson 8: Classic Problems Collection</a></li>





<li class="toctree-l2"><a class="reference internal" href="09_ctf_challenges.html">Lesson 9: Capture The Flag (CTF) - Hacker Training</a></li>






<li class="toctree-l2"><a class="reference internal" href="10_performance_computing.html">10. Performance Computing ‚ö° NEW!</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_cuda_and_parallel_computing.html">11. CUDA &amp; GPU Computing üéÆ NEW!</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tools/README.html">üõ†Ô∏è Developer Tools Track</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tools/01_shell_basics.html">1. Shell and Command Line</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/02_command_line_tools.html">2. Command Line Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/03_git_essentials.html">3. Git Essentials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/04_text_editors.html">4. Text Editors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/05_build_systems_cicd.html">5. Build Systems and CI/CD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/06_debugging_profiling.html">6. Debugging and Profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/07_security_essentials.html">7. Security Essentials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/08_package_management.html">8. Package Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/09_ssh_remote_systems.html">9. SSH and Remote Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools/10_docker_containers.html">10. Docker and Containers</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../solutions/README_SOLUTIONS.html">üìù Solutions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../solutions/easy_solutions.html">Easy Level - Complete Solutions</a></li>





<li class="toctree-l2"><a class="reference internal" href="../solutions/medium_solutions.html">Medium Level - Complete Solutions</a></li>






<li class="toctree-l2"><a class="reference internal" href="../solutions/hard_solutions.html">Hard Level - Complete Solutions</a></li>








<li class="toctree-l2"><a class="reference internal" href="../solutions/tools_solutions.html">Developer Tools - Complete Solutions</a></li>






</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../RESOURCES.html">üìö Learning Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PYTHON_CHEATSHEET.html">‚ö° Python Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ML_AI_CHEATSHEET.html">ü§ñ ML/AI Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SETUP.html">üîß Setup Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE_NOTES_v2.0.0.html">üéâ Release Notes v2.0.0</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lesson 4: Deep Learning and Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-context">Real-World Context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-ll-learn">What You‚Äôll Learn</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-neural-network-fundamentals">Part 1: Neural Network Fundamentals</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-neural-network">What is a Neural Network?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-components">Architecture Components</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mathematics">The Mathematics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-activation-functions">Part 2: Activation Functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-activation-functions">Common Activation Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-non-linearity-matters">Why Non-Linearity Matters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-building-your-first-neural-network">Part 3: Building Your First Neural Network</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-architecture">Understanding the Architecture</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-4-backpropagation-and-gradient-descent">Part 4: Backpropagation and Gradient Descent</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-networks-learn">How Neural Networks Learn</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent-variants">Gradient Descent Variants</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">The Mathematics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-5-regularization-techniques">Part 5: Regularization Techniques</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-regularization-methods">Common Regularization Methods</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-6-convolutional-neural-networks-cnns">Part 6: Convolutional Neural Networks (CNNs)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-cnns-for-images">Why CNNs for Images?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn-layers">CNN Layers</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-7-transfer-learning">Part 7: Transfer Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-transfer-learning">Why Transfer Learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#popular-pre-trained-models">Popular Pre-trained Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-strategy">Fine-Tuning Strategy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-8-advanced-architectures">Part 8: Advanced Architectures</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#residual-connections-resnet">Residual Connections (ResNet)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-mechanisms-simplified">Attention Mechanisms (Simplified)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-9-training-best-practices">Part 9: Training Best Practices</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate-schedules">Learning Rate Schedules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation-images">Data Augmentation (Images)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-10-model-deployment">Part 10: Model Deployment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading-models">Saving and Loading Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#production-checklist">Production Checklist</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-11-common-mistakes-and-how-to-avoid-them">Part 11: Common Mistakes and How to Avoid Them</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-12-exercises">Part 12: Exercises</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-cifar-10-cnn">Exercise 1: CIFAR-10 CNN (‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-custom-activation-function">Exercise 2: Custom Activation Function (‚≠ê‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-transfer-learning">Exercise 3: Transfer Learning (‚≠ê‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-build-a-resnet-block">Exercise 4: Build a ResNet Block (‚≠ê‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-regularization-study">Exercise 5: Regularization Study (‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-6-model-interpretation">Exercise 6: Model Interpretation (‚≠ê‚≠ê‚≠ê‚≠ê)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#self-check-quiz">Self-Check Quiz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnns">CNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#production">Production</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pro-tips">Pro Tips</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#debugging-checklist">Debugging Checklist</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-next">What‚Äôs Next?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continue-in-hard-track">Continue in Hard Track:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deepen-your-knowledge">Deepen Your Knowledge:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practice-projects">Practice Projects:</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lesson-4-deep-learning-and-neural-networks">
<h1>Lesson 4: Deep Learning and Neural Networks<a class="headerlink" href="#lesson-4-deep-learning-and-neural-networks" title="Link to this heading">#</a></h1>
<p><strong>Master the fundamentals of deep learning and build production-ready neural networks</strong></p>
<section id="real-world-context">
<h2>Real-World Context<a class="headerlink" href="#real-world-context" title="Link to this heading">#</a></h2>
<p>Deep learning powers modern AI systems from GPT-4 to self-driving cars. Understanding neural networks is essential for any ML engineer - they‚Äôre used in computer vision (Tesla Autopilot), natural language processing (ChatGPT), speech recognition (Siri), recommendation systems (Netflix), and countless other applications.</p>
</section>
<section id="what-you-ll-learn">
<h2>What You‚Äôll Learn<a class="headerlink" href="#what-you-ll-learn" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Neural Network Theory</strong>: Neurons, layers, activation functions, and forward propagation</p></li>
<li><p><strong>Backpropagation</strong>: How networks learn through gradient descent</p></li>
<li><p><strong>Optimizers</strong>: Adam, SGD, RMSprop and their trade-offs</p></li>
<li><p><strong>Regularization</strong>: Dropout, batch normalization, L1/L2 regularization</p></li>
<li><p><strong>Convolutional Neural Networks (CNNs)</strong>: Architecture for computer vision</p></li>
<li><p><strong>Advanced Architectures</strong>: ResNets, Inception, attention mechanisms</p></li>
<li><p><strong>Training Strategies</strong>: Learning rate schedules, callbacks, early stopping</p></li>
<li><p><strong>Transfer Learning</strong>: Leveraging pre-trained models</p></li>
<li><p><strong>Production Best Practices</strong>: Model saving, versioning, deployment</p></li>
</ol>
<p><strong>Prerequisites</strong>: Python, NumPy, basic machine learning concepts</p>
<p><strong>Time</strong>: 3-4 hours</p>
</section>
<section id="part-1-neural-network-fundamentals">
<h2>Part 1: Neural Network Fundamentals<a class="headerlink" href="#part-1-neural-network-fundamentals" title="Link to this heading">#</a></h2>
<section id="what-is-a-neural-network">
<h3>What is a Neural Network?<a class="headerlink" href="#what-is-a-neural-network" title="Link to this heading">#</a></h3>
<p>A neural network is a computational model inspired by the human brain:</p>
<ul class="simple">
<li><p><strong>Biological neurons</strong>: Receive signals through dendrites, process in cell body, output through axon</p></li>
<li><p><strong>Artificial neurons</strong>: Receive inputs, apply weights, add bias, pass through activation function</p></li>
</ul>
</section>
<section id="architecture-components">
<h3>Architecture Components<a class="headerlink" href="#architecture-components" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Component</p></th>
<th class="head"><p>Purpose</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Input Layer</strong></p></td>
<td><p>Receives raw data</p></td>
<td><p>784 pixels for MNIST images</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hidden Layers</strong></p></td>
<td><p>Extract features</p></td>
<td><p>[128, 64, 32] neurons in 3 layers</p></td>
</tr>
<tr class="row-even"><td><p><strong>Output Layer</strong></p></td>
<td><p>Produces predictions</p></td>
<td><p>10 neurons for digit classification</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Weights</strong></p></td>
<td><p>Learnable parameters</p></td>
<td><p>Matrix of connections between layers</p></td>
</tr>
<tr class="row-even"><td><p><strong>Biases</strong></p></td>
<td><p>Learnable offsets</p></td>
<td><p>One per neuron</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Activation Functions</strong></p></td>
<td><p>Introduce non-linearity</p></td>
<td><p>ReLU, sigmoid, tanh</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="the-mathematics">
<h3>The Mathematics<a class="headerlink" href="#the-mathematics" title="Link to this heading">#</a></h3>
<p>For a single neuron:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>z = Œ£(wi √ó xi) + b     # Linear combination
a = œÉ(z)               # Activation function
</pre></div>
</div>
<p>For a layer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Z = W √ó X + b          # Matrix multiplication
A = œÉ(Z)               # Element-wise activation
</pre></div>
</div>
</section>
</section>
<section id="part-2-activation-functions">
<h2>Part 2: Activation Functions<a class="headerlink" href="#part-2-activation-functions" title="Link to this heading">#</a></h2>
<p>Activation functions introduce non-linearity, allowing networks to learn complex patterns.</p>
<section id="common-activation-functions">
<h3>Common Activation Functions<a class="headerlink" href="#common-activation-functions" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Formula</p></th>
<th class="head"><p>Range</p></th>
<th class="head"><p>Use Case</p></th>
<th class="head"><p>Pros</p></th>
<th class="head"><p>Cons</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>ReLU</strong></p></td>
<td><p>max(0, x)</p></td>
<td><p>[0, ‚àû)</p></td>
<td><p>Hidden layers</p></td>
<td><p>Fast, no vanishing gradient</p></td>
<td><p>Dead neurons</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Leaky ReLU</strong></p></td>
<td><p>max(0.01x, x)</p></td>
<td><p>(-‚àû, ‚àû)</p></td>
<td><p>Hidden layers</p></td>
<td><p>Fixes dead ReLU</p></td>
<td><p>Slightly slower</p></td>
</tr>
<tr class="row-even"><td><p><strong>Sigmoid</strong></p></td>
<td><p>1/(1+e^-x)</p></td>
<td><p>(0, 1)</p></td>
<td><p>Binary output</p></td>
<td><p>Probabilistic interpretation</p></td>
<td><p>Vanishing gradient</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Tanh</strong></p></td>
<td><p>(e^x - e^-x)/(e^x + e^-x)</p></td>
<td><p>(-1, 1)</p></td>
<td><p>Hidden layers (RNN)</p></td>
<td><p>Zero-centered</p></td>
<td><p>Vanishing gradient</p></td>
</tr>
<tr class="row-even"><td><p><strong>Softmax</strong></p></td>
<td><p>e^xi / Œ£e^xj</p></td>
<td><p>[0, 1], sum=1</p></td>
<td><p>Multi-class output</p></td>
<td><p>Probability distribution</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Swish</strong></p></td>
<td><p>x √ó sigmoid(x)</p></td>
<td><p>(-‚àû, ‚àû)</p></td>
<td><p>Modern architectures</p></td>
<td><p>Smooth, self-gated</p></td>
<td><p>More computation</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="why-non-linearity-matters">
<h3>Why Non-Linearity Matters<a class="headerlink" href="#why-non-linearity-matters" title="Link to this heading">#</a></h3>
<p>Without activation functions, deep networks collapse to a single linear transformation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Layer 1: y = W1√óx
Layer 2: z = W2√óy = W2√ó(W1√óx) = (W2√óW1)√óx = W_combined√óx
</pre></div>
</div>
<p>This defeats the purpose of depth!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install required packages (uncomment if needed):</span>
<span class="c1"># !pip install tensorflow numpy matplotlib scikit-learn pandas seaborn</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span><span class="p">,</span> <span class="n">make_circles</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">callbacks</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow version: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU available: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize activation functions</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">swish</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="n">functions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">sigmoid</span><span class="p">,</span> <span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">tanh</span><span class="p">,</span> <span class="s1">&#39;Tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">relu</span><span class="p">,</span> <span class="s1">&#39;ReLU&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">leaky_relu</span><span class="p">,</span> <span class="s1">&#39;Leaky ReLU&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">swish</span><span class="p">,</span> <span class="s1">&#39;Swish&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">),</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">functions</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Output&#39;</span><span class="p">)</span>

<span class="c1"># Hide last subplot</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üìä Key Observations:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ReLU: Zero for negative, linear for positive (most popular)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Sigmoid: Saturates at 0 and 1 (use for probabilities)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Tanh: Zero-centered version of sigmoid&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Leaky ReLU: Prevents &#39;dead neurons&#39; with small negative slope&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Swish: Smooth, self-gated (used in EfficientNet)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-3-building-your-first-neural-network">
<h2>Part 3: Building Your First Neural Network<a class="headerlink" href="#part-3-building-your-first-neural-network" title="Link to this heading">#</a></h2>
<p>Let‚Äôs build a network to classify non-linear data that a linear classifier can‚Äôt handle.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate non-linear dataset (two interleaving half circles)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Standardize features (important for neural networks!)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Visualize the dataset</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Non-Linear Classification Problem&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Feature 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Testing samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature shape: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Class distribution: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build neural network</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="c1"># Input layer (implicitly defined by first layer)</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hidden1&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>  <span class="c1"># Regularization: randomly drop 20% of neurons during training</span>
    
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hidden2&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hidden3&#39;</span><span class="p">),</span>
    
    <span class="c1"># Output layer</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>  <span class="c1"># Binary classification</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;simple_nn&#39;</span><span class="p">)</span>

<span class="c1"># Compile model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>  <span class="c1"># Adaptive learning rate optimizer</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>  <span class="c1"># For binary classification</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>  <span class="c1"># Track accuracy during training</span>
<span class="p">)</span>

<span class="c1"># Display architecture</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># Calculate total parameters</span>
<span class="n">total_params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìä Total trainable parameters: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="understanding-the-architecture">
<h3>Understanding the Architecture<a class="headerlink" href="#understanding-the-architecture" title="Link to this heading">#</a></h3>
<p><strong>Layer Sizes:</strong></p>
<ul class="simple">
<li><p>Input: 2 features</p></li>
<li><p>Hidden 1: 64 neurons ‚Üí 2√ó64 + 64 bias = 192 params</p></li>
<li><p>Hidden 2: 32 neurons ‚Üí 64√ó32 + 32 bias = 2,080 params</p></li>
<li><p>Hidden 3: 16 neurons ‚Üí 32√ó16 + 16 bias = 528 params</p></li>
<li><p>Output: 1 neuron ‚Üí 16√ó1 + 1 bias = 17 params</p></li>
<li><p><strong>Total: 2,817 parameters</strong></p></li>
</ul>
<p><strong>Why this architecture?</strong></p>
<ul class="simple">
<li><p><strong>Funnel shape</strong> (64‚Üí32‚Üí16): Common pattern for classification</p></li>
<li><p><strong>Dropout layers</strong>: Prevent overfitting by randomly disabling neurons</p></li>
<li><p><strong>ReLU activation</strong>: Fast, effective, avoids vanishing gradients</p></li>
<li><p><strong>Sigmoid output</strong>: Produces probability between 0 and 1</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train model with validation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üèãÔ∏è Training neural network...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>  <span class="c1"># Process 32 samples at a time</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># Use 20% of training data for validation</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>  <span class="c1"># Suppress epoch-by-epoch output</span>
<span class="p">)</span>

<span class="c1"># Evaluate on test set</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚úÖ Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üìâ Test Loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Final training accuracy</span>
<span class="n">final_train_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">final_val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìä Final Training Accuracy: </span><span class="si">{</span><span class="n">final_train_acc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üìä Final Validation Accuracy: </span><span class="si">{</span><span class="n">final_val_acc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># Check for overfitting</span>
<span class="k">if</span> <span class="n">final_train_acc</span> <span class="o">-</span> <span class="n">final_val_acc</span> <span class="o">&gt;</span> <span class="mf">0.05</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚ö†Ô∏è  Warning: Potential overfitting detected (train-val gap &gt; 5%)&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ No significant overfitting detected&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize training progress</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Accuracy</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy Over Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Loss</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss Over Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìà Interpretation:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Both training and validation curves should decrease&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Gap between curves indicates overfitting&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Validation loss increasing = model memorizing, not learning&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-4-backpropagation-and-gradient-descent">
<h2>Part 4: Backpropagation and Gradient Descent<a class="headerlink" href="#part-4-backpropagation-and-gradient-descent" title="Link to this heading">#</a></h2>
<section id="how-neural-networks-learn">
<h3>How Neural Networks Learn<a class="headerlink" href="#how-neural-networks-learn" title="Link to this heading">#</a></h3>
<p><strong>Forward Pass (Prediction):</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input ‚Üí Layer 1 ‚Üí Layer 2 ‚Üí ... ‚Üí Output ‚Üí Loss
</pre></div>
</div>
<p><strong>Backward Pass (Learning):</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Loss ‚Üí ‚àÇLoss/‚àÇweights ‚Üí Update weights ‚Üê Gradient descent
</pre></div>
</div>
</section>
<section id="gradient-descent-variants">
<h3>Gradient Descent Variants<a class="headerlink" href="#gradient-descent-variants" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Optimizer</p></th>
<th class="head"><p>Learning Rate</p></th>
<th class="head"><p>Memory</p></th>
<th class="head"><p>Speed</p></th>
<th class="head"><p>Use Case</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>SGD</strong></p></td>
<td><p>Constant</p></td>
<td><p>Low</p></td>
<td><p>Slow</p></td>
<td><p>Simple problems</p></td>
</tr>
<tr class="row-odd"><td><p><strong>SGD + Momentum</strong></p></td>
<td><p>Constant + velocity</p></td>
<td><p>Low</p></td>
<td><p>Medium</p></td>
<td><p>Helps escape local minima</p></td>
</tr>
<tr class="row-even"><td><p><strong>RMSprop</strong></p></td>
<td><p>Adaptive per-parameter</p></td>
<td><p>Medium</p></td>
<td><p>Fast</p></td>
<td><p>Recurrent networks</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Adam</strong></p></td>
<td><p>Adaptive + momentum</p></td>
<td><p>High</p></td>
<td><p>Fast</p></td>
<td><p>Default choice (most tasks)</p></td>
</tr>
<tr class="row-even"><td><p><strong>AdamW</strong></p></td>
<td><p>Adam + weight decay</p></td>
<td><p>High</p></td>
<td><p>Fast</p></td>
<td><p>Modern SOTA (transformers)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="id1">
<h3>The Mathematics<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p><strong>Standard gradient descent:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>w_new = w_old - learning_rate √ó ‚àÇLoss/‚àÇw
</pre></div>
</div>
<p><strong>Adam (simplified):</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>m_t = Œ≤1 √ó m_{t-1} + (1-Œ≤1) √ó gradient          # First moment (momentum)
v_t = Œ≤2 √ó v_{t-1} + (1-Œ≤2) √ó gradient¬≤         # Second moment (variance)
w_new = w_old - learning_rate √ó m_t / ‚àö(v_t)    # Update
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare different optimizers</span>
<span class="n">optimizers_to_test</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;SGD&#39;</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;SGD+Momentum&#39;</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;RMSprop&#39;</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)),</span>
<span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers_to_test</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üîÑ Training with </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
    
    <span class="c1"># Create fresh model</span>
    <span class="n">test_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,)),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="n">test_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="c1"># Train</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">test_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                          <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Store results</span>
    <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
    <span class="n">final_acc</span> <span class="o">=</span> <span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ‚úÖ Final validation accuracy: </span><span class="si">{</span><span class="n">final_acc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># Plot comparison</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">accuracies</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Optimizer Comparison: Validation Accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üéØ Key Insights:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Adam typically converges fastest&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - SGD with momentum is more stable than plain SGD&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - RMSprop works well but Adam is usually better&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-5-regularization-techniques">
<h2>Part 5: Regularization Techniques<a class="headerlink" href="#part-5-regularization-techniques" title="Link to this heading">#</a></h2>
<p>Regularization prevents overfitting by constraining model complexity.</p>
<section id="common-regularization-methods">
<h3>Common Regularization Methods<a class="headerlink" href="#common-regularization-methods" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Technique</p></th>
<th class="head"><p>How it Works</p></th>
<th class="head"><p>When to Use</p></th>
<th class="head"><p>Strength</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Dropout</strong></p></td>
<td><p>Randomly disable neurons</p></td>
<td><p>Most cases</p></td>
<td><p>0.2-0.5</p></td>
</tr>
<tr class="row-odd"><td><p><strong>L2 Regularization</strong></p></td>
<td><p>Penalize large weights</p></td>
<td><p>Small datasets</p></td>
<td><p>0.001-0.01</p></td>
</tr>
<tr class="row-even"><td><p><strong>L1 Regularization</strong></p></td>
<td><p>Penalize non-zero weights</p></td>
<td><p>Feature selection</p></td>
<td><p>0.001-0.01</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Batch Normalization</strong></p></td>
<td><p>Normalize layer inputs</p></td>
<td><p>Deep networks</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even"><td><p><strong>Early Stopping</strong></p></td>
<td><p>Stop when validation plateaus</p></td>
<td><p>Always</p></td>
<td><p>patience=5-10</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Data Augmentation</strong></p></td>
<td><p>Generate variations</p></td>
<td><p>Images, text</p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model with aggressive regularization</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">regularizers</span>

<span class="n">regularized_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,),</span>
                <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)),</span>  <span class="c1"># L2 regularization</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>  <span class="c1"># Normalize activations</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>  <span class="c1"># Drop 30% of neurons</span>
    
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
    
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;regularized_model&#39;</span><span class="p">)</span>

<span class="n">regularized_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Early stopping callback</span>
<span class="n">early_stop</span> <span class="o">=</span> <span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>  <span class="c1"># Watch validation loss</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># Stop if no improvement for 10 epochs</span>
    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Revert to best model</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Train with regularization</span>
<span class="n">reg_history</span> <span class="o">=</span> <span class="n">regularized_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>  <span class="c1"># More epochs, but early stopping will halt training</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stop</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">‚úÖ Training stopped after </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reg_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> epochs&quot;</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">regularized_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚úÖ Test Accuracy: </span><span class="si">{</span><span class="n">test_acc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-6-convolutional-neural-networks-cnns">
<h2>Part 6: Convolutional Neural Networks (CNNs)<a class="headerlink" href="#part-6-convolutional-neural-networks-cnns" title="Link to this heading">#</a></h2>
<p>CNNs are specialized for <strong>spatial data</strong> (images, video, audio spectrograms).</p>
<section id="why-cnns-for-images">
<h3>Why CNNs for Images?<a class="headerlink" href="#why-cnns-for-images" title="Link to this heading">#</a></h3>
<p><strong>Traditional neural networks:</strong></p>
<ul class="simple">
<li><p>28√ó28 image ‚Üí 784 input neurons</p></li>
<li><p>224√ó224 RGB image ‚Üí 150,528 input neurons!</p></li>
<li><p>Doesn‚Äôt exploit spatial structure</p></li>
<li><p>Too many parameters</p></li>
</ul>
<p><strong>CNNs solve this:</strong></p>
<ul class="simple">
<li><p><strong>Local connectivity</strong>: Each neuron sees small region (receptive field)</p></li>
<li><p><strong>Parameter sharing</strong>: Same filter used across entire image</p></li>
<li><p><strong>Translation invariance</strong>: Detect features anywhere in image</p></li>
</ul>
</section>
<section id="cnn-layers">
<h3>CNN Layers<a class="headerlink" href="#cnn-layers" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Layer</p></th>
<th class="head"><p>Purpose</p></th>
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Output</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Conv2D</strong></p></td>
<td><p>Detect features</p></td>
<td><p>Filters (e.g., 3√ó3√ó32)</p></td>
<td><p>Feature maps</p></td>
</tr>
<tr class="row-odd"><td><p><strong>MaxPooling2D</strong></p></td>
<td><p>Downsample</p></td>
<td><p>None</p></td>
<td><p>Reduced spatial size</p></td>
</tr>
<tr class="row-even"><td><p><strong>BatchNormalization</strong></p></td>
<td><p>Stabilize training</p></td>
<td><p>Œ≥, Œ≤ per channel</p></td>
<td><p>Normalized activations</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Flatten</strong></p></td>
<td><p>Convert to 1D</p></td>
<td><p>None</p></td>
<td><p>Vector</p></td>
</tr>
<tr class="row-even"><td><p><strong>Dense</strong></p></td>
<td><p>Classification</p></td>
<td><p>Weights + biases</p></td>
<td><p>Predictions</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load MNIST dataset (handwritten digits)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üì¶ Loading MNIST dataset...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">X_train_img</span><span class="p">,</span> <span class="n">y_train_img</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test_img</span><span class="p">,</span> <span class="n">y_test_img</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Preprocess</span>
<span class="n">X_train_img</span> <span class="o">=</span> <span class="n">X_train_img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">X_test_img</span> <span class="o">=</span> <span class="n">X_test_img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="c1"># One-hot encode labels (0-9 ‚Üí 10 binary columns)</span>
<span class="n">y_train_img</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train_img</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_test_img</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test_img</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training images: </span><span class="si">{</span><span class="n">X_train_img</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test images: </span><span class="si">{</span><span class="n">X_test_img</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image shape: </span><span class="si">{</span><span class="n">X_train_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of classes: </span><span class="si">{</span><span class="n">y_train_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualize samples</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train_img</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_train_img</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Sample MNIST Images&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build CNN architecture</span>
<span class="n">cnn_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="c1"># First convolutional block</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>  <span class="c1"># 28√ó28 ‚Üí 14√ó14</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">),</span>
    
    <span class="c1"># Second convolutional block</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>  <span class="c1"># 14√ó14 ‚Üí 7√ó7</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">),</span>
    
    <span class="c1"># Third convolutional block</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">),</span>
    
    <span class="c1"># Flatten and dense layers</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>  <span class="c1"># 7√ó7√ó128 = 6,272 features</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>  <span class="c1"># 10 digit classes</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cnn_mnist&#39;</span><span class="p">)</span>

<span class="n">cnn_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">cnn_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìä Total parameters: </span><span class="si">{</span><span class="n">cnn_model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train CNN with callbacks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üèãÔ∏è Training CNN...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Learning rate reduction on plateau</span>
<span class="n">reduce_lr</span> <span class="o">=</span> <span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
    <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Reduce LR by half</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Early stopping</span>
<span class="n">early_stop_cnn</span> <span class="o">=</span> <span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Train (using subset for speed in demo)</span>
<span class="n">cnn_history</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train_img</span><span class="p">[:</span><span class="mi">20000</span><span class="p">],</span> <span class="n">y_train_img</span><span class="p">[:</span><span class="mi">20000</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">reduce_lr</span><span class="p">,</span> <span class="n">early_stop_cnn</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_img</span><span class="p">,</span> <span class="n">y_test_img</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">‚úÖ Test Accuracy: </span><span class="si">{</span><span class="n">test_acc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üìâ Test Loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize CNN predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_img</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">true_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test_img</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test_img</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">predicted_classes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">true</span> <span class="o">=</span> <span class="n">true_classes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">confidence</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">pred</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
    
    <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span> <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="n">true</span> <span class="k">else</span> <span class="s1">&#39;red&#39;</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;True: </span><span class="si">{</span><span class="n">true</span><span class="si">}</span><span class="se">\n</span><span class="s1">Pred: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">confidence</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%)&#39;</span><span class="p">,</span> 
                <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;CNN Predictions (Green=Correct, Red=Wrong)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Confusion matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">all_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cnn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_img</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">all_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test_img</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">all_true</span><span class="p">,</span> <span class="n">all_preds</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-7-transfer-learning">
<h2>Part 7: Transfer Learning<a class="headerlink" href="#part-7-transfer-learning" title="Link to this heading">#</a></h2>
<p>Transfer learning leverages pre-trained models to solve new tasks faster with less data.</p>
<section id="why-transfer-learning">
<h3>Why Transfer Learning?<a class="headerlink" href="#why-transfer-learning" title="Link to this heading">#</a></h3>
<p><strong>Training from scratch:</strong></p>
<ul class="simple">
<li><p>Requires millions of images</p></li>
<li><p>Needs days/weeks on GPUs</p></li>
<li><p>Expensive ($1000s in compute)</p></li>
</ul>
<p><strong>Transfer learning:</strong></p>
<ul class="simple">
<li><p>Use model trained on ImageNet (14M images, 1000 classes)</p></li>
<li><p>Fine-tune on your dataset (can be just 100s of images)</p></li>
<li><p>Train in hours, not days</p></li>
</ul>
</section>
<section id="popular-pre-trained-models">
<h3>Popular Pre-trained Models<a class="headerlink" href="#popular-pre-trained-models" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Top-1 Acc</p></th>
<th class="head"><p>Year</p></th>
<th class="head"><p>Use Case</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>VGG16</strong></p></td>
<td><p>138M</p></td>
<td><p>71.3%</p></td>
<td><p>2014</p></td>
<td><p>Simple, interpretable</p></td>
</tr>
<tr class="row-odd"><td><p><strong>ResNet50</strong></p></td>
<td><p>25.6M</p></td>
<td><p>76.1%</p></td>
<td><p>2015</p></td>
<td><p>Good balance</p></td>
</tr>
<tr class="row-even"><td><p><strong>Inception-v3</strong></p></td>
<td><p>23.9M</p></td>
<td><p>77.9%</p></td>
<td><p>2015</p></td>
<td><p>Multi-scale features</p></td>
</tr>
<tr class="row-odd"><td><p><strong>MobileNetV2</strong></p></td>
<td><p>3.5M</p></td>
<td><p>71.8%</p></td>
<td><p>2018</p></td>
<td><p>Mobile/embedded</p></td>
</tr>
<tr class="row-even"><td><p><strong>EfficientNet-B0</strong></p></td>
<td><p>5.3M</p></td>
<td><p>77.1%</p></td>
<td><p>2019</p></td>
<td><p>Best accuracy/size</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Vision Transformer</strong></p></td>
<td><p>86M</p></td>
<td><p>84.2%</p></td>
<td><p>2020</p></td>
<td><p>SOTA (expensive)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load pre-trained ResNet50 (without top classification layer)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üì¶ Loading pre-trained ResNet50...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">base_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span>  <span class="c1"># Pre-trained on ImageNet</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Exclude final classification layer</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Standard ImageNet size</span>
<span class="p">)</span>

<span class="c1"># Freeze base model layers (don&#39;t train them initially)</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Add custom classification head</span>
<span class="n">transfer_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">base_model</span><span class="p">,</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(),</span>  <span class="c1"># Reduce to 1D</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>  <span class="c1"># 10 classes (example)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;transfer_learning_model&#39;</span><span class="p">)</span>

<span class="n">transfer_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total parameters: </span><span class="si">{</span><span class="n">transfer_model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trainable parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">transfer_model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">])</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Non-trainable parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">transfer_model</span><span class="o">.</span><span class="n">non_trainable_weights</span><span class="p">])</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üéØ Transfer Learning Strategy:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  1. Freeze pre-trained layers (use learned features)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  2. Train only custom classification head&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  3. Optionally: Unfreeze top layers and fine-tune&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tuning-strategy">
<h3>Fine-Tuning Strategy<a class="headerlink" href="#fine-tuning-strategy" title="Link to this heading">#</a></h3>
<p><strong>Phase 1: Train head only</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># Train for 5-10 epochs</span>
</pre></div>
</div>
<p><strong>Phase 2: Fine-tune top layers</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">base_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">20</span><span class="p">]:</span>  <span class="c1"># Freeze all but last 20 layers</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>  <span class="c1"># Lower LR!</span>
</pre></div>
</div>
</section>
</section>
<section id="part-8-advanced-architectures">
<h2>Part 8: Advanced Architectures<a class="headerlink" href="#part-8-advanced-architectures" title="Link to this heading">#</a></h2>
<section id="residual-connections-resnet">
<h3>Residual Connections (ResNet)<a class="headerlink" href="#residual-connections-resnet" title="Link to this heading">#</a></h3>
<p><strong>Problem</strong>: Deep networks suffer from vanishing gradients</p>
<p><strong>Solution</strong>: Skip connections that allow gradients to flow directly</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Traditional:  x ‚Üí Conv ‚Üí Conv ‚Üí y
Residual:     x ‚Üí Conv ‚Üí Conv ‚Üí (+) ‚Üí y
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (skip connection)
</pre></div>
</div>
<p><strong>Mathematics:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>    <span class="c1"># Instead of y = F(x)</span>
</pre></div>
</div>
<p>This allows networks with 100+ layers!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement a residual block</span>
<span class="k">def</span> <span class="nf">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a residual block with skip connection.&quot;&quot;&quot;</span>
    <span class="c1"># Main path</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="c1"># Skip connection (adjust dimensions if needed)</span>
    <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">filters</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># Add skip connection</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">out</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out</span>

<span class="c1"># Build mini-ResNet</span>
<span class="k">def</span> <span class="nf">build_mini_resnet</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
    
    <span class="c1"># Initial convolution</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># Residual blocks</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Downsample</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Downsample</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    
    <span class="c1"># Classification head</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mini_resnet&#39;</span><span class="p">)</span>

<span class="n">resnet_model</span> <span class="o">=</span> <span class="n">build_mini_resnet</span><span class="p">()</span>
<span class="n">resnet_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìä Total parameters: </span><span class="si">{</span><span class="n">resnet_model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="attention-mechanisms-simplified">
<h3>Attention Mechanisms (Simplified)<a class="headerlink" href="#attention-mechanisms-simplified" title="Link to this heading">#</a></h3>
<p>Attention allows the model to <strong>focus on important features</strong>.</p>
<p><strong>Intuition</strong>: When reading a sentence, you don‚Äôt give equal attention to every word.</p>
<p><strong>Mathematics (simplified):</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Attention(Q, K, V) = softmax(Q¬∑K^T / ‚àöd) ¬∑ V
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><p>Q = Query (what we‚Äôre looking for)</p></li>
<li><p>K = Key (what‚Äôs available)</p></li>
<li><p>V = Value (actual information)</p></li>
</ul>
<p>Used in:</p>
<ul class="simple">
<li><p>Transformers (GPT, BERT)</p></li>
<li><p>Vision Transformers (ViT)</p></li>
<li><p>Multi-modal models (CLIP)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simple channel attention (Squeeze-and-Excitation)</span>
<span class="k">def</span> <span class="nf">channel_attention</span><span class="p">(</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Channel attention: Which feature maps are important?</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">channel</span> <span class="o">=</span> <span class="n">input_feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Squeeze: Global average pooling</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">input_feature</span><span class="p">)</span>
    
    <span class="c1"># Excitation: Learn channel importance</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">channel</span> <span class="o">//</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># Reshape and multiply</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">channel</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Multiply</span><span class="p">()([</span><span class="n">input_feature</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span>

<span class="c1"># Example: Add attention to a CNN</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">channel_attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ‚Üê Add attention!</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">attention_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cnn_with_attention&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ CNN with channel attention created!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üìä Parameters: </span><span class="si">{</span><span class="n">attention_model</span><span class="o">.</span><span class="n">count_params</span><span class="p">()</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-9-training-best-practices">
<h2>Part 9: Training Best Practices<a class="headerlink" href="#part-9-training-best-practices" title="Link to this heading">#</a></h2>
<section id="learning-rate-schedules">
<h3>Learning Rate Schedules<a class="headerlink" href="#learning-rate-schedules" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Strategy</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Use Case</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Constant</strong></p></td>
<td><p>Same LR throughout</p></td>
<td><p>Simple problems</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Step Decay</strong></p></td>
<td><p>Reduce LR every N epochs</p></td>
<td><p>General purpose</p></td>
</tr>
<tr class="row-even"><td><p><strong>Exponential Decay</strong></p></td>
<td><p>LR = LR‚ÇÄ √ó e^(-kt)</p></td>
<td><p>Smooth reduction</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Cosine Annealing</strong></p></td>
<td><p>Follows cosine curve</p></td>
<td><p>SOTA training</p></td>
</tr>
<tr class="row-even"><td><p><strong>ReduceLROnPlateau</strong></p></td>
<td><p>Reduce when stuck</p></td>
<td><p>Adaptive</p></td>
</tr>
<tr class="row-odd"><td><p><strong>One Cycle</strong></p></td>
<td><p>Increase then decrease</p></td>
<td><p>Fast training</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="data-augmentation-images">
<h3>Data Augmentation (Images)<a class="headerlink" href="#data-augmentation-images" title="Link to this heading">#</a></h3>
<p>Artificially expand dataset by applying transformations:</p>
<ul class="simple">
<li><p>Random rotation (¬±15¬∞)</p></li>
<li><p>Horizontal/vertical flip</p></li>
<li><p>Zoom (90%-110%)</p></li>
<li><p>Shift (¬±10%)</p></li>
<li><p>Brightness/contrast</p></li>
<li><p>Cutout/mixup (advanced)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Learning rate schedules</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># Cosine annealing</span>
<span class="k">def</span> <span class="nf">cosine_annealing</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">total_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cosine annealing learning rate schedule.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">min_lr</span> <span class="o">+</span> <span class="p">(</span><span class="n">lr</span> <span class="o">-</span> <span class="n">min_lr</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">epoch</span> <span class="o">/</span> <span class="n">total_epochs</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>

<span class="c1"># Visualize schedule</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">initial_lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">cosine_annealing</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">initial_lr</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lrs</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cosine Annealing Learning Rate Schedule&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Learning Rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üìà Benefits of LR scheduling:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Start high: Explore loss landscape quickly&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - End low: Fine-tune to optimal solution&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Cosine: Smooth transitions, no sudden jumps&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data augmentation example</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>

<span class="c1"># Create augmentation pipeline</span>
<span class="n">datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span>
    <span class="n">rotation_range</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>  <span class="c1"># Random rotation ¬±15¬∞</span>
    <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># Horizontal shift ¬±10%</span>
    <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># Vertical shift ¬±10%</span>
    <span class="n">zoom_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># Zoom 90%-110%</span>
    <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># Shear transformation</span>
    <span class="n">fill_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span>  <span class="c1"># Fill empty pixels</span>
<span class="p">)</span>

<span class="c1"># Visualize augmented images</span>
<span class="n">sample_img</span> <span class="o">=</span> <span class="n">X_train_img</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Take first image</span>
<span class="n">sample_label</span> <span class="o">=</span> <span class="n">y_train_img</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="c1"># Original</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample_img</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="c1"># Augmented versions</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">sample_img</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">9</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Augmented </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Data Augmentation Examples&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üéØ Data Augmentation Benefits:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Reduces overfitting (model sees variations)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Acts as regularization&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Improves generalization to new data&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Effective with small datasets&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-10-model-deployment">
<h2>Part 10: Model Deployment<a class="headerlink" href="#part-10-model-deployment" title="Link to this heading">#</a></h2>
<section id="saving-and-loading-models">
<h3>Saving and Loading Models<a class="headerlink" href="#saving-and-loading-models" title="Link to this heading">#</a></h3>
<p><strong>Three formats:</strong></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Format</p></th>
<th class="head"><p>Extension</p></th>
<th class="head"><p>Use Case</p></th>
<th class="head"><p>Size</p></th>
<th class="head"><p>Load Speed</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>SavedModel</strong></p></td>
<td><p>/ (directory)</p></td>
<td><p>Production (TF Serving)</p></td>
<td><p>Large</p></td>
<td><p>Medium</p></td>
</tr>
<tr class="row-odd"><td><p><strong>HDF5</strong></p></td>
<td><p>.h5, .keras</p></td>
<td><p>Development</p></td>
<td><p>Medium</p></td>
<td><p>Fast</p></td>
</tr>
<tr class="row-even"><td><p><strong>TFLite</strong></p></td>
<td><p>.tflite</p></td>
<td><p>Mobile/Edge</p></td>
<td><p>Small</p></td>
<td><p>Very fast</p></td>
</tr>
<tr class="row-odd"><td><p><strong>ONNX</strong></p></td>
<td><p>.onnx</p></td>
<td><p>Cross-platform</p></td>
<td><p>Medium</p></td>
<td><p>Fast</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="production-checklist">
<h3>Production Checklist<a class="headerlink" href="#production-checklist" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚úÖ Save model architecture and weights</p></li>
<li><p>‚úÖ Save preprocessing parameters (scaler, tokenizer)</p></li>
<li><p>‚úÖ Version control (model_v1, model_v2, ‚Ä¶)</p></li>
<li><p>‚úÖ Document input/output shapes and types</p></li>
<li><p>‚úÖ Test on validation set</p></li>
<li><p>‚úÖ Benchmark inference time</p></li>
<li><p>‚úÖ Monitor performance in production</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save model (multiple formats)</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Create models directory</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;saved_models&#39;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 1. SavedModel format (TensorFlow native)</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;saved_models/cnn_mnist&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ Saved: SavedModel format (directory)&quot;</span><span class="p">)</span>

<span class="c1"># 2. HDF5 format (legacy, but widely used)</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;saved_models/cnn_mnist.h5&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ Saved: HDF5 format (.h5)&quot;</span><span class="p">)</span>

<span class="c1"># 3. Keras format (recommended for Keras 3+)</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;saved_models/cnn_mnist.keras&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ Saved: Keras format (.keras)&quot;</span><span class="p">)</span>

<span class="c1"># Save weights only (smaller file)</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;saved_models/cnn_mnist_weights.h5&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ Saved: Weights only (.h5)&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìÇ Saved model files:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="s1">&#39;saved_models&#39;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># KB</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load model</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;saved_models/cnn_mnist.keras&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;‚úÖ Model loaded successfully!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Verify it works</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_img</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="n">y_test_img</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded model accuracy: </span><span class="si">{</span><span class="n">test_acc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># Model versioning example</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="n">version</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">)</span>
<span class="n">versioned_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;saved_models/cnn_mnist_v</span><span class="si">{</span><span class="n">version</span><span class="si">}</span><span class="s1">.keras&#39;</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">versioned_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">‚úÖ Versioned model saved: </span><span class="si">{</span><span class="n">versioned_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-11-common-mistakes-and-how-to-avoid-them">
<h2>Part 11: Common Mistakes and How to Avoid Them<a class="headerlink" href="#part-11-common-mistakes-and-how-to-avoid-them" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Mistake</p></th>
<th class="head"><p>Symptom</p></th>
<th class="head"><p>Solution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Forgot to normalize data</strong></p></td>
<td><p>Poor accuracy</p></td>
<td><p>Scale inputs to [0,1] or standardize</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Wrong activation on output</strong></p></td>
<td><p>NaN loss</p></td>
<td><p>Sigmoid for binary, softmax for multi-class</p></td>
</tr>
<tr class="row-even"><td><p><strong>Too high learning rate</strong></p></td>
<td><p>Loss explodes</p></td>
<td><p>Start with 0.001 (Adam) or 0.01 (SGD)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Too small batch size</strong></p></td>
<td><p>Noisy training</p></td>
<td><p>Use 32-128 for most tasks</p></td>
</tr>
<tr class="row-even"><td><p><strong>Not using validation set</strong></p></td>
<td><p>Can‚Äôt detect overfitting</p></td>
<td><p>Always use validation_split or separate set</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Forgetting dropout at test time</strong></p></td>
<td><p>Poor test accuracy</p></td>
<td><p>Use model.predict(), not training mode</p></td>
</tr>
<tr class="row-even"><td><p><strong>Class imbalance</strong></p></td>
<td><p>Model predicts majority class</p></td>
<td><p>Use class weights or resampling</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Vanishing gradients</strong></p></td>
<td><p>No learning in deep nets</p></td>
<td><p>Use ReLU, batch norm, residual connections</p></td>
</tr>
<tr class="row-even"><td><p><strong>Data leakage</strong></p></td>
<td><p>Perfect val score, poor test</p></td>
<td><p>Normalize AFTER train/test split</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Not shuffling data</strong></p></td>
<td><p>Poor generalization</p></td>
<td><p>Use shuffle=True in fit()</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="part-12-exercises">
<h2>Part 12: Exercises<a class="headerlink" href="#part-12-exercises" title="Link to this heading">#</a></h2>
<section id="exercise-1-cifar-10-cnn">
<h3>Exercise 1: CIFAR-10 CNN (‚≠ê‚≠ê)<a class="headerlink" href="#exercise-1-cifar-10-cnn" title="Link to this heading">#</a></h3>
<p>Build and train a CNN for CIFAR-10 dataset:</p>
<ol class="arabic simple">
<li><p>Load CIFAR-10 (32√ó32 RGB images, 10 classes)</p></li>
<li><p>Design CNN with at least 3 convolutional blocks</p></li>
<li><p>Use data augmentation</p></li>
<li><p>Apply learning rate scheduling and early stopping</p></li>
<li><p>Achieve &gt;70% test accuracy</p></li>
<li><p>Visualize predictions and confusion matrix</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 1: Your code here</span>
<span class="c1"># Hint: keras.datasets.cifar10.load_data()</span>
<span class="c1"># Hint: ImageDataGenerator for augmentation</span>
<span class="c1"># Hint: Use reduce_lr and early_stop callbacks</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-2-custom-activation-function">
<h3>Exercise 2: Custom Activation Function (‚≠ê‚≠ê‚≠ê)<a class="headerlink" href="#exercise-2-custom-activation-function" title="Link to this heading">#</a></h3>
<p>Implement a custom activation function:</p>
<ol class="arabic simple">
<li><p>Create a custom Mish activation: <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">√ó</span> <span class="pre">tanh(ln(1</span> <span class="pre">+</span> <span class="pre">e^x))</span></code></p></li>
<li><p>Build a network using your custom activation</p></li>
<li><p>Compare performance with ReLU on MNIST</p></li>
<li><p>Plot both activation functions</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 2: Your code here</span>
<span class="c1"># Hint: @tf.function for custom activation</span>
<span class="c1"># Hint: Use layers.Activation(custom_mish)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-3-transfer-learning">
<h3>Exercise 3: Transfer Learning (‚≠ê‚≠ê‚≠ê)<a class="headerlink" href="#exercise-3-transfer-learning" title="Link to this heading">#</a></h3>
<p>Apply transfer learning to a small dataset:</p>
<ol class="arabic simple">
<li><p>Use a subset of CIFAR-10 (only 1000 images)</p></li>
<li><p>Load MobileNetV2 pre-trained on ImageNet</p></li>
<li><p>Freeze base, train custom head</p></li>
<li><p>Unfreeze top layers and fine-tune</p></li>
<li><p>Compare accuracy with model trained from scratch</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 3: Your code here</span>
<span class="c1"># Hint: keras.applications.MobileNetV2</span>
<span class="c1"># Hint: Resize CIFAR-10 images to 96√ó96 or 224√ó224</span>
<span class="c1"># Hint: Use very low LR for fine-tuning (1e-5)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-4-build-a-resnet-block">
<h3>Exercise 4: Build a ResNet Block (‚≠ê‚≠ê‚≠ê)<a class="headerlink" href="#exercise-4-build-a-resnet-block" title="Link to this heading">#</a></h3>
<p>Implement and test a ResNet architecture:</p>
<ol class="arabic simple">
<li><p>Create a residual_block function with skip connections</p></li>
<li><p>Build a small ResNet with 3-4 residual blocks</p></li>
<li><p>Train on Fashion MNIST</p></li>
<li><p>Compare with a regular CNN (same parameters)</p></li>
<li><p>Visualize training curves</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 4: Your code here</span>
<span class="c1"># Hint: keras.datasets.fashion_mnist.load_data()</span>
<span class="c1"># Hint: Use Functional API for skip connections</span>
<span class="c1"># Hint: layers.Add()([shortcut, x])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-5-regularization-study">
<h3>Exercise 5: Regularization Study (‚≠ê‚≠ê)<a class="headerlink" href="#exercise-5-regularization-study" title="Link to this heading">#</a></h3>
<p>Compare regularization techniques:</p>
<ol class="arabic simple">
<li><p>Train 4 models on MNIST:</p>
<ul class="simple">
<li><p>No regularization</p></li>
<li><p>Dropout only</p></li>
<li><p>L2 regularization only</p></li>
<li><p>Dropout + L2 + Batch Normalization</p></li>
</ul>
</li>
<li><p>Use small training set (5000 images)</p></li>
<li><p>Plot training vs validation accuracy for all</p></li>
<li><p>Identify which prevents overfitting best</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 5: Your code here</span>
<span class="c1"># Hint: Use same architecture, vary regularization only</span>
<span class="c1"># Hint: kernel_regularizer=regularizers.l2(0.01)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-6-model-interpretation">
<h3>Exercise 6: Model Interpretation (‚≠ê‚≠ê‚≠ê‚≠ê)<a class="headerlink" href="#exercise-6-model-interpretation" title="Link to this heading">#</a></h3>
<p>Visualize what a CNN learns:</p>
<ol class="arabic simple">
<li><p>Train a CNN on MNIST</p></li>
<li><p>Visualize first layer filters (convolutional kernels)</p></li>
<li><p>Create activation maps for a test image</p></li>
<li><p>Identify which filters activate for specific features</p></li>
<li><p><strong>Bonus</strong>: Implement Grad-CAM for class activation maps</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise 6: Your code here</span>
<span class="c1"># Hint: model.layers[0].get_weights()[0] for filters</span>
<span class="c1"># Hint: Create intermediate model: Model(inputs, layer.output)</span>
<span class="c1"># Hint: Grad-CAM: gradient of output w.r.t. activations</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="self-check-quiz">
<h2>Self-Check Quiz<a class="headerlink" href="#self-check-quiz" title="Link to this heading">#</a></h2>
<p>Test your understanding:</p>
<ol class="arabic simple">
<li><p><strong>Why do we need activation functions in neural networks?</strong></p>
<ul class="simple">
<li><p>A) To make training faster</p></li>
<li><p>B) To introduce non-linearity</p></li>
<li><p>C) To reduce overfitting</p></li>
<li><p>D) To normalize outputs</p></li>
</ul>
</li>
<li><p><strong>Which optimizer is the default choice for most deep learning tasks?</strong></p>
<ul class="simple">
<li><p>A) SGD</p></li>
<li><p>B) RMSprop</p></li>
<li><p>C) Adam</p></li>
<li><p>D) AdaGrad</p></li>
</ul>
</li>
<li><p><strong>What is the purpose of dropout?</strong></p>
<ul class="simple">
<li><p>A) Reduce model size</p></li>
<li><p>B) Speed up training</p></li>
<li><p>C) Prevent overfitting</p></li>
<li><p>D) Improve accuracy</p></li>
</ul>
</li>
<li><p><strong>In a CNN, what does a convolutional layer do?</strong></p>
<ul class="simple">
<li><p>A) Classify images</p></li>
<li><p>B) Detect local features</p></li>
<li><p>C) Reduce dimensions</p></li>
<li><p>D) Normalize inputs</p></li>
</ul>
</li>
<li><p><strong>What is transfer learning?</strong></p>
<ul class="simple">
<li><p>A) Training multiple models simultaneously</p></li>
<li><p>B) Using pre-trained weights as initialization</p></li>
<li><p>C) Transferring data between GPUs</p></li>
<li><p>D) Converting models between frameworks</p></li>
</ul>
</li>
<li><p><strong>Which activation should be used for binary classification output?</strong></p>
<ul class="simple">
<li><p>A) ReLU</p></li>
<li><p>B) Sigmoid</p></li>
<li><p>C) Tanh</p></li>
<li><p>D) Softmax</p></li>
</ul>
</li>
<li><p><strong>What is the main benefit of residual connections (ResNet)?</strong></p>
<ul class="simple">
<li><p>A) Fewer parameters</p></li>
<li><p>B) Faster inference</p></li>
<li><p>C) Solves vanishing gradient problem</p></li>
<li><p>D) Better accuracy on small datasets</p></li>
</ul>
</li>
<li><p><strong>When should you normalize your data?</strong></p>
<ul class="simple">
<li><p>A) Before train/test split</p></li>
<li><p>B) After train/test split</p></li>
<li><p>C) Only for images</p></li>
<li><p>D) Never</p></li>
</ul>
</li>
<li><p><strong>What is data augmentation?</strong></p>
<ul class="simple">
<li><p>A) Collecting more data</p></li>
<li><p>B) Applying transformations to create variations</p></li>
<li><p>C) Removing outliers</p></li>
<li><p>D) Normalizing features</p></li>
</ul>
</li>
<li><p><strong>How do you detect overfitting?</strong></p>
<ul class="simple">
<li><p>A) High training loss</p></li>
<li><p>B) Low test accuracy</p></li>
<li><p>C) Large gap between train and validation accuracy</p></li>
<li><p>D) Model trains too fast</p></li>
</ul>
</li>
</ol>
<p><strong>Answers</strong>: 1-B, 2-C, 3-C, 4-B, 5-B, 6-B, 7-C, 8-B, 9-B, 10-C</p>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading">#</a></h2>
<section id="architecture">
<h3>Architecture<a class="headerlink" href="#architecture" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚úÖ Neural networks learn hierarchical features through layers</p></li>
<li><p>‚úÖ Activation functions introduce non-linearity (ReLU most common)</p></li>
<li><p>‚úÖ Deeper networks can learn more complex patterns</p></li>
<li><p>‚úÖ Skip connections (ResNets) enable very deep networks</p></li>
</ul>
</section>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚úÖ Adam optimizer is the default choice for most tasks</p></li>
<li><p>‚úÖ Always use validation set to detect overfitting</p></li>
<li><p>‚úÖ Normalize inputs (critical for convergence)</p></li>
<li><p>‚úÖ Learning rate scheduling improves final accuracy</p></li>
</ul>
</section>
<section id="regularization">
<h3>Regularization<a class="headerlink" href="#regularization" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚úÖ Dropout prevents overfitting (0.2-0.5 typical)</p></li>
<li><p>‚úÖ Batch normalization stabilizes training</p></li>
<li><p>‚úÖ Data augmentation acts as regularization</p></li>
<li><p>‚úÖ Early stopping prevents overtraining</p></li>
</ul>
</section>
<section id="cnns">
<h3>CNNs<a class="headerlink" href="#cnns" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚úÖ CNNs exploit spatial structure in images</p></li>
<li><p>‚úÖ Convolutional layers detect local features</p></li>
<li><p>‚úÖ Pooling layers reduce spatial dimensions</p></li>
<li><p>‚úÖ Transfer learning leverages pre-trained models</p></li>
</ul>
</section>
<section id="production">
<h3>Production<a class="headerlink" href="#production" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚úÖ Save models with versioning</p></li>
<li><p>‚úÖ Document input/output specifications</p></li>
<li><p>‚úÖ Benchmark inference time</p></li>
<li><p>‚úÖ Monitor performance in production</p></li>
</ul>
</section>
</section>
<section id="pro-tips">
<h2>Pro Tips<a class="headerlink" href="#pro-tips" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Start simple, then add complexity</strong>: Begin with small network, add layers only if needed</p></li>
<li><p><strong>Always visualize training curves</strong>: Catch overfitting early</p></li>
<li><p><strong>Use callbacks</strong>: Early stopping, learning rate reduction, checkpointing</p></li>
<li><p><strong>Normalize inputs</strong>: Scale to [0,1] or standardize (Œº=0, œÉ=1)</p></li>
<li><p><strong>Batch size matters</strong>: 32-128 typical, larger = faster but less stable</p></li>
<li><p><strong>Transfer learning for small datasets</strong>: Don‚Äôt train from scratch if you have &lt;10k images</p></li>
<li><p><strong>GPU makes 10-100√ó difference</strong>: Use Colab/Kaggle for free GPUs</p></li>
<li><p><strong>Read error messages carefully</strong>: TensorFlow errors often suggest solutions</p></li>
<li><p><strong>Version control your models</strong>: Save each experiment with metadata</p></li>
<li><p><strong>Stay up to date</strong>: Deep learning evolves rapidly (follow papers/blogs)</p></li>
</ol>
<section id="debugging-checklist">
<h3>Debugging Checklist<a class="headerlink" href="#debugging-checklist" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>‚ö†Ô∏è Loss is NaN ‚Üí Learning rate too high or wrong activation</p></li>
<li><p>‚ö†Ô∏è Accuracy stuck at ~50% (binary) ‚Üí Model predicting one class</p></li>
<li><p>‚ö†Ô∏è Training loss doesn‚Äôt decrease ‚Üí Learning rate too low or data not normalized</p></li>
<li><p>‚ö†Ô∏è Perfect train accuracy, poor validation ‚Üí Overfitting (add regularization)</p></li>
<li><p>‚ö†Ô∏è Model trains very slowly ‚Üí Batch size too small or architecture too complex</p></li>
</ul>
</section>
</section>
<section id="what-s-next">
<h2>What‚Äôs Next?<a class="headerlink" href="#what-s-next" title="Link to this heading">#</a></h2>
<section id="continue-in-hard-track">
<h3>Continue in Hard Track:<a class="headerlink" href="#continue-in-hard-track" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Lesson 5</strong>: Advanced ML and NLP (transformers, BERT, GPT)</p></li>
<li><p><strong>Lesson 6</strong>: Computer Systems and Theory</p></li>
<li><p><strong>Lesson 8</strong>: Classic Problems (algorithms every engineer should know)</p></li>
</ul>
</section>
<section id="deepen-your-knowledge">
<h3>Deepen Your Knowledge:<a class="headerlink" href="#deepen-your-knowledge" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Stanford CS231n</strong>: Convolutional Neural Networks for Visual Recognition</p></li>
<li><p><strong><a class="reference external" href="http://Fast.ai">Fast.ai</a></strong>: Practical Deep Learning for Coders</p></li>
<li><p><strong>Deep Learning Book</strong>: Goodfellow, Bengio, Courville</p></li>
<li><p><strong>Papers With Code</strong>: Latest research implementations</p></li>
</ul>
</section>
<section id="practice-projects">
<h3>Practice Projects:<a class="headerlink" href="#practice-projects" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Image classification on your own dataset</p></li>
<li><p>Object detection (YOLO, Faster R-CNN)</p></li>
<li><p>Style transfer (neural artistic styles)</p></li>
<li><p>GANs (generate realistic images)</p></li>
<li><p>Deploy model to web app (Flask/FastAPI + TensorFlow.js)</p></li>
</ol>
<hr class="docutils" />
<p><strong>Congratulations!</strong> You now understand deep learning fundamentals and can build production-ready neural networks. Keep experimenting and building! üöÄ</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./hard"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="03_algorithms_and_complexity.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Hard Lesson 03: Algorithms and Complexity Analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="05_advanced_ml_and_nlp.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lesson 5: Advanced Machine Learning and NLP</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-context">Real-World Context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-ll-learn">What You‚Äôll Learn</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-neural-network-fundamentals">Part 1: Neural Network Fundamentals</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-neural-network">What is a Neural Network?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-components">Architecture Components</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mathematics">The Mathematics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-activation-functions">Part 2: Activation Functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-activation-functions">Common Activation Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-non-linearity-matters">Why Non-Linearity Matters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-building-your-first-neural-network">Part 3: Building Your First Neural Network</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-architecture">Understanding the Architecture</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-4-backpropagation-and-gradient-descent">Part 4: Backpropagation and Gradient Descent</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-neural-networks-learn">How Neural Networks Learn</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent-variants">Gradient Descent Variants</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">The Mathematics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-5-regularization-techniques">Part 5: Regularization Techniques</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-regularization-methods">Common Regularization Methods</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-6-convolutional-neural-networks-cnns">Part 6: Convolutional Neural Networks (CNNs)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-cnns-for-images">Why CNNs for Images?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn-layers">CNN Layers</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-7-transfer-learning">Part 7: Transfer Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-transfer-learning">Why Transfer Learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#popular-pre-trained-models">Popular Pre-trained Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-strategy">Fine-Tuning Strategy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-8-advanced-architectures">Part 8: Advanced Architectures</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#residual-connections-resnet">Residual Connections (ResNet)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-mechanisms-simplified">Attention Mechanisms (Simplified)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-9-training-best-practices">Part 9: Training Best Practices</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate-schedules">Learning Rate Schedules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation-images">Data Augmentation (Images)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-10-model-deployment">Part 10: Model Deployment</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading-models">Saving and Loading Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#production-checklist">Production Checklist</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-11-common-mistakes-and-how-to-avoid-them">Part 11: Common Mistakes and How to Avoid Them</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-12-exercises">Part 12: Exercises</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1-cifar-10-cnn">Exercise 1: CIFAR-10 CNN (‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-custom-activation-function">Exercise 2: Custom Activation Function (‚≠ê‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-transfer-learning">Exercise 3: Transfer Learning (‚≠ê‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-build-a-resnet-block">Exercise 4: Build a ResNet Block (‚≠ê‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-regularization-study">Exercise 5: Regularization Study (‚≠ê‚≠ê)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-6-model-interpretation">Exercise 6: Model Interpretation (‚≠ê‚≠ê‚≠ê‚≠ê)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#self-check-quiz">Self-Check Quiz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnns">CNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#production">Production</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pro-tips">Pro Tips</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#debugging-checklist">Debugging Checklist</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-s-next">What‚Äôs Next?</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continue-in-hard-track">Continue in Hard Track:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deepen-your-knowledge">Deepen Your Knowledge:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practice-projects">Practice Projects:</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mykolas Perevicius
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>