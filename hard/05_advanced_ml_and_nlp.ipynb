{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Advanced Machine Learning and NLP\n",
    "\n",
    "**Master ensemble methods, modern NLP, and production ML techniques**\n",
    "\n",
    "## Real-World Context\n",
    "This lesson covers the techniques used at top tech companies: ensemble methods power Kaggle winning solutions, transformers revolutionized NLP (GPT, BERT, ChatGPT), and hyperparameter optimization is crucial for production systems. You'll learn the same approaches used at Google, OpenAI, and Meta.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Ensemble Learning**: Bagging, boosting, stacking, and voting\n",
    "2. **Advanced Tree Methods**: XGBoost, LightGBM, CatBoost\n",
    "3. **NLP Fundamentals**: Tokenization, vectorization, TF-IDF\n",
    "4. **Word Embeddings**: Word2Vec, GloVe, contextual embeddings\n",
    "5. **Modern NLP**: Transformers, BERT, GPT architecture explained\n",
    "6. **Text Classification**: Sentiment analysis, topic modeling\n",
    "7. **Hyperparameter Optimization**: Grid search, random search, Bayesian optimization\n",
    "8. **Model Interpretability**: SHAP, LIME, feature importance\n",
    "9. **Production ML**: Deployment, monitoring, A/B testing\n",
    "\n",
    "**Prerequisites**: Python, scikit-learn, basic ML knowledge\n",
    "\n",
    "**Time**: 4-5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Ensemble Learning Fundamentals\n",
    "\n",
    "### Why Ensemble Methods?\n",
    "\n",
    "**\"Wisdom of crowds\"**: Multiple weak models can create a strong model.\n",
    "\n",
    "**Example**: Single decision tree = 85% accuracy, 100 trees = 95% accuracy\n",
    "\n",
    "### Three Main Approaches\n",
    "\n",
    "| Method | How It Works | Best For | Examples |\n",
    "|--------|--------------|----------|----------|\n",
    "| **Bagging** | Train models on random subsets (parallel) | Reduce variance | Random Forest |\n",
    "| **Boosting** | Train models sequentially, focus on errors | Reduce bias | XGBoost, AdaBoost |\n",
    "| **Stacking** | Use model outputs as features for meta-model | Maximum performance | Netflix Prize winner |\n",
    "\n",
    "### Bias-Variance Tradeoff\n",
    "\n",
    "```\n",
    "Error = Bias¬≤ + Variance + Irreducible Error\n",
    "```\n",
    "\n",
    "- **High bias**: Model too simple (underfit)\n",
    "- **High variance**: Model too complex (overfit)\n",
    "- **Bagging**: Reduces variance\n",
    "- **Boosting**: Reduces bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed):\n",
    "# !pip install scikit-learn xgboost lightgbm catboost nltk transformers torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier,\n",
    "    VotingClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üì¶ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=2000, \n",
    "    n_features=20, \n",
    "    n_informative=15, \n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.6, 0.4],  # Imbalanced classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {X_train.shape[0]} training, {X_test.shape[0]} test samples\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bagging Methods\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "**Algorithm:**\n",
    "1. Bootstrap samples from training data (sample with replacement)\n",
    "2. Train decision tree on each sample\n",
    "3. At each split, consider random subset of features\n",
    "4. Average predictions (regression) or vote (classification)\n",
    "\n",
    "**Key Parameters:**\n",
    "- `n_estimators`: Number of trees (100-1000)\n",
    "- `max_depth`: Maximum tree depth (control overfitting)\n",
    "- `max_features`: Features to consider per split (‚àön for classification)\n",
    "- `min_samples_split`: Minimum samples to split a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"üå≤ Training Random Forest...\\n\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"‚úÖ Random Forest Accuracy: {rf_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"üìä Top 5 Important Features:\")\n",
    "feature_importance = sorted(\n",
    "    enumerate(rf_model.feature_importances_), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True\n",
    ")[:5]\n",
    "\n",
    "for idx, (feat, importance) in enumerate(feature_importance, 1):\n",
    "    print(f\"  {idx}. Feature {feat}: {importance:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(10), sorted(rf_model.feature_importances_, reverse=True)[:10], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature Rank')\n",
    "plt.title('Top 10 Feature Importances (Random Forest)', fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Boosting Methods\n",
    "\n",
    "### Gradient Boosting\n",
    "\n",
    "**Algorithm:**\n",
    "1. Start with simple model (e.g., predicting mean)\n",
    "2. Calculate residuals (errors)\n",
    "3. Train new model to predict residuals\n",
    "4. Add scaled prediction to ensemble\n",
    "5. Repeat for N iterations\n",
    "\n",
    "**Mathematics:**\n",
    "```\n",
    "F‚ÇÄ(x) = initial prediction\n",
    "For m = 1 to M:\n",
    "    r‚Çò = y - F_{m-1}(x)           # Calculate residuals\n",
    "    h‚Çò = train_tree(r‚Çò)           # Fit to residuals\n",
    "    F‚Çò(x) = F_{m-1}(x) + Œ±¬∑h‚Çò(x)  # Update ensemble\n",
    "```\n",
    "\n",
    "### XGBoost vs LightGBM vs CatBoost\n",
    "\n",
    "| Library | Speed | Memory | GPU Support | Categorical Features | Use Case |\n",
    "|---------|-------|--------|-------------|----------------------|----------|\n",
    "| **XGBoost** | Medium | Medium | Yes | Manual encoding | General purpose |\n",
    "| **LightGBM** | Fast | Low | Yes | Manual encoding | Large datasets |\n",
    "| **CatBoost** | Slow | Medium | Yes | Native support | Categorical data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Boosting Methods\n",
    "boosting_models = {\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, \n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"‚ö° Comparing Boosting Algorithms...\\n\")\n",
    "\n",
    "for name, model in boosting_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    results[name] = acc\n",
    "    print(f\"  ‚úÖ Accuracy: {acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results.keys(), [v * 100 for v in results.values()], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Boosting Algorithms Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylim([85, 100])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (name, acc) in enumerate(results.items()):\n",
    "    plt.text(i, acc * 100 + 0.5, f'{acc * 100:.2f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüèÜ Best Model: XGBoost typically wins on structured data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Stacking and Voting\n",
    "\n",
    "### Voting Classifier\n",
    "\n",
    "**Hard Voting**: Majority vote (classification)\n",
    "```\n",
    "Model A: Class 1, Model B: Class 0, Model C: Class 1 ‚Üí Prediction: Class 1\n",
    "```\n",
    "\n",
    "**Soft Voting**: Average probabilities\n",
    "```\n",
    "Model A: [0.7, 0.3], Model B: [0.4, 0.6], Model C: [0.8, 0.2]\n",
    "Average: [0.63, 0.37] ‚Üí Prediction: Class 0\n",
    "```\n",
    "\n",
    "### Stacking\n",
    "\n",
    "**Level 0**: Base models train on data\n",
    "**Level 1**: Meta-model trains on base model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble\n",
    "print(\"üó≥Ô∏è  Building Voting Ensemble...\\n\")\n",
    "\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "        ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, eval_metric='logloss')),\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # Use probability averaging\n",
    ")\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "voting_pred = voting_model.predict(X_test)\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "\n",
    "print(\"üìä Results Comparison:\")\n",
    "print(f\"  Random Forest:     {rf_acc * 100:.2f}%\")\n",
    "print(f\"  XGBoost:           {results['XGBoost'] * 100:.2f}%\")\n",
    "print(f\"  Voting Ensemble:   {voting_acc * 100:.2f}%\")\n",
    "\n",
    "if voting_acc > max(rf_acc, results['XGBoost']):\n",
    "    print(\"\\n‚úÖ Ensemble improved over individual models!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Individual model performed better (not always the case)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Natural Language Processing Fundamentals\n",
    "\n",
    "### Text Preprocessing Pipeline\n",
    "\n",
    "1. **Tokenization**: Split into words/sentences\n",
    "2. **Lowercasing**: Normalize capitalization\n",
    "3. **Remove punctuation/special characters**\n",
    "4. **Remove stop words**: Common words (\"the\", \"is\", \"and\")\n",
    "5. **Stemming/Lemmatization**: Reduce to root form\n",
    "   - Stemming: \"running\" ‚Üí \"run\" (crude)\n",
    "   - Lemmatization: \"better\" ‚Üí \"good\" (linguistic)\n",
    "\n",
    "### Text Vectorization\n",
    "\n",
    "| Method | Description | Pros | Cons |\n",
    "|--------|-------------|------|------|\n",
    "| **Bag of Words** | Count word occurrences | Simple, fast | Ignores order, large sparse matrices |\n",
    "| **TF-IDF** | Weight by importance | Reduces common word impact | Still sparse, no semantics |\n",
    "| **Word2Vec** | Dense embeddings | Captures semantics | Requires large data |\n",
    "| **BERT** | Contextual embeddings | SOTA, context-aware | Slow, requires GPUs |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "\n",
    "# Sample movie reviews dataset\n",
    "movie_reviews = [\n",
    "    \"This movie was absolutely amazing! Best film I've ever seen.\",\n",
    "    \"Terrible movie, complete waste of time and money. Very disappointing.\",\n",
    "    \"Great acting and plot. Highly recommend this movie to everyone!\",\n",
    "    \"Boring and predictable. Would not watch again. Save your money.\",\n",
    "    \"Excellent cinematography and soundtrack. A true masterpiece!\",\n",
    "    \"Worst movie ever made. Don't waste your time on this garbage.\",\n",
    "    \"Absolutely loved it! The cast was perfect and story engaging.\",\n",
    "    \"Disappointing ending ruined the whole experience for me.\",\n",
    "    \"Brilliant direction and storytelling. Oscar-worthy performance!\",\n",
    "    \"Terrible acting and weak plot. Couldn't finish watching it.\"\n",
    "]\n",
    "\n",
    "sentiments = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1=positive, 0=negative\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Preprocess\n",
    "processed_reviews = [preprocess_text(review) for review in movie_reviews]\n",
    "\n",
    "print(\"üìù Original Review:\")\n",
    "print(f\"  {movie_reviews[0]}\\n\")\n",
    "print(\"üîß Preprocessed:\")\n",
    "print(f\"  {processed_reviews[0]}\\n\")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(processed_reviews)\n",
    "\n",
    "print(f\"TF-IDF Matrix Shape: {X_tfidf.shape}\")\n",
    "print(f\"Vocabulary Size: {len(tfidf.vocabulary_)}\")\n",
    "print(f\"\\nTop 15 Features: {list(tfidf.get_feature_names_out()[:15])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding TF-IDF\n",
    "\n",
    "**TF (Term Frequency):**\n",
    "```\n",
    "TF(word) = (Number of times word appears in document) / (Total words in document)\n",
    "```\n",
    "\n",
    "**IDF (Inverse Document Frequency):**\n",
    "```\n",
    "IDF(word) = log(Total documents / Documents containing word)\n",
    "```\n",
    "\n",
    "**TF-IDF Score:**\n",
    "```\n",
    "TF-IDF = TF √ó IDF\n",
    "```\n",
    "\n",
    "**Effect**: Common words (\"the\", \"is\") get low scores, rare important words get high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TF-IDF scores for a document\n",
    "doc_idx = 0\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "doc_vector = X_tfidf[doc_idx].toarray()[0]\n",
    "\n",
    "# Get top words\n",
    "top_indices = doc_vector.argsort()[-10:][::-1]\n",
    "top_words = [(feature_names[i], doc_vector[i]) for i in top_indices if doc_vector[i] > 0]\n",
    "\n",
    "if top_words:\n",
    "    words, scores = zip(*top_words)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(words)), scores, color='coral')\n",
    "    plt.yticks(range(len(words)), words)\n",
    "    plt.xlabel('TF-IDF Score')\n",
    "    plt.title(f'Top Words in Review: \"{movie_reviews[doc_idx][:50]}...\"', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüìä Observation: Important, rare words get higher scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Sentiment Analysis with Real Data\n",
    "\n",
    "Let's build a production-quality sentiment classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded dataset (simulating real-world data)\n",
    "positive_reviews = [\n",
    "    \"Excellent product, highly recommended!\",\n",
    "    \"Love it! Best purchase I've ever made.\",\n",
    "    \"Amazing quality and very fast delivery.\",\n",
    "    \"Perfect! Exactly what I was looking for.\",\n",
    "    \"Outstanding customer service and great product.\",\n",
    "    \"Fantastic! Exceeded all my expectations.\",\n",
    "    \"Wonderful experience from start to finish.\",\n",
    "    \"Brilliant product, works like a charm!\",\n",
    "    \"Superb quality, definitely worth the price.\",\n",
    "    \"Absolutely satisfied with my purchase!\"\n",
    "]\n",
    "\n",
    "negative_reviews = [\n",
    "    \"Terrible quality, very disappointed with purchase.\",\n",
    "    \"Complete waste of money, do not buy this.\",\n",
    "    \"Poor customer service and defective product.\",\n",
    "    \"Not as described at all, requesting full refund.\",\n",
    "    \"Awful experience, would give zero stars if possible.\",\n",
    "    \"Broke within days, cheap materials used.\",\n",
    "    \"Horrible product, does not work as advertised.\",\n",
    "    \"Disappointed and frustrated with this purchase.\",\n",
    "    \"Very poor quality, fell apart immediately.\",\n",
    "    \"Worst purchase ever, complete rip-off!\"\n",
    "]\n",
    "\n",
    "# Combine and create labels\n",
    "all_reviews = positive_reviews + negative_reviews\n",
    "labels = np.array([1] * len(positive_reviews) + [0] * len(negative_reviews))\n",
    "\n",
    "print(f\"üìä Dataset: {len(all_reviews)} reviews\")\n",
    "print(f\"  Positive: {sum(labels)}\")\n",
    "print(f\"  Negative: {len(labels) - sum(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sentiment analysis pipeline\n",
    "sentiment_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=100, stop_words='english')),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train\n",
    "sentiment_pipeline.fit(all_reviews, labels)\n",
    "\n",
    "# Test on new reviews\n",
    "test_reviews = [\n",
    "    \"This is absolutely fantastic and amazing!\",\n",
    "    \"Very poor quality and terrible customer service\",\n",
    "    \"Good value for money, happy with purchase\",\n",
    "    \"Disappointed with the product, not worth it\",\n",
    "    \"Excellent! Will definitely buy again!\"\n",
    "]\n",
    "\n",
    "predictions = sentiment_pipeline.predict(test_reviews)\n",
    "probabilities = sentiment_pipeline.predict_proba(test_reviews)\n",
    "\n",
    "print(\"\\nüéØ Sentiment Predictions:\\n\")\n",
    "for review, pred, prob in zip(test_reviews, predictions, probabilities):\n",
    "    sentiment = \"üòä Positive\" if pred == 1 else \"üòû Negative\"\n",
    "    confidence = max(prob) * 100\n",
    "    bar = '‚ñà' * int(confidence / 10)\n",
    "    print(f\"Review: \\\"{review}\\\"\")\n",
    "    print(f\"  ‚Üí {sentiment} ({confidence:.1f}% confident) {bar}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Word Embeddings\n",
    "\n",
    "### From Sparse to Dense Representations\n",
    "\n",
    "**Traditional (Sparse):**\n",
    "```\n",
    "\"king\"  ‚Üí [0, 0, 1, 0, 0, ..., 0]  (10,000 dimensions, mostly zeros)\n",
    "\"queen\" ‚Üí [0, 0, 0, 1, 0, ..., 0]\n",
    "```\n",
    "\n",
    "**Embeddings (Dense):**\n",
    "```\n",
    "\"king\"  ‚Üí [0.2, -0.5, 0.8, ..., 0.3]  (300 dimensions, all meaningful)\n",
    "\"queen\" ‚Üí [0.1, -0.6, 0.7, ..., 0.4]  (semantically similar)\n",
    "```\n",
    "\n",
    "### Word2Vec Magic\n",
    "\n",
    "Famous equation:\n",
    "```\n",
    "king - man + woman ‚âà queen\n",
    "```\n",
    "\n",
    "This works because embeddings capture semantic relationships!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddings with Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Prepare text data\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(all_reviews)\n",
    "\n",
    "# Convert to sequences\n",
    "sequences = tokenizer.texts_to_sequences(all_reviews)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=20, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Vocabulary size: {len(tokenizer.word_index)}\")\n",
    "print(f\"Padded sequence shape: {padded_sequences.shape}\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"  Original: '{all_reviews[0]}'\")\n",
    "print(f\"  Tokenized: {sequences[0]}\")\n",
    "print(f\"  Padded: {padded_sequences[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model with embeddings\n",
    "embedding_dim = 32\n",
    "vocab_size = min(1000, len(tokenizer.word_index) + 1)\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    # Embedding layer: Converts word indices to dense vectors\n",
    "    Embedding(vocab_size, embedding_dim, input_length=20, name='embedding'),\n",
    "    \n",
    "    # Bidirectional LSTM: Processes text forward and backward\n",
    "    Bidirectional(LSTM(64, return_sequences=True), name='bi_lstm_1'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    Bidirectional(LSTM(32), name='bi_lstm_2'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense layers\n",
    "    Dense(64, activation='relu', name='dense_1'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', name='output')\n",
    "], name='sentiment_lstm')\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lstm_model.summary()\n",
    "print(f\"\\nüìä Total parameters: {lstm_model.count_params():,}\")\n",
    "print(f\"üìä Embedding matrix shape: (vocab={vocab_size}, dim={embedding_dim})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding LSTM\n",
    "\n",
    "**Why LSTM for text?**\n",
    "- Captures long-range dependencies\n",
    "- Handles variable-length sequences\n",
    "- Understands context\n",
    "\n",
    "**LSTM Cell:**\n",
    "- **Forget gate**: What to forget from memory\n",
    "- **Input gate**: What new information to store\n",
    "- **Output gate**: What to output\n",
    "\n",
    "**Bidirectional**: Reads text forward and backward for better context understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Introduction to Transformers\n",
    "\n",
    "### The Revolution: Attention is All You Need (2017)\n",
    "\n",
    "**Before Transformers:**\n",
    "- RNNs/LSTMs: Sequential processing (slow)\n",
    "- Limited context window\n",
    "- Hard to parallelize\n",
    "\n",
    "**Transformers:**\n",
    "- Parallel processing (fast!)\n",
    "- Unlimited context (practically)\n",
    "- Attention mechanism: Focus on relevant words\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "```\n",
    "Input Text ‚Üí Tokenization ‚Üí Embeddings ‚Üí Positional Encoding\n",
    "                                ‚Üì\n",
    "                    Multi-Head Self-Attention\n",
    "                                ‚Üì\n",
    "                    Feed-Forward Network\n",
    "                                ‚Üì\n",
    "                            Repeat N times\n",
    "                                ‚Üì\n",
    "                            Output\n",
    "```\n",
    "\n",
    "### Self-Attention Simplified\n",
    "\n",
    "**Example**: \"The animal didn't cross the street because **it** was too tired.\"\n",
    "\n",
    "**Question**: What does \"it\" refer to?\n",
    "\n",
    "**Attention weights**:\n",
    "- \"it\" ‚Üí \"animal\": 0.8 ‚úÖ\n",
    "- \"it\" ‚Üí \"street\": 0.1\n",
    "- \"it\" ‚Üí \"cross\": 0.1\n",
    "\n",
    "The model learns to focus on \"animal\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major Transformer Models\n",
    "\n",
    "| Model | Type | Parameters | Training Data | Use Case |\n",
    "|-------|------|------------|---------------|----------|\n",
    "| **BERT** | Encoder-only | 110M - 340M | Books + Wikipedia | Classification, NER, QA |\n",
    "| **GPT-3/4** | Decoder-only | 175B+ | Internet text | Text generation, ChatGPT |\n",
    "| **T5** | Encoder-Decoder | 60M - 11B | C4 dataset | Translation, summarization |\n",
    "| **RoBERTa** | Encoder-only | 125M - 355M | Improved BERT data | Better than BERT |\n",
    "| **BART** | Encoder-Decoder | 140M - 400M | Denoising | Summarization |\n",
    "\n",
    "### BERT vs GPT\n",
    "\n",
    "**BERT (Bidirectional)**:\n",
    "- Reads text in both directions\n",
    "- Great for understanding (classification, QA)\n",
    "- Pre-training: Masked Language Modeling\n",
    "  - Input: \"The [MASK] sat on the mat\"\n",
    "  - Task: Predict [MASK] = \"cat\"\n",
    "\n",
    "**GPT (Autoregressive)**:\n",
    "- Reads text left-to-right only\n",
    "- Great for generation (writing, chat)\n",
    "- Pre-training: Next Token Prediction\n",
    "  - Input: \"The cat sat on the\"\n",
    "  - Task: Predict next word = \"mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Attention Mechanism (educational)\n",
    "def simple_attention(query, keys, values):\n",
    "    \"\"\"\n",
    "    Simplified attention mechanism.\n",
    "    \n",
    "    Args:\n",
    "        query: What we're looking for\n",
    "        keys: What's available\n",
    "        values: Actual information\n",
    "    \n",
    "    Returns:\n",
    "        Weighted combination of values\n",
    "    \"\"\"\n",
    "    # Calculate attention scores\n",
    "    scores = np.dot(query, keys.T)  # Dot product\n",
    "    \n",
    "    # Apply softmax to get weights (sum to 1)\n",
    "    weights = np.exp(scores) / np.sum(np.exp(scores))\n",
    "    \n",
    "    # Weighted sum of values\n",
    "    output = np.dot(weights, values)\n",
    "    \n",
    "    return output, weights\n",
    "\n",
    "# Example: Sentence \"I love NLP\"\n",
    "# Simple word embeddings (normally 300-768 dimensions)\n",
    "embeddings = np.array([\n",
    "    [0.1, 0.2, 0.3],  # \"I\"\n",
    "    [0.4, 0.5, 0.6],  # \"love\"\n",
    "    [0.7, 0.8, 0.9],  # \"NLP\"\n",
    "])\n",
    "\n",
    "# Calculate attention for word \"love\" (index 1)\n",
    "query = embeddings[1]\n",
    "keys = embeddings\n",
    "values = embeddings\n",
    "\n",
    "output, weights = simple_attention(query, keys, values)\n",
    "\n",
    "print(\"üîç Attention Mechanism Demo\\n\")\n",
    "print(\"Query word: 'love'\")\n",
    "print(f\"\\nAttention weights:\")\n",
    "words = [\"I\", \"love\", \"NLP\"]\n",
    "for word, weight in zip(words, weights):\n",
    "    bar = '‚ñà' * int(weight * 50)\n",
    "    print(f\"  {word:6s}: {weight:.3f} {bar}\")\n",
    "\n",
    "print(f\"\\nContext-aware representation: {output}\")\n",
    "print(\"\\nüí° The model learned which words to focus on!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Hyperparameter Optimization\n",
    "\n",
    "### Strategies\n",
    "\n",
    "| Method | How It Works | Speed | Effectiveness |\n",
    "|--------|--------------|-------|---------------|\n",
    "| **Manual** | Try values by hand | Slow | Poor |\n",
    "| **Grid Search** | Try all combinations | Very slow | Good |\n",
    "| **Random Search** | Random sampling | Medium | Good |\n",
    "| **Bayesian Optimization** | Smart sampling | Fast | Best |\n",
    "| **Hyperband** | Adaptive allocation | Fast | Best |\n",
    "\n",
    "### Search Space Example\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],     # 3 options\n",
    "    'max_depth': [5, 10, 15, None],     # 4 options\n",
    "    'learning_rate': [0.01, 0.1, 0.3]   # 3 options\n",
    "}\n",
    "# Grid Search: 3 √ó 4 √ó 3 = 36 combinations!\n",
    "# Random Search: Sample N combinations (e.g., 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print(\"üîç Hyperparameter Tuning Comparison\\n\")\n",
    "\n",
    "# Random Search (faster)\n",
    "print(\"‚ö° Running Random Search...\")\n",
    "rf_random = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_random,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,  # Try 10 random combinations\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"‚úÖ Random Search Complete\")\n",
    "print(f\"  Best Score: {random_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"  Best Params: {random_search.best_params_}\")\n",
    "\n",
    "# Test on holdout set\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"  Test Accuracy: {test_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Model Interpretation with SHAP\n",
    "\n",
    "### Why Interpretability Matters\n",
    "\n",
    "- **Trust**: Understand why model makes predictions\n",
    "- **Debugging**: Find biases and errors\n",
    "- **Compliance**: Regulations (GDPR, healthcare)\n",
    "- **Science**: Discover insights\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "**Idea**: How much does each feature contribute to prediction?\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Base prediction: 0.5\n",
    "Feature 'price':     +0.2  (pushes toward positive)\n",
    "Feature 'rating':    +0.15 (pushes toward positive)\n",
    "Feature 'shipping': -0.05 (pushes toward negative)\n",
    "Final prediction:    0.8   (positive)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Interpretation (Feature Importance)\n",
    "print(\"üìä Feature Importance Analysis\\n\")\n",
    "\n",
    "# Get feature importances from best model\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:10]  # Top 10\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Top 10 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.bar(range(10), importances[indices], color='steelblue')\n",
    "plt.xticks(range(10), [f'Feature {i}' for i in indices], rotation=45)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 Features:\")\n",
    "for rank, idx in enumerate(indices[:5], 1):\n",
    "    print(f\"  {rank}. Feature {idx}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Production ML Considerations\n",
    "\n",
    "### Deployment Checklist\n",
    "\n",
    "- ‚úÖ **Model Serialization**: Save with pickle/joblib\n",
    "- ‚úÖ **API Endpoint**: Flask/FastAPI wrapper\n",
    "- ‚úÖ **Input Validation**: Check data types, ranges\n",
    "- ‚úÖ **Monitoring**: Track accuracy, latency, errors\n",
    "- ‚úÖ **Versioning**: Model version control\n",
    "- ‚úÖ **A/B Testing**: Compare models in production\n",
    "- ‚úÖ **Rollback Plan**: Revert to previous version\n",
    "- ‚úÖ **Documentation**: API docs, model card\n",
    "\n",
    "### Model Monitoring\n",
    "\n",
    "**Key Metrics:**\n",
    "- Prediction latency (p50, p95, p99)\n",
    "- Accuracy over time\n",
    "- Data drift detection\n",
    "- Error rate\n",
    "- Traffic volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for production\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('production_models', exist_ok=True)\n",
    "\n",
    "# Save best model\n",
    "model_path = 'production_models/best_rf_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"‚úÖ Model saved to {model_path}\")\n",
    "\n",
    "# Save preprocessing pipeline\n",
    "pipeline_path = 'production_models/sentiment_pipeline.pkl'\n",
    "joblib.dump(sentiment_pipeline, pipeline_path)\n",
    "print(f\"‚úÖ Sentiment pipeline saved to {pipeline_path}\")\n",
    "\n",
    "# File sizes\n",
    "model_size = os.path.getsize(model_path) / 1024  # KB\n",
    "pipeline_size = os.path.getsize(pipeline_path) / 1024\n",
    "\n",
    "print(f\"\\nüì¶ Model sizes:\")\n",
    "print(f\"  RF Model: {model_size:.1f} KB\")\n",
    "print(f\"  Sentiment Pipeline: {pipeline_size:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and use model (production simulation)\n",
    "loaded_model = joblib.load(model_path)\n",
    "\n",
    "# Make prediction\n",
    "sample_data = X_test[:5]\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "probabilities = loaded_model.predict_proba(sample_data)\n",
    "\n",
    "print(\"üöÄ Production Model Inference:\\n\")\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    confidence = max(prob) * 100\n",
    "    print(f\"Sample {i+1}: Class {pred} (confidence: {confidence:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded and working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Exercises\n",
    "\n",
    "### Exercise 1: Ensemble Comparison (‚≠ê‚≠ê)\n",
    "\n",
    "Compare ensemble methods on a real dataset:\n",
    "1. Load the Iris or Wine dataset\n",
    "2. Train 5 different models:\n",
    "   - Single Decision Tree\n",
    "   - Random Forest\n",
    "   - XGBoost\n",
    "   - AdaBoost\n",
    "   - Voting Ensemble (combine RF, XGB, LogReg)\n",
    "3. Use cross-validation for all\n",
    "4. Plot comparison bar chart\n",
    "5. Identify which performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Hint: from sklearn.datasets import load_wine\n",
    "# Hint: Use cross_val_score for each model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Advanced Text Classification (‚≠ê‚≠ê‚≠ê)\n",
    "\n",
    "Build a multi-class text classifier:\n",
    "1. Create/find a dataset with 3+ categories (news topics, product categories, etc.)\n",
    "2. Implement preprocessing: lowercasing, stop words, stemming\n",
    "3. Compare vectorization methods:\n",
    "   - Bag of Words (CountVectorizer)\n",
    "   - TF-IDF\n",
    "   - Word embeddings + LSTM\n",
    "4. Train classifiers on each\n",
    "5. Plot confusion matrix for best model\n",
    "6. Identify misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# Hint: Use 20 Newsgroups dataset: fetch_20newsgroups()\n",
    "# Hint: from nltk.stem import PorterStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Hyperparameter Tuning (‚≠ê‚≠ê)\n",
    "\n",
    "Optimize XGBoost with different search strategies:\n",
    "1. Define comprehensive parameter grid\n",
    "2. Run Grid Search (small grid)\n",
    "3. Run Random Search (larger space, 20 iterations)\n",
    "4. Compare time taken and best scores\n",
    "5. Plot search history (score vs iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# Hint: Track time with time.time()\n",
    "# Hint: Access cv_results_ for search history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: LSTM Sentiment Analysis (‚≠ê‚≠ê‚≠ê)\n",
    "\n",
    "Build LSTM model from scratch:\n",
    "1. Collect larger sentiment dataset (IMDB or custom)\n",
    "2. Implement full preprocessing pipeline\n",
    "3. Build LSTM with:\n",
    "   - Embedding layer (trainable)\n",
    "   - 2 LSTM layers\n",
    "   - Dropout regularization\n",
    "   - Dense output\n",
    "4. Train with early stopping\n",
    "5. Plot training curves\n",
    "6. Compare with traditional ML (Naive Bayes, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n",
    "# Hint: keras.datasets.imdb.load_data()\n",
    "# Hint: Use callbacks=[EarlyStopping()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Model Interpretability (‚≠ê‚≠ê‚≠ê‚≠ê)\n",
    "\n",
    "Analyze model decisions:\n",
    "1. Train Random Forest or XGBoost\n",
    "2. Extract feature importances\n",
    "3. Visualize top 20 features\n",
    "4. For text model: Find most important words per class\n",
    "5. **Bonus**: Implement LIME for local explanations\n",
    "6. Compare global vs local importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Your code here\n",
    "# Hint: !pip install lime\n",
    "# Hint: from lime.lime_text import LimeTextExplainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Production API (‚≠ê‚≠ê‚≠ê)\n",
    "\n",
    "Build deployment-ready prediction service:\n",
    "1. Save trained model with joblib\n",
    "2. Create Flask/FastAPI endpoint\n",
    "3. Implement input validation\n",
    "4. Add error handling\n",
    "5. Return predictions with confidence scores\n",
    "6. **Bonus**: Add simple logging\n",
    "7. Test with curl/Postman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Your code here\n",
    "# Hint: from flask import Flask, request, jsonify\n",
    "# Hint: Validate input before prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Check Quiz\n",
    "\n",
    "Test your understanding:\n",
    "\n",
    "1. **What is the main difference between bagging and boosting?**\n",
    "   - A) Bagging is faster\n",
    "   - B) Bagging trains models in parallel, boosting sequentially\n",
    "   - C) Boosting uses fewer models\n",
    "   - D) No difference\n",
    "\n",
    "2. **Which boosting algorithm is fastest for large datasets?**\n",
    "   - A) AdaBoost\n",
    "   - B) Gradient Boosting\n",
    "   - C) LightGBM\n",
    "   - D) Random Forest\n",
    "\n",
    "3. **What does TF-IDF stand for?**\n",
    "   - A) Text Frequency - Important Document Frequency\n",
    "   - B) Term Frequency - Inverse Document Frequency\n",
    "   - C) Total Frequency - Indexed Document Frequency\n",
    "   - D) Token Frequency - Information Document Frequency\n",
    "\n",
    "4. **What is the main advantage of word embeddings over TF-IDF?**\n",
    "   - A) Faster computation\n",
    "   - B) Captures semantic relationships\n",
    "   - C) Requires less data\n",
    "   - D) Always performs better\n",
    "\n",
    "5. **What is the key innovation of transformers?**\n",
    "   - A) Recurrent connections\n",
    "   - B) Convolutional layers\n",
    "   - C) Self-attention mechanism\n",
    "   - D) Dropout regularization\n",
    "\n",
    "6. **Which model is best for text generation?**\n",
    "   - A) BERT\n",
    "   - B) GPT\n",
    "   - C) Random Forest\n",
    "   - D) Naive Bayes\n",
    "\n",
    "7. **What is the purpose of hyperparameter tuning?**\n",
    "   - A) Train model faster\n",
    "   - B) Reduce overfitting only\n",
    "   - C) Find optimal model configuration\n",
    "   - D) Increase model size\n",
    "\n",
    "8. **Which search method is most efficient?**\n",
    "   - A) Manual\n",
    "   - B) Grid Search\n",
    "   - C) Random Search\n",
    "   - D) Bayesian Optimization\n",
    "\n",
    "9. **Why is model interpretability important?**\n",
    "   - A) Makes models faster\n",
    "   - B) Increases accuracy\n",
    "   - C) Builds trust and enables debugging\n",
    "   - D) Reduces model size\n",
    "\n",
    "10. **What should you monitor in production?**\n",
    "    - A) Accuracy only\n",
    "    - B) Latency only\n",
    "    - C) Accuracy, latency, and data drift\n",
    "    - D) Nothing after deployment\n",
    "\n",
    "**Answers**: 1-B, 2-C, 3-B, 4-B, 5-C, 6-B, 7-C, 8-D, 9-C, 10-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Ensemble Learning\n",
    "- ‚úÖ Ensemble methods combine multiple models for better performance\n",
    "- ‚úÖ Bagging reduces variance (Random Forest)\n",
    "- ‚úÖ Boosting reduces bias (XGBoost, LightGBM)\n",
    "- ‚úÖ XGBoost wins most Kaggle competitions\n",
    "\n",
    "### NLP Fundamentals\n",
    "- ‚úÖ Text preprocessing is critical (tokenization, cleaning, normalization)\n",
    "- ‚úÖ TF-IDF weights words by importance\n",
    "- ‚úÖ Word embeddings capture semantic meaning\n",
    "- ‚úÖ LSTMs handle sequential text data\n",
    "\n",
    "### Modern NLP\n",
    "- ‚úÖ Transformers revolutionized NLP (parallel processing)\n",
    "- ‚úÖ Self-attention focuses on relevant context\n",
    "- ‚úÖ BERT for understanding, GPT for generation\n",
    "- ‚úÖ Pre-trained models save time and data\n",
    "\n",
    "### Production ML\n",
    "- ‚úÖ Hyperparameter tuning improves performance\n",
    "- ‚úÖ Model interpretability builds trust\n",
    "- ‚úÖ Monitor models in production\n",
    "- ‚úÖ Version control models like code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pro Tips\n",
    "\n",
    "1. **Start with XGBoost**: It works well out-of-the-box for structured data\n",
    "2. **Always try ensembles**: Combining models rarely hurts\n",
    "3. **Text preprocessing matters**: Clean data = better results\n",
    "4. **Use pre-trained embeddings**: Don't train Word2Vec from scratch with small data\n",
    "5. **Fine-tune transformers**: BERT/GPT transfer learning beats training from scratch\n",
    "6. **Random search before grid**: Sample 10-20 random configs, then refine\n",
    "7. **Cross-validation always**: Never trust single train/test split\n",
    "8. **Monitor data drift**: Production data changes over time\n",
    "9. **Start simple**: Logistic Regression baseline, then add complexity\n",
    "10. **Document everything**: Model cards, API docs, decision rationale\n",
    "\n",
    "### Common Mistakes\n",
    "- ‚ùå Skipping text preprocessing\n",
    "- ‚ùå Not removing stop words for classification\n",
    "- ‚ùå Training Word2Vec on small datasets\n",
    "- ‚ùå Using BERT for generation (use GPT)\n",
    "- ‚ùå Grid searching huge spaces\n",
    "- ‚ùå Not validating production inputs\n",
    "- ‚ùå Ignoring class imbalance\n",
    "- ‚ùå Overfitting to validation set\n",
    "\n",
    "### Debug Checklist\n",
    "- ‚ö†Ô∏è Low accuracy ‚Üí Check preprocessing, try ensemble\n",
    "- ‚ö†Ô∏è High variance ‚Üí Add regularization, more data\n",
    "- ‚ö†Ô∏è High bias ‚Üí More complex model, better features\n",
    "- ‚ö†Ô∏è Slow inference ‚Üí Reduce model size, optimize code\n",
    "- ‚ö†Ô∏è Production accuracy drops ‚Üí Data drift, retrain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "### Continue in Hard Track:\n",
    "- **Lesson 6**: Computer Systems and Theory\n",
    "- **Lesson 7**: Project Ideas (apply everything!)\n",
    "- **Lesson 8**: Classic Problems (interview preparation)\n",
    "\n",
    "### Deepen Your NLP Knowledge:\n",
    "- **Hugging Face Transformers**: Pre-trained models library\n",
    "- **fast.ai NLP**: Practical deep learning for text\n",
    "- **spaCy**: Industrial-strength NLP\n",
    "- **Papers With Code**: Latest NLP research\n",
    "\n",
    "### Practice Projects:\n",
    "1. Sentiment analysis on Twitter data\n",
    "2. News article classifier (Reuters, 20 Newsgroups)\n",
    "3. Chatbot with GPT-2/3\n",
    "4. Named Entity Recognition (NER)\n",
    "5. Text summarization with T5\n",
    "6. Deploy ML API with FastAPI\n",
    "\n",
    "### Resources:\n",
    "- **Books**: \"Speech and Language Processing\" (Jurafsky & Martin)\n",
    "- **Courses**: Stanford CS224N (NLP with Deep Learning)\n",
    "- **Competitions**: Kaggle NLP challenges\n",
    "- **Tools**: Weights & Biases (experiment tracking)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You now understand advanced ML and modern NLP. You can build ensemble models, process text, and deploy production systems! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
