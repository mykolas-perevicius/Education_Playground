{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Level: Advanced Project Ideas & Implementation Guide\n",
    "\n",
    "## Real-World Context\n",
    "\n",
    "**The Problem**: Many developers struggle to move from tutorials to building real, production-quality systems. This notebook bridges that gap by providing detailed project blueprints with architectural guidance, starter code, and implementation strategies.\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Portfolio Development**: These projects demonstrate senior-level engineering skills\n",
    "- **System Design Experience**: Learn to architect complex, scalable systems\n",
    "- **Production Readiness**: Focus on testing, deployment, monitoring, and maintenance\n",
    "- **Interview Preparation**: Many projects mirror real interview system design questions\n",
    "- **Career Growth**: Building these projects develops skills needed for senior/staff engineer roles\n",
    "\n",
    "**What You'll Learn**:\n",
    "- How to design and architect complex systems from scratch\n",
    "- Production-quality code patterns and best practices\n",
    "- Testing strategies for distributed and ML systems\n",
    "- Deployment, monitoring, and operational considerations\n",
    "- Trade-off analysis in system design decisions\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "\n",
    "All projects should include:\n",
    "- **Clean Architecture**: Well-organized, modular code with clear separation of concerns\n",
    "- **Comprehensive Testing**: Unit tests, integration tests, end-to-end tests (target 80%+ coverage)\n",
    "- **Documentation**: README, API docs, architecture diagrams, setup guides\n",
    "- **Error Handling**: Robust exception management, logging, and recovery mechanisms\n",
    "- **Performance**: Optimized algorithms, caching, async where appropriate\n",
    "- **Version Control**: Git with meaningful commits, branching strategy, PR workflow\n",
    "- **CI/CD**: Automated testing and deployment pipeline\n",
    "- **Monitoring**: Metrics, logging, and observability\n",
    "- **Security**: Authentication, authorization, input validation, encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Build Your Own Web Framework\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐⭐ (Advanced)\n",
    "\n",
    "**Skills**: Advanced Python, networking, HTTP protocol, decorators, metaclasses, WSGI\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "Create a minimal web framework similar to Flask/FastAPI from scratch. This project teaches the internals of web frameworks and HTTP.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "┌─────────────┐\n",
    "│   Client    │\n",
    "└──────┬──────┘\n",
    "       │ HTTP Request\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│  WSGI Server        │ (Gunicorn/uWSGI)\n",
    "└──────┬──────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│  Your Framework     │\n",
    "│  ┌───────────────┐  │\n",
    "│  │  Middleware   │  │ ← Request Pipeline\n",
    "│  ├───────────────┤  │\n",
    "│  │  Router       │  │ ← URL → Handler Mapping\n",
    "│  ├───────────────┤  │\n",
    "│  │  Request      │  │ ← Parse HTTP Request\n",
    "│  ├───────────────┤  │\n",
    "│  │  Response     │  │ ← Build HTTP Response\n",
    "│  ├───────────────┤  │\n",
    "│  │  Templates    │  │ ← Render HTML\n",
    "│  └───────────────┘  │\n",
    "└──────┬──────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│  Your Application   │ (User Code)\n",
    "└─────────────────────┘\n",
    "```\n",
    "\n",
    "### Core Features\n",
    "\n",
    "1. **HTTP Request Parsing**: Parse raw HTTP requests into structured objects\n",
    "2. **Routing System**: Map URLs to handler functions using decorators\n",
    "3. **Request/Response Objects**: Clean abstractions for HTTP\n",
    "4. **Middleware Support**: Request/response processing pipeline\n",
    "5. **Template Rendering**: Simple template engine\n",
    "6. **Session Management**: Cookie-based sessions\n",
    "\n",
    "### Implementation Roadmap\n",
    "\n",
    "**Phase 1: Basic Request/Response (Week 1)**\n",
    "- Implement Request and Response classes\n",
    "- Parse HTTP headers, query params, form data\n",
    "- WSGI interface\n",
    "\n",
    "**Phase 2: Routing (Week 2)**\n",
    "- URL pattern matching (static and dynamic routes)\n",
    "- Decorator-based route registration\n",
    "- HTTP method handling (GET, POST, PUT, DELETE)\n",
    "\n",
    "**Phase 3: Middleware & Advanced Features (Week 3)**\n",
    "- Middleware pipeline\n",
    "- Exception handling\n",
    "- Static file serving\n",
    "- Template rendering\n",
    "\n",
    "**Phase 4: Production Features (Week 4)**\n",
    "- Session management\n",
    "- CORS support\n",
    "- Rate limiting\n",
    "- Testing and documentation\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "- Deep understanding of HTTP protocol and WSGI\n",
    "- Advanced Python decorators and metaprogramming\n",
    "- Request/response lifecycle in web frameworks\n",
    "- Middleware pattern and request pipelines\n",
    "- Security considerations (CSRF, XSS, injection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter Code: Minimal Web Framework Core\n",
    "\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import parse_qs\n",
    "from typing import Callable, Dict, List, Any, Optional\n",
    "\n",
    "class Request:\n",
    "    \"\"\"Represents an HTTP request.\"\"\"\n",
    "    \n",
    "    def __init__(self, environ: dict):\n",
    "        self.environ = environ\n",
    "        self.method = environ['REQUEST_METHOD']\n",
    "        self.path = environ['PATH_INFO']\n",
    "        self.query_string = environ.get('QUERY_STRING', '')\n",
    "        \n",
    "        # Parse query parameters\n",
    "        self.args = parse_qs(self.query_string)\n",
    "        # Flatten single-value lists\n",
    "        self.args = {k: v[0] if len(v) == 1 else v for k, v in self.args.items()}\n",
    "        \n",
    "        # Parse request body\n",
    "        self._parse_body()\n",
    "        \n",
    "        # Parse headers\n",
    "        self.headers = self._parse_headers()\n",
    "    \n",
    "    def _parse_headers(self) -> Dict[str, str]:\n",
    "        \"\"\"Extract HTTP headers from WSGI environ.\"\"\"\n",
    "        headers = {}\n",
    "        for key, value in self.environ.items():\n",
    "            if key.startswith('HTTP_'):\n",
    "                header_name = key[5:].replace('_', '-').title()\n",
    "                headers[header_name] = value\n",
    "        return headers\n",
    "    \n",
    "    def _parse_body(self):\n",
    "        \"\"\"Parse request body based on content type.\"\"\"\n",
    "        content_length = int(self.environ.get('CONTENT_LENGTH', 0))\n",
    "        if content_length == 0:\n",
    "            self.json = None\n",
    "            self.form = {}\n",
    "            return\n",
    "        \n",
    "        body = self.environ['wsgi.input'].read(content_length).decode('utf-8')\n",
    "        content_type = self.environ.get('CONTENT_TYPE', '')\n",
    "        \n",
    "        if 'application/json' in content_type:\n",
    "            self.json = json.loads(body)\n",
    "            self.form = {}\n",
    "        elif 'application/x-www-form-urlencoded' in content_type:\n",
    "            self.form = parse_qs(body)\n",
    "            self.form = {k: v[0] if len(v) == 1 else v for k, v in self.form.items()}\n",
    "            self.json = None\n",
    "        else:\n",
    "            self.json = None\n",
    "            self.form = {}\n",
    "\n",
    "\n",
    "class Response:\n",
    "    \"\"\"Represents an HTTP response.\"\"\"\n",
    "    \n",
    "    def __init__(self, body: str = '', status: int = 200, headers: Optional[Dict] = None):\n",
    "        self.body = body\n",
    "        self.status = status\n",
    "        self.headers = headers or {}\n",
    "        \n",
    "        # Set default content type\n",
    "        if 'Content-Type' not in self.headers:\n",
    "            self.headers['Content-Type'] = 'text/html; charset=utf-8'\n",
    "    \n",
    "    def json_response(self, data: Any) -> 'Response':\n",
    "        \"\"\"Create a JSON response.\"\"\"\n",
    "        self.body = json.dumps(data)\n",
    "        self.headers['Content-Type'] = 'application/json'\n",
    "        return self\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Make response iterable for WSGI.\"\"\"\n",
    "        yield self.body.encode('utf-8')\n",
    "\n",
    "\n",
    "class Router:\n",
    "    \"\"\"URL routing system.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.routes: Dict[str, Dict[str, Callable]] = {}\n",
    "    \n",
    "    def add_route(self, path: str, method: str, handler: Callable):\n",
    "        \"\"\"Register a route.\"\"\"\n",
    "        if path not in self.routes:\n",
    "            self.routes[path] = {}\n",
    "        self.routes[path][method] = handler\n",
    "    \n",
    "    def match(self, path: str, method: str) -> Optional[tuple]:\n",
    "        \"\"\"Match a path to a handler. Returns (handler, params) or None.\"\"\"\n",
    "        # Try exact match first\n",
    "        if path in self.routes and method in self.routes[path]:\n",
    "            return self.routes[path][method], {}\n",
    "        \n",
    "        # Try pattern matching for dynamic routes like /users/<id>\n",
    "        for route_path, methods in self.routes.items():\n",
    "            if method not in methods:\n",
    "                continue\n",
    "            \n",
    "            # Convert route pattern to regex\n",
    "            pattern = re.sub(r'<(\\w+)>', r'(?P<\\1>[^/]+)', route_path)\n",
    "            match = re.fullmatch(pattern, path)\n",
    "            \n",
    "            if match:\n",
    "                return methods[method], match.groupdict()\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "class WebFramework:\n",
    "    \"\"\"Minimal web framework.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.router = Router()\n",
    "        self.middleware: List[Callable] = []\n",
    "    \n",
    "    def route(self, path: str, methods: List[str] = None):\n",
    "        \"\"\"Decorator for registering routes.\"\"\"\n",
    "        if methods is None:\n",
    "            methods = ['GET']\n",
    "        \n",
    "        def decorator(handler: Callable) -> Callable:\n",
    "            for method in methods:\n",
    "                self.router.add_route(path, method, handler)\n",
    "            return handler\n",
    "        \n",
    "        return decorator\n",
    "    \n",
    "    def use(self, middleware: Callable):\n",
    "        \"\"\"Add middleware to the pipeline.\"\"\"\n",
    "        self.middleware.append(middleware)\n",
    "    \n",
    "    def __call__(self, environ: dict, start_response: Callable):\n",
    "        \"\"\"WSGI application callable.\"\"\"\n",
    "        request = Request(environ)\n",
    "        \n",
    "        # Apply middleware\n",
    "        for mw in self.middleware:\n",
    "            result = mw(request)\n",
    "            if isinstance(result, Response):\n",
    "                return self._send_response(result, start_response)\n",
    "        \n",
    "        # Route the request\n",
    "        match = self.router.match(request.path, request.method)\n",
    "        \n",
    "        if match is None:\n",
    "            response = Response('404 Not Found', status=404)\n",
    "        else:\n",
    "            handler, params = match\n",
    "            try:\n",
    "                # Call handler with request and any path parameters\n",
    "                response = handler(request, **params)\n",
    "                \n",
    "                # If handler returns a dict, convert to JSON response\n",
    "                if isinstance(response, dict):\n",
    "                    response = Response().json_response(response)\n",
    "                elif isinstance(response, str):\n",
    "                    response = Response(response)\n",
    "            except Exception as e:\n",
    "                response = Response(f'500 Internal Server Error: {str(e)}', status=500)\n",
    "        \n",
    "        return self._send_response(response, start_response)\n",
    "    \n",
    "    def _send_response(self, response: Response, start_response: Callable):\n",
    "        \"\"\"Send HTTP response via WSGI.\"\"\"\n",
    "        status_messages = {\n",
    "            200: '200 OK',\n",
    "            404: '404 Not Found',\n",
    "            500: '500 Internal Server Error',\n",
    "        }\n",
    "        \n",
    "        status = status_messages.get(response.status, f'{response.status} Unknown')\n",
    "        headers = list(response.headers.items())\n",
    "        \n",
    "        start_response(status, headers)\n",
    "        return response\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    app = WebFramework()\n",
    "    \n",
    "    # Simple route\n",
    "    @app.route('/')\n",
    "    def home(request):\n",
    "        return Response('<h1>Welcome to My Framework!</h1>')\n",
    "    \n",
    "    # JSON API endpoint\n",
    "    @app.route('/api/users', methods=['GET'])\n",
    "    def get_users(request):\n",
    "        return {'users': ['Alice', 'Bob', 'Charlie']}\n",
    "    \n",
    "    # Dynamic route with path parameter\n",
    "    @app.route('/users/<user_id>', methods=['GET'])\n",
    "    def get_user(request, user_id):\n",
    "        return {'user_id': user_id, 'name': f'User {user_id}'}\n",
    "    \n",
    "    # Middleware example: logging\n",
    "    def logging_middleware(request):\n",
    "        print(f'{request.method} {request.path}')\n",
    "        return None  # Continue to next middleware/handler\n",
    "    \n",
    "    app.use(logging_middleware)\n",
    "    \n",
    "    # Run with WSGI server (e.g., wsgiref for development)\n",
    "    from wsgiref.simple_server import make_server\n",
    "    \n",
    "    server = make_server('localhost', 8000, app)\n",
    "    print('Server running on http://localhost:8000')\n",
    "    # server.serve_forever()  # Commented to avoid blocking in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Features to Implement\n",
    "\n",
    "1. **Async Support**: Use `asyncio` and `aiohttp` for async request handling\n",
    "2. **WebSocket Handling**: Implement WebSocket protocol for real-time communication\n",
    "3. **Template Engine**: Build a simple template engine with variable substitution and control flow\n",
    "4. **ORM Integration**: Create adapters for SQLAlchemy or other ORMs\n",
    "5. **Authentication System**: JWT-based auth, session management, OAuth\n",
    "6. **Rate Limiting**: Token bucket or sliding window algorithm\n",
    "7. **CORS Handling**: Proper CORS middleware with configurable origins\n",
    "8. **File Upload**: Multipart form data parsing\n",
    "9. **Blueprints/Modules**: Organize routes into reusable modules\n",
    "10. **Dependency Injection**: Automatic dependency resolution for handlers\n",
    "\n",
    "### Testing Strategy\n",
    "\n",
    "- **Unit Tests**: Test Router, Request, Response classes independently\n",
    "- **Integration Tests**: Test full request/response cycle\n",
    "- **Performance Tests**: Benchmark against Flask/FastAPI\n",
    "- **Example App**: Build a small app (blog, API) using your framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Distributed Task Queue System\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐⭐ (Advanced)\n",
    "\n",
    "**Skills**: Concurrency, networking, databases, system design, message queues\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "Build a distributed task queue system like Celery. This teaches distributed systems, concurrency, and reliability patterns.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "┌──────────────┐          ┌──────────────┐\n",
    "│   Client     │──task──▶ │   Broker     │ (Redis/RabbitMQ)\n",
    "└──────────────┘          │  (Message    │\n",
    "       │                  │   Queue)     │\n",
    "       │                  └──────┬───────┘\n",
    "       │                         │\n",
    "       │                  ┌──────▼───────┐\n",
    "       │                  │   Worker 1   │───┐\n",
    "       │                  └──────────────┘   │\n",
    "       │                  ┌──────────────┐   │ results\n",
    "       │                  │   Worker 2   │───┤\n",
    "       │                  └──────────────┘   │\n",
    "       │                  ┌──────────────┐   │\n",
    "       │                  │   Worker N   │───┘\n",
    "       │                  └──────────────┘   \n",
    "       │                         │\n",
    "       │                  ┌──────▼───────┐\n",
    "       └─────result──────▶│   Result     │ (Redis/DB)\n",
    "                          │   Backend    │\n",
    "                          └──────────────┘\n",
    "```\n",
    "\n",
    "### Components\n",
    "\n",
    "1. **Task Definition**: Decorator-based task registration\n",
    "2. **Broker Interface**: Abstract message queue (Redis, RabbitMQ, or in-memory)\n",
    "3. **Worker Process**: Consume and execute tasks\n",
    "4. **Result Backend**: Store task results\n",
    "5. **Scheduler**: Periodic/delayed task execution\n",
    "6. **Monitor**: Track task status and worker health\n",
    "\n",
    "### Implementation Roadmap\n",
    "\n",
    "**Phase 1: Core Task System (Week 1)**\n",
    "- Task registry and decorator\n",
    "- Serialization (pickle/JSON)\n",
    "- In-memory queue implementation\n",
    "- Basic worker\n",
    "\n",
    "**Phase 2: Distributed Components (Week 2)**\n",
    "- Redis broker integration\n",
    "- Result backend\n",
    "- Task state tracking (pending, running, success, failure)\n",
    "- Multiple workers\n",
    "\n",
    "**Phase 3: Reliability (Week 3)**\n",
    "- Retry logic with exponential backoff\n",
    "- Failure handling and dead letter queue\n",
    "- Task timeouts\n",
    "- Worker heartbeat and failure detection\n",
    "\n",
    "**Phase 4: Advanced Features (Week 4)**\n",
    "- Task prioritization\n",
    "- Task chaining and workflows\n",
    "- Scheduled/periodic tasks\n",
    "- Monitoring dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter Code: Distributed Task Queue Core\n",
    "\n",
    "import uuid\n",
    "import time\n",
    "import pickle\n",
    "import threading\n",
    "from typing import Callable, Any, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from queue import Queue, Empty\n",
    "import traceback\n",
    "\n",
    "class TaskState(Enum):\n",
    "    \"\"\"Task execution states.\"\"\"\n",
    "    PENDING = 'PENDING'\n",
    "    RUNNING = 'RUNNING'\n",
    "    SUCCESS = 'SUCCESS'\n",
    "    FAILURE = 'FAILURE'\n",
    "    RETRY = 'RETRY'\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    \"\"\"Represents a task to be executed.\"\"\"\n",
    "    id: str\n",
    "    func_name: str\n",
    "    args: tuple = field(default_factory=tuple)\n",
    "    kwargs: dict = field(default_factory=dict)\n",
    "    state: TaskState = TaskState.PENDING\n",
    "    result: Any = None\n",
    "    error: Optional[str] = None\n",
    "    retries: int = 0\n",
    "    max_retries: int = 3\n",
    "    created_at: float = field(default_factory=time.time)\n",
    "    started_at: Optional[float] = None\n",
    "    completed_at: Optional[float] = None\n",
    "\n",
    "class TaskRegistry:\n",
    "    \"\"\"Registry for task functions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._tasks: Dict[str, Callable] = {}\n",
    "    \n",
    "    def register(self, name: str, func: Callable):\n",
    "        \"\"\"Register a task function.\"\"\"\n",
    "        self._tasks[name] = func\n",
    "    \n",
    "    def get(self, name: str) -> Optional[Callable]:\n",
    "        \"\"\"Get a registered task function.\"\"\"\n",
    "        return self._tasks.get(name)\n",
    "    \n",
    "    def task(self, func: Callable = None, *, max_retries: int = 3):\n",
    "        \"\"\"Decorator to register a task.\"\"\"\n",
    "        def decorator(f: Callable) -> Callable:\n",
    "            task_name = f.__name__\n",
    "            self.register(task_name, f)\n",
    "            \n",
    "            # Add apply_async method to function\n",
    "            def apply_async(*args, **kwargs):\n",
    "                task_id = str(uuid.uuid4())\n",
    "                task = Task(\n",
    "                    id=task_id,\n",
    "                    func_name=task_name,\n",
    "                    args=args,\n",
    "                    kwargs=kwargs,\n",
    "                    max_retries=max_retries\n",
    "                )\n",
    "                broker.enqueue(task)\n",
    "                return task_id\n",
    "            \n",
    "            f.apply_async = apply_async\n",
    "            return f\n",
    "        \n",
    "        if func is None:\n",
    "            return decorator\n",
    "        else:\n",
    "            return decorator(func)\n",
    "\n",
    "class InMemoryBroker:\n",
    "    \"\"\"Simple in-memory message broker using queue.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = Queue()\n",
    "        self.results: Dict[str, Task] = {}\n",
    "    \n",
    "    def enqueue(self, task: Task):\n",
    "        \"\"\"Add task to queue.\"\"\"\n",
    "        self.queue.put(pickle.dumps(task))\n",
    "        self.results[task.id] = task\n",
    "    \n",
    "    def dequeue(self, timeout: int = 1) -> Optional[Task]:\n",
    "        \"\"\"Get next task from queue.\"\"\"\n",
    "        try:\n",
    "            task_bytes = self.queue.get(timeout=timeout)\n",
    "            return pickle.loads(task_bytes)\n",
    "        except Empty:\n",
    "            return None\n",
    "    \n",
    "    def update_result(self, task: Task):\n",
    "        \"\"\"Store task result.\"\"\"\n",
    "        self.results[task.id] = task\n",
    "    \n",
    "    def get_result(self, task_id: str) -> Optional[Task]:\n",
    "        \"\"\"Get task result.\"\"\"\n",
    "        return self.results.get(task_id)\n",
    "\n",
    "class Worker:\n",
    "    \"\"\"Worker process that executes tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, broker: InMemoryBroker, registry: TaskRegistry, worker_id: str = None):\n",
    "        self.broker = broker\n",
    "        self.registry = registry\n",
    "        self.worker_id = worker_id or str(uuid.uuid4())\n",
    "        self.running = False\n",
    "        self.thread = None\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start worker in background thread.\"\"\"\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self._run, daemon=True)\n",
    "        self.thread.start()\n",
    "        print(f\"Worker {self.worker_id} started\")\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop worker.\"\"\"\n",
    "        self.running = False\n",
    "        if self.thread:\n",
    "            self.thread.join()\n",
    "        print(f\"Worker {self.worker_id} stopped\")\n",
    "    \n",
    "    def _run(self):\n",
    "        \"\"\"Main worker loop.\"\"\"\n",
    "        while self.running:\n",
    "            task = self.broker.dequeue(timeout=1)\n",
    "            \n",
    "            if task is None:\n",
    "                continue\n",
    "            \n",
    "            self._execute_task(task)\n",
    "    \n",
    "    def _execute_task(self, task: Task):\n",
    "        \"\"\"Execute a single task.\"\"\"\n",
    "        func = self.registry.get(task.func_name)\n",
    "        \n",
    "        if func is None:\n",
    "            task.state = TaskState.FAILURE\n",
    "            task.error = f\"Task function '{task.func_name}' not found\"\n",
    "            self.broker.update_result(task)\n",
    "            return\n",
    "        \n",
    "        task.state = TaskState.RUNNING\n",
    "        task.started_at = time.time()\n",
    "        \n",
    "        print(f\"Worker {self.worker_id} executing task {task.id}: {task.func_name}\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*task.args, **task.kwargs)\n",
    "            task.result = result\n",
    "            task.state = TaskState.SUCCESS\n",
    "            print(f\"Task {task.id} completed successfully\")\n",
    "        except Exception as e:\n",
    "            task.error = traceback.format_exc()\n",
    "            \n",
    "            # Retry logic\n",
    "            if task.retries < task.max_retries:\n",
    "                task.retries += 1\n",
    "                task.state = TaskState.RETRY\n",
    "                print(f\"Task {task.id} failed, retry {task.retries}/{task.max_retries}\")\n",
    "                # Re-enqueue with exponential backoff\n",
    "                time.sleep(2 ** task.retries)\n",
    "                self.broker.enqueue(task)\n",
    "                return\n",
    "            else:\n",
    "                task.state = TaskState.FAILURE\n",
    "                print(f\"Task {task.id} failed after {task.max_retries} retries: {e}\")\n",
    "        \n",
    "        task.completed_at = time.time()\n",
    "        self.broker.update_result(task)\n",
    "\n",
    "# Global instances\n",
    "registry = TaskRegistry()\n",
    "broker = InMemoryBroker()\n",
    "\n",
    "# Example usage\n",
    "@registry.task(max_retries=2)\n",
    "def add(x, y):\n",
    "    \"\"\"Simple addition task.\"\"\"\n",
    "    print(f\"Adding {x} + {y}\")\n",
    "    return x + y\n",
    "\n",
    "@registry.task\n",
    "def slow_task(duration):\n",
    "    \"\"\"Simulate slow task.\"\"\"\n",
    "    print(f\"Starting slow task ({duration}s)\")\n",
    "    time.sleep(duration)\n",
    "    print(f\"Slow task completed\")\n",
    "    return f\"Slept for {duration} seconds\"\n",
    "\n",
    "@registry.task\n",
    "def failing_task():\n",
    "    \"\"\"Task that always fails (for testing retry).\"\"\"\n",
    "    raise ValueError(\"This task always fails!\")\n",
    "\n",
    "# Demo\n",
    "if __name__ == '__main__':\n",
    "    # Start workers\n",
    "    worker1 = Worker(broker, registry, \"worker-1\")\n",
    "    worker2 = Worker(broker, registry, \"worker-2\")\n",
    "    \n",
    "    worker1.start()\n",
    "    worker2.start()\n",
    "    \n",
    "    # Submit tasks\n",
    "    task1_id = add.apply_async(10, 20)\n",
    "    task2_id = slow_task.apply_async(2)\n",
    "    task3_id = add.apply_async(5, 15)\n",
    "    \n",
    "    print(f\"Submitted tasks: {task1_id}, {task2_id}, {task3_id}\")\n",
    "    \n",
    "    # Wait for tasks to complete\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Check results\n",
    "    result1 = broker.get_result(task1_id)\n",
    "    result2 = broker.get_result(task2_id)\n",
    "    result3 = broker.get_result(task3_id)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Task 1: {result1.state.value} - {result1.result}\")\n",
    "    print(f\"Task 2: {result2.state.value} - {result2.result}\")\n",
    "    print(f\"Task 3: {result3.state.value} - {result3.result}\")\n",
    "    \n",
    "    # Stop workers\n",
    "    worker1.stop()\n",
    "    worker2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Features to Implement\n",
    "\n",
    "1. **Redis Broker**: Replace in-memory queue with Redis for true distribution\n",
    "2. **Task Priorities**: High/medium/low priority queues\n",
    "3. **Task Chains**: Execute tasks sequentially, passing results\n",
    "4. **Task Groups**: Execute tasks in parallel, collect results\n",
    "5. **Scheduled Tasks**: Cron-like periodic task execution\n",
    "6. **Rate Limiting**: Limit task execution rate\n",
    "7. **Worker Pools**: Process pool for CPU-bound tasks\n",
    "8. **Dead Letter Queue**: Failed tasks after max retries\n",
    "9. **Task Monitoring**: Web dashboard to view task status\n",
    "10. **Graceful Shutdown**: Finish running tasks before stopping\n",
    "\n",
    "### Trade-offs and Design Decisions\n",
    "\n",
    "- **Message Format**: Pickle vs JSON (pickle supports more types, JSON is safer)\n",
    "- **Broker Choice**: Redis (fast, simple) vs RabbitMQ (more features, complex)\n",
    "- **Result Storage**: Redis (fast, temporary) vs PostgreSQL (persistent, queryable)\n",
    "- **Concurrency**: Threads (I/O-bound) vs Processes (CPU-bound) vs Async (high concurrency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Image Recognition System (End-to-End ML Pipeline)\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐⭐ (Advanced)\n",
    "\n",
    "**Skills**: Deep Learning, CNN, Transfer Learning, MLOps, API development\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "Build a complete image recognition system from data collection to deployment. This project teaches the full ML pipeline.\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│              Data Pipeline                          │\n",
    "│  ┌──────────┐  ┌──────────┐  ┌──────────┐         │\n",
    "│  │  Scrape  │→ │ Clean &  │→ │ Augment  │         │\n",
    "│  │  Images  │  │ Label    │  │ & Split  │         │\n",
    "│  └──────────┘  └──────────┘  └──────────┘         │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "                      ↓\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│            Training Pipeline                        │\n",
    "│  ┌──────────┐  ┌──────────┐  ┌──────────┐         │\n",
    "│  │  Model   │→ │  Train   │→ │ Evaluate │         │\n",
    "│  │  Design  │  │ Monitor  │  │ & Tune   │         │\n",
    "│  └──────────┘  └──────────┘  └──────────┘         │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "                      ↓\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│         Deployment & Serving                        │\n",
    "│  ┌──────────┐  ┌──────────┐  ┌──────────┐         │\n",
    "│  │   REST   │  │  Model   │  │ Monitor  │         │\n",
    "│  │   API    │→ │ Serving  │→ │ & Logs   │         │\n",
    "│  └──────────┘  └──────────┘  └──────────┘         │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Implementation Phases\n",
    "\n",
    "**Phase 1: Data Collection & Preparation (Week 1)**\n",
    "- Collect images (web scraping, public datasets)\n",
    "- Data cleaning and quality checks\n",
    "- Labeling strategy (manual, semi-automated)\n",
    "- Data augmentation techniques\n",
    "- Train/validation/test split\n",
    "\n",
    "**Phase 2: Model Development (Week 2)**\n",
    "- Baseline model (simple CNN)\n",
    "- Transfer learning (ResNet, EfficientNet)\n",
    "- Hyperparameter tuning\n",
    "- Ensemble methods\n",
    "- Model evaluation and metrics\n",
    "\n",
    "**Phase 3: Deployment (Week 3)**\n",
    "- Model serialization and versioning\n",
    "- REST API with FastAPI/Flask\n",
    "- Model serving optimization (ONNX, TensorRT)\n",
    "- Containerization with Docker\n",
    "- Load testing\n",
    "\n",
    "**Phase 4: Production & Monitoring (Week 4)**\n",
    "- Monitoring and logging\n",
    "- A/B testing framework\n",
    "- Model retraining pipeline\n",
    "- CI/CD for ML\n",
    "- Web interface for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter Code: Image Classification API with Transfer Learning\n",
    "\n",
    "# Note: This requires tensorflow/pytorch, fastapi, pillow\n",
    "# For demonstration, we'll use pseudocode where heavy imports are needed\n",
    "\n",
    "from typing import List, Tuple\n",
    "import io\n",
    "\n",
    "# Placeholder for image processing\n",
    "class ImageClassifier:\n",
    "    \"\"\"\n",
    "    Image classifier using transfer learning.\n",
    "    \n",
    "    In real implementation:\n",
    "    - Use PyTorch or TensorFlow\n",
    "    - Load pre-trained model (ResNet50, EfficientNet)\n",
    "    - Fine-tune on your dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = None, num_classes: int = 10):\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "        if model_path:\n",
    "            self._load_weights(model_path)\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Build model architecture.\n",
    "        \n",
    "        Real implementation using PyTorch:\n",
    "        ```python\n",
    "        import torch\n",
    "        import torchvision.models as models\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer for our classes\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_features, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return f\"ResNet50 model with {self.num_classes} classes\"\n",
    "    \n",
    "    def _load_weights(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Load trained weights.\n",
    "        \n",
    "        Real implementation:\n",
    "        ```python\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.eval()\n",
    "        ```\n",
    "        \"\"\"\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "    \n",
    "    def preprocess_image(self, image_bytes: bytes):\n",
    "        \"\"\"\n",
    "        Preprocess image for model input.\n",
    "        \n",
    "        Real implementation:\n",
    "        ```python\n",
    "        from PIL import Image\n",
    "        import torchvision.transforms as transforms\n",
    "        \n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return \"preprocessed_image_tensor\"\n",
    "    \n",
    "    def predict(self, image_bytes: bytes, top_k: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Predict top-k classes for image.\n",
    "        \n",
    "        Real implementation:\n",
    "        ```python\n",
    "        import torch.nn.functional as F\n",
    "        \n",
    "        image_tensor = self.preprocess_image(image_bytes)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "        \n",
    "        results = []\n",
    "        for prob, idx in zip(top_probs[0], top_indices[0]):\n",
    "            class_name = self.class_names[idx.item()]\n",
    "            confidence = prob.item()\n",
    "            results.append((class_name, confidence))\n",
    "        \n",
    "        return results\n",
    "        ```\n",
    "        \"\"\"\n",
    "        # Mock predictions\n",
    "        return [\n",
    "            ('cat', 0.92),\n",
    "            ('dog', 0.05),\n",
    "            ('bird', 0.02),\n",
    "        ]\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs: int = 10):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \n",
    "        Real implementation:\n",
    "        ```python\n",
    "        import torch.optim as optim\n",
    "        \n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.fc.parameters(), lr=0.001)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                train_correct += (preds == labels).sum().item()\n",
    "            \n",
    "            # Validation phase\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    val_correct += (preds == labels).sum().item()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # Log metrics\n",
    "            train_acc = train_correct / len(train_loader.dataset)\n",
    "            val_acc = val_correct / len(val_loader.dataset)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        ```\n",
    "        \"\"\"\n",
    "        print(f\"Training model for {epochs} epochs...\")\n",
    "\n",
    "\n",
    "# FastAPI service for model serving\n",
    "class ImageClassificationAPI:\n",
    "    \"\"\"\n",
    "    REST API for image classification.\n",
    "    \n",
    "    Real implementation with FastAPI:\n",
    "    ```python\n",
    "    from fastapi import FastAPI, File, UploadFile\n",
    "    from fastapi.responses import JSONResponse\n",
    "    import uvicorn\n",
    "    \n",
    "    app = FastAPI(title=\"Image Classification API\")\n",
    "    classifier = ImageClassifier(model_path='models/best_model.pth')\n",
    "    \n",
    "    @app.post(\"/predict\")\n",
    "    async def predict(file: UploadFile = File(...)):\n",
    "        # Read image\n",
    "        image_bytes = await file.read()\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = classifier.predict(image_bytes, top_k=5)\n",
    "        \n",
    "        # Format response\n",
    "        results = [\n",
    "            {'class': class_name, 'confidence': float(conf)}\n",
    "            for class_name, conf in predictions\n",
    "        ]\n",
    "        \n",
    "        return JSONResponse({\n",
    "            'success': True,\n",
    "            'predictions': results\n",
    "        })\n",
    "    \n",
    "    @app.get(\"/health\")\n",
    "    async def health():\n",
    "        return {'status': 'healthy'}\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        uvicorn.run(app, host='0.0.0.0', port=8000)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Demo usage\n",
    "print(\"Image Classification System - Starter Code\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nKey Components:\")\n",
    "print(\"1. ImageClassifier - Transfer learning with ResNet50\")\n",
    "print(\"2. Training pipeline with validation\")\n",
    "print(\"3. FastAPI for model serving\")\n",
    "print(\"4. Preprocessing and postprocessing\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"- Install: pip install torch torchvision fastapi uvicorn pillow\")\n",
    "print(\"- Collect and prepare your dataset\")\n",
    "print(\"- Train the model\")\n",
    "print(\"- Deploy API and test with curl/Postman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLOps Pipeline Components\n",
    "\n",
    "1. **Data Versioning**: Use DVC (Data Version Control) or similar\n",
    "2. **Experiment Tracking**: MLflow, Weights & Biases, TensorBoard\n",
    "3. **Model Registry**: Store models with versions, metrics, and metadata\n",
    "4. **Automated Retraining**: Trigger training on new data or performance degradation\n",
    "5. **Model Monitoring**: Track inference latency, accuracy drift, data drift\n",
    "6. **A/B Testing**: Compare model versions in production\n",
    "7. **Feature Store**: Centralized storage for features\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "- **Model Optimization**: ONNX conversion, quantization, pruning for faster inference\n",
    "- **Batching**: Batch predictions for efficiency\n",
    "- **Caching**: Cache frequent predictions\n",
    "- **GPU Utilization**: Maximize GPU usage for inference\n",
    "- **Fallback Strategy**: Handle model failures gracefully\n",
    "- **Versioning**: Support multiple model versions simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Build a Programming Language Interpreter\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐⭐⭐ (Expert)\n",
    "\n",
    "**Skills**: Compilers, interpreters, parsing, AST, language design, virtual machines\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "Create your own interpreted programming language from scratch. This is one of the most challenging and rewarding projects.\n",
    "\n",
    "### Compiler Pipeline\n",
    "\n",
    "```\n",
    "Source Code\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────┐\n",
    "│   Lexer     │  Split into tokens\n",
    "└──────┬──────┘\n",
    "       │ Tokens: [KEYWORD, IDENTIFIER, OPERATOR, ...]\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│   Parser    │  Build Abstract Syntax Tree (AST)\n",
    "└──────┬──────┘\n",
    "       │ AST: Tree of nodes (expressions, statements)\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│  Semantic   │  Type checking, scope analysis\n",
    "│  Analyzer   │\n",
    "└──────┬──────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ Interpreter │  Execute AST\n",
    "│  or Compiler│\n",
    "└──────┬──────┘\n",
    "       │\n",
    "       ▼\n",
    "   Output / Side Effects\n",
    "```\n",
    "\n",
    "### Language Features (Progressive)\n",
    "\n",
    "**Phase 1: Basic Expressions (Week 1-2)**\n",
    "- Lexer: Tokenize source code\n",
    "- Parser: Build AST for arithmetic expressions\n",
    "- Interpreter: Evaluate expressions\n",
    "- Data types: Numbers, strings, booleans\n",
    "\n",
    "**Phase 2: Variables & Control Flow (Week 3-4)**\n",
    "- Variable declaration and assignment\n",
    "- If/else statements\n",
    "- While loops\n",
    "- Scope and symbol table\n",
    "\n",
    "**Phase 3: Functions (Week 5-6)**\n",
    "- Function definition and calls\n",
    "- Parameters and return values\n",
    "- Closures\n",
    "- Recursion\n",
    "\n",
    "**Phase 4: Advanced Features (Week 7-8)**\n",
    "- Classes and objects\n",
    "- Error handling (try/catch)\n",
    "- Modules and imports\n",
    "- Standard library\n",
    "\n",
    "### Example Language Syntax\n",
    "\n",
    "```\n",
    "# Variables\n",
    "let x = 10\n",
    "let name = \"Alice\"\n",
    "\n",
    "# Functions\n",
    "fn factorial(n) {\n",
    "    if n <= 1 {\n",
    "        return 1\n",
    "    }\n",
    "    return n * factorial(n - 1)\n",
    "}\n",
    "\n",
    "# Classes\n",
    "class Point {\n",
    "    fn init(x, y) {\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    }\n",
    "    \n",
    "    fn distance() {\n",
    "        return sqrt(self.x^2 + self.y^2)\n",
    "    }\n",
    "}\n",
    "\n",
    "let p = Point(3, 4)\n",
    "print(p.distance())  # 5.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter Code: Simple Expression Interpreter\n",
    "\n",
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Any, Optional\n",
    "\n",
    "# ============= LEXER =============\n",
    "\n",
    "class TokenType(Enum):\n",
    "    \"\"\"Token types for lexer.\"\"\"\n",
    "    NUMBER = auto()\n",
    "    PLUS = auto()\n",
    "    MINUS = auto()\n",
    "    MULTIPLY = auto()\n",
    "    DIVIDE = auto()\n",
    "    LPAREN = auto()\n",
    "    RPAREN = auto()\n",
    "    EOF = auto()\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    \"\"\"Represents a token.\"\"\"\n",
    "    type: TokenType\n",
    "    value: Any\n",
    "\n",
    "class Lexer:\n",
    "    \"\"\"Tokenizes source code.\"\"\"\n",
    "    \n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.pos = 0\n",
    "        self.current_char = self.text[0] if text else None\n",
    "    \n",
    "    def advance(self):\n",
    "        \"\"\"Move to next character.\"\"\"\n",
    "        self.pos += 1\n",
    "        if self.pos >= len(self.text):\n",
    "            self.current_char = None\n",
    "        else:\n",
    "            self.current_char = self.text[self.pos]\n",
    "    \n",
    "    def skip_whitespace(self):\n",
    "        \"\"\"Skip whitespace characters.\"\"\"\n",
    "        while self.current_char and self.current_char.isspace():\n",
    "            self.advance()\n",
    "    \n",
    "    def number(self) -> float:\n",
    "        \"\"\"Parse number (integer or float).\"\"\"\n",
    "        result = ''\n",
    "        while self.current_char and (self.current_char.isdigit() or self.current_char == '.'):\n",
    "            result += self.current_char\n",
    "            self.advance()\n",
    "        return float(result)\n",
    "    \n",
    "    def get_next_token(self) -> Token:\n",
    "        \"\"\"Get next token from input.\"\"\"\n",
    "        while self.current_char:\n",
    "            if self.current_char.isspace():\n",
    "                self.skip_whitespace()\n",
    "                continue\n",
    "            \n",
    "            if self.current_char.isdigit():\n",
    "                return Token(TokenType.NUMBER, self.number())\n",
    "            \n",
    "            if self.current_char == '+':\n",
    "                self.advance()\n",
    "                return Token(TokenType.PLUS, '+')\n",
    "            \n",
    "            if self.current_char == '-':\n",
    "                self.advance()\n",
    "                return Token(TokenType.MINUS, '-')\n",
    "            \n",
    "            if self.current_char == '*':\n",
    "                self.advance()\n",
    "                return Token(TokenType.MULTIPLY, '*')\n",
    "            \n",
    "            if self.current_char == '/':\n",
    "                self.advance()\n",
    "                return Token(TokenType.DIVIDE, '/')\n",
    "            \n",
    "            if self.current_char == '(':\n",
    "                self.advance()\n",
    "                return Token(TokenType.LPAREN, '(')\n",
    "            \n",
    "            if self.current_char == ')':\n",
    "                self.advance()\n",
    "                return Token(TokenType.RPAREN, ')')\n",
    "            \n",
    "            raise ValueError(f\"Invalid character: {self.current_char}\")\n",
    "        \n",
    "        return Token(TokenType.EOF, None)\n",
    "\n",
    "# ============= PARSER (AST) =============\n",
    "\n",
    "@dataclass\n",
    "class ASTNode:\n",
    "    \"\"\"Base class for AST nodes.\"\"\"\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class Number(ASTNode):\n",
    "    \"\"\"Number literal.\"\"\"\n",
    "    value: float\n",
    "\n",
    "@dataclass\n",
    "class BinaryOp(ASTNode):\n",
    "    \"\"\"Binary operation (e.g., 1 + 2).\"\"\"\n",
    "    left: ASTNode\n",
    "    op: Token\n",
    "    right: ASTNode\n",
    "\n",
    "class Parser:\n",
    "    \"\"\"Builds Abstract Syntax Tree from tokens.\"\"\"\n",
    "    \n",
    "    def __init__(self, lexer: Lexer):\n",
    "        self.lexer = lexer\n",
    "        self.current_token = self.lexer.get_next_token()\n",
    "    \n",
    "    def eat(self, token_type: TokenType):\n",
    "        \"\"\"Consume current token if it matches expected type.\"\"\"\n",
    "        if self.current_token.type == token_type:\n",
    "            self.current_token = self.lexer.get_next_token()\n",
    "        else:\n",
    "            raise ValueError(f\"Expected {token_type}, got {self.current_token.type}\")\n",
    "    \n",
    "    def factor(self) -> ASTNode:\n",
    "        \"\"\"Parse factor: NUMBER | LPAREN expr RPAREN.\"\"\"\n",
    "        token = self.current_token\n",
    "        \n",
    "        if token.type == TokenType.NUMBER:\n",
    "            self.eat(TokenType.NUMBER)\n",
    "            return Number(token.value)\n",
    "        elif token.type == TokenType.LPAREN:\n",
    "            self.eat(TokenType.LPAREN)\n",
    "            node = self.expr()\n",
    "            self.eat(TokenType.RPAREN)\n",
    "            return node\n",
    "        \n",
    "        raise ValueError(f\"Invalid factor: {token}\")\n",
    "    \n",
    "    def term(self) -> ASTNode:\n",
    "        \"\"\"Parse term: factor ((MUL | DIV) factor)*.\"\"\"\n",
    "        node = self.factor()\n",
    "        \n",
    "        while self.current_token.type in (TokenType.MULTIPLY, TokenType.DIVIDE):\n",
    "            op = self.current_token\n",
    "            self.eat(op.type)\n",
    "            node = BinaryOp(left=node, op=op, right=self.factor())\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def expr(self) -> ASTNode:\n",
    "        \"\"\"Parse expression: term ((PLUS | MINUS) term)*.\"\"\"\n",
    "        node = self.term()\n",
    "        \n",
    "        while self.current_token.type in (TokenType.PLUS, TokenType.MINUS):\n",
    "            op = self.current_token\n",
    "            self.eat(op.type)\n",
    "            node = BinaryOp(left=node, op=op, right=self.term())\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def parse(self) -> ASTNode:\n",
    "        \"\"\"Parse input and return AST.\"\"\"\n",
    "        return self.expr()\n",
    "\n",
    "# ============= INTERPRETER =============\n",
    "\n",
    "class Interpreter:\n",
    "    \"\"\"Executes AST.\"\"\"\n",
    "    \n",
    "    def visit(self, node: ASTNode) -> float:\n",
    "        \"\"\"Visit AST node and evaluate.\"\"\"\n",
    "        if isinstance(node, Number):\n",
    "            return node.value\n",
    "        elif isinstance(node, BinaryOp):\n",
    "            left = self.visit(node.left)\n",
    "            right = self.visit(node.right)\n",
    "            \n",
    "            if node.op.type == TokenType.PLUS:\n",
    "                return left + right\n",
    "            elif node.op.type == TokenType.MINUS:\n",
    "                return left - right\n",
    "            elif node.op.type == TokenType.MULTIPLY:\n",
    "                return left * right\n",
    "            elif node.op.type == TokenType.DIVIDE:\n",
    "                return left / right\n",
    "        \n",
    "        raise ValueError(f\"Unknown node type: {type(node)}\")\n",
    "    \n",
    "    def interpret(self, text: str) -> float:\n",
    "        \"\"\"Interpret source code.\"\"\"\n",
    "        lexer = Lexer(text)\n",
    "        parser = Parser(lexer)\n",
    "        tree = parser.parse()\n",
    "        return self.visit(tree)\n",
    "\n",
    "# ============= DEMO =============\n",
    "\n",
    "interpreter = Interpreter()\n",
    "\n",
    "test_cases = [\n",
    "    \"7 + 3\",\n",
    "    \"10 - 4\",\n",
    "    \"3 * 4\",\n",
    "    \"20 / 5\",\n",
    "    \"7 + 3 * 2\",  # Respects operator precedence\n",
    "    \"(7 + 3) * 2\",  # Parentheses\n",
    "    \"10 + 2 * 6 / 4 - 1\",  # Complex expression\n",
    "]\n",
    "\n",
    "print(\"Simple Expression Interpreter Demo\")\n",
    "print(\"=\"*40)\n",
    "for expr in test_cases:\n",
    "    result = interpreter.interpret(expr)\n",
    "    print(f\"{expr:20} = {result}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Add variables and assignment\")\n",
    "print(\"2. Add if/else statements\")\n",
    "print(\"3. Add while loops\")\n",
    "print(\"4. Add functions\")\n",
    "print(\"5. Add classes and objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Language Features\n",
    "\n",
    "1. **Variables and Scoping**:\n",
    "   - Symbol table for variable lookup\n",
    "   - Lexical scoping\n",
    "   - Global vs local scope\n",
    "\n",
    "2. **Functions**:\n",
    "   - Function definitions and calls\n",
    "   - Closures and first-class functions\n",
    "   - Recursion\n",
    "\n",
    "3. **Objects and Classes**:\n",
    "   - Class definitions\n",
    "   - Object instantiation\n",
    "   - Method calls\n",
    "   - Inheritance\n",
    "\n",
    "4. **Advanced Compilation**:\n",
    "   - Compile to bytecode\n",
    "   - Virtual machine execution\n",
    "   - Garbage collection\n",
    "   - JIT compilation\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Book**: \"Crafting Interpreters\" by Robert Nystrom (free online)\n",
    "- **Book**: \"Writing An Interpreter In Go\" by Thorsten Ball\n",
    "- **Tutorial**: \"Let's Build A Simple Interpreter\" by Ruslan Spivak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Additional Advanced Project Ideas\n",
    "\n",
    "### 5.1 Real-Time Chat with AI Features\n",
    "\n",
    "**Stack**: WebSockets, asyncio, NLP models, Redis, PostgreSQL\n",
    "\n",
    "- Real-time messaging with Socket.IO or native WebSockets\n",
    "- Sentiment analysis of messages\n",
    "- Auto-translation between languages\n",
    "- Smart reply suggestions\n",
    "- Content moderation\n",
    "- Message search with Elasticsearch\n",
    "\n",
    "### 5.2 Recommendation Engine at Scale\n",
    "\n",
    "**Stack**: Spark, Redis, ML libraries, FastAPI\n",
    "\n",
    "- Collaborative filtering (user-based, item-based)\n",
    "- Matrix factorization (SVD, ALS)\n",
    "- Neural collaborative filtering\n",
    "- Hybrid recommender\n",
    "- Real-time recommendations\n",
    "- A/B testing framework\n",
    "\n",
    "### 5.3 Algorithmic Trading System\n",
    "\n",
    "**Stack**: Pandas, TA-Lib, ML models, real-time data APIs\n",
    "\n",
    "- Data pipeline for market data\n",
    "- Technical indicators\n",
    "- Strategy development (momentum, mean-reversion)\n",
    "- Backtesting engine\n",
    "- Risk management\n",
    "- Paper trading with live data\n",
    "\n",
    "### 5.4 Distributed Database\n",
    "\n",
    "**Stack**: Socket programming, Raft consensus, B-trees\n",
    "\n",
    "- Key-value storage engine\n",
    "- Replication (leader-follower)\n",
    "- Consensus algorithm (Raft)\n",
    "- Sharding/partitioning\n",
    "- Transactions\n",
    "- Client protocol\n",
    "\n",
    "### 5.5 Container Orchestrator\n",
    "\n",
    "**Stack**: Docker API, networking, scheduling algorithms\n",
    "\n",
    "- Container lifecycle management\n",
    "- Scheduling (bin packing, spread)\n",
    "- Service discovery\n",
    "- Load balancing\n",
    "- Health checks\n",
    "- Rolling updates\n",
    "\n",
    "### 5.6 Search Engine\n",
    "\n",
    "**Stack**: Web crawling, inverted index, ranking algorithms\n",
    "\n",
    "- Web crawler with respect to robots.txt\n",
    "- HTML parsing and content extraction\n",
    "- Inverted index construction\n",
    "- PageRank algorithm\n",
    "- Query processing\n",
    "- Autocomplete suggestions\n",
    "\n",
    "### 5.7 Neural Machine Translation\n",
    "\n",
    "**Stack**: PyTorch, Transformers, Hugging Face\n",
    "\n",
    "- Seq2Seq with attention\n",
    "- Transformer architecture\n",
    "- Beam search decoding\n",
    "- BLEU evaluation\n",
    "- Fine-tuning pre-trained models\n",
    "- Zero-shot translation\n",
    "\n",
    "### 5.8 Operating System Kernel Module\n",
    "\n",
    "**Stack**: C, Linux kernel, Python ctypes\n",
    "\n",
    "- Character device driver\n",
    "- System call wrapper\n",
    "- Kernel-userspace communication\n",
    "- Custom scheduler\n",
    "- Memory allocator\n",
    "\n",
    "### 5.9 Video Streaming Service\n",
    "\n",
    "**Stack**: FFmpeg, HLS/DASH, CDN, adaptive bitrate\n",
    "\n",
    "- Video transcoding pipeline\n",
    "- Adaptive bitrate streaming\n",
    "- CDN integration\n",
    "- Video player with quality selection\n",
    "- Recommendation system\n",
    "- User analytics\n",
    "\n",
    "### 5.10 Blockchain Implementation\n",
    "\n",
    "**Stack**: Cryptography, P2P networking, consensus\n",
    "\n",
    "- Block structure and chain\n",
    "- Proof of work\n",
    "- Transaction pool\n",
    "- P2P network\n",
    "- Wallet and digital signatures\n",
    "- Smart contracts (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Project Planning and Execution Guide\n",
    "\n",
    "### Step 1: Project Selection\n",
    "\n",
    "Choose a project based on:\n",
    "- **Interest**: You'll spend weeks on this, pick something you're excited about\n",
    "- **Career Goals**: Align with your target role (backend, ML, systems, etc.)\n",
    "- **Learning Objectives**: What skills do you want to develop?\n",
    "- **Complexity**: Start with 4-star projects before attempting 5-star ones\n",
    "\n",
    "### Step 2: Research Phase (1 week)\n",
    "\n",
    "Before writing code:\n",
    "1. **Read existing implementations**: Study similar open-source projects\n",
    "2. **Read foundational papers**: For distributed systems, ML models, etc.\n",
    "3. **Understand trade-offs**: Why do different systems make different choices?\n",
    "4. **Design document**: Write a 2-3 page design doc with:\n",
    "   - Problem statement\n",
    "   - Goals and non-goals\n",
    "   - Architecture diagram\n",
    "   - API/interface design\n",
    "   - Technology choices and rationale\n",
    "   - Success criteria\n",
    "\n",
    "### Step 3: MVP (Minimum Viable Product)\n",
    "\n",
    "Build the simplest version first:\n",
    "- **Core functionality only**: No bells and whistles\n",
    "- **In-memory first**: Before adding databases\n",
    "- **Single machine**: Before distributing\n",
    "- **Happy path**: Before error handling\n",
    "- **Timeline**: 1-2 weeks for MVP\n",
    "\n",
    "### Step 4: Iterative Development\n",
    "\n",
    "Add features incrementally:\n",
    "1. **Each iteration**: 1-2 weeks\n",
    "2. **One feature at a time**: Don't parallelize features initially\n",
    "3. **Test thoroughly**: Before moving to next feature\n",
    "4. **Refactor**: Clean up code debt regularly\n",
    "5. **Document**: Keep README and docs updated\n",
    "\n",
    "### Step 5: Production-Ready Features\n",
    "\n",
    "Transform from toy project to production quality:\n",
    "- **Testing**: Aim for 80%+ code coverage\n",
    "- **Error Handling**: All edge cases covered\n",
    "- **Logging**: Comprehensive logging at appropriate levels\n",
    "- **Monitoring**: Metrics and observability\n",
    "- **Documentation**: README, API docs, architecture docs\n",
    "- **Performance**: Profiling and optimization\n",
    "- **Security**: Input validation, authentication, encryption\n",
    "\n",
    "### Step 6: Deployment\n",
    "\n",
    "Make it accessible:\n",
    "- **Dockerize**: Create Dockerfile and docker-compose\n",
    "- **CI/CD**: GitHub Actions or similar\n",
    "- **Cloud Deployment**: AWS, GCP, or Heroku\n",
    "- **Demo**: Live demo or video walkthrough\n",
    "\n",
    "### Step 7: Portfolio Presentation\n",
    "\n",
    "**README should include**:\n",
    "- Project description and motivation\n",
    "- Architecture diagram\n",
    "- Key features with screenshots/demos\n",
    "- Technology stack\n",
    "- Setup instructions\n",
    "- API documentation\n",
    "- Performance benchmarks\n",
    "- Challenges and learnings\n",
    "- Future improvements\n",
    "\n",
    "**Blog post** (highly recommended):\n",
    "- Write about your experience\n",
    "- Technical deep dives on interesting problems\n",
    "- Share on dev.to, Medium, or your personal blog\n",
    "- Helps with SEO and demonstrates communication skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Planning Template\n",
    "\n",
    "project_template = \"\"\"\n",
    "# Project: [Your Project Name]\n",
    "\n",
    "## Problem Statement\n",
    "[What problem does this solve? Who is it for?]\n",
    "\n",
    "## Goals\n",
    "- [ ] Goal 1\n",
    "- [ ] Goal 2\n",
    "- [ ] Goal 3\n",
    "\n",
    "## Non-Goals (Out of Scope)\n",
    "- Feature X (may add later)\n",
    "- Feature Y (complexity too high)\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "[ASCII diagram of system architecture]\n",
    "```\n",
    "\n",
    "## Technology Stack\n",
    "- **Language**: Python 3.11\n",
    "- **Framework**: FastAPI\n",
    "- **Database**: PostgreSQL + Redis\n",
    "- **Deployment**: Docker + AWS\n",
    "\n",
    "## Milestones\n",
    "\n",
    "### Week 1-2: MVP\n",
    "- [ ] Core feature A\n",
    "- [ ] Core feature B\n",
    "- [ ] Basic API\n",
    "\n",
    "### Week 3-4: Enhanced Features\n",
    "- [ ] Feature C\n",
    "- [ ] Feature D\n",
    "- [ ] Testing suite\n",
    "\n",
    "### Week 5-6: Production Ready\n",
    "- [ ] Error handling\n",
    "- [ ] Logging and monitoring\n",
    "- [ ] Documentation\n",
    "- [ ] Deployment\n",
    "\n",
    "## Success Criteria\n",
    "- [ ] All core features working\n",
    "- [ ] 80%+ test coverage\n",
    "- [ ] Handles X requests/second\n",
    "- [ ] Deployed and accessible\n",
    "- [ ] Comprehensive documentation\n",
    "\n",
    "## Risks and Mitigations\n",
    "- **Risk**: Technology X might not scale\n",
    "  - **Mitigation**: Prototype early, have Plan B\n",
    "\n",
    "## Resources\n",
    "- [Paper/Tutorial 1]\n",
    "- [Similar Project 1]\n",
    "- [Documentation]\n",
    "\"\"\"\n",
    "\n",
    "print(project_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Best Practices for Advanced Projects\n",
    "\n",
    "### Code Quality\n",
    "\n",
    "1. **Design Patterns**:\n",
    "   - Use appropriate patterns (Factory, Strategy, Observer, etc.)\n",
    "   - SOLID principles for maintainability\n",
    "   - Separation of concerns\n",
    "\n",
    "2. **Code Style**:\n",
    "   - Follow language conventions (PEP 8 for Python)\n",
    "   - Use linters (pylint, flake8, black)\n",
    "   - Type hints for better IDE support\n",
    "\n",
    "3. **Documentation**:\n",
    "   - Docstrings for all public functions\n",
    "   - Comments for complex logic (the \"why\", not the \"what\")\n",
    "   - README with setup and usage\n",
    "\n",
    "### Testing Strategy\n",
    "\n",
    "1. **Unit Tests**:\n",
    "   - Test individual functions/classes\n",
    "   - Mock external dependencies\n",
    "   - Aim for 80%+ coverage\n",
    "\n",
    "2. **Integration Tests**:\n",
    "   - Test component interactions\n",
    "   - Use test databases\n",
    "   - End-to-end user flows\n",
    "\n",
    "3. **Performance Tests**:\n",
    "   - Load testing (Apache Bench, Locust)\n",
    "   - Profiling (cProfile, py-spy)\n",
    "   - Benchmarking against baselines\n",
    "\n",
    "### Deployment Best Practices\n",
    "\n",
    "1. **Containerization**:\n",
    "   - Multi-stage Docker builds\n",
    "   - Small base images (Alpine)\n",
    "   - .dockerignore for efficiency\n",
    "\n",
    "2. **CI/CD Pipeline**:\n",
    "   - Automated testing on PR\n",
    "   - Automated deployment on merge\n",
    "   - Environment-specific configs\n",
    "\n",
    "3. **Monitoring**:\n",
    "   - Application metrics (Prometheus)\n",
    "   - Logging (ELK stack)\n",
    "   - Alerting (PagerDuty, Slack)\n",
    "   - Distributed tracing (Jaeger)\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "1. **Profile First**:\n",
    "   - Don't optimize prematurely\n",
    "   - Use profilers to find bottlenecks\n",
    "   - Measure before and after\n",
    "\n",
    "2. **Common Optimizations**:\n",
    "   - Caching (Redis, Memcached)\n",
    "   - Database indexing\n",
    "   - Connection pooling\n",
    "   - Async I/O for I/O-bound tasks\n",
    "   - Multiprocessing for CPU-bound tasks\n",
    "\n",
    "3. **Scalability**:\n",
    "   - Stateless services\n",
    "   - Horizontal scaling\n",
    "   - Load balancing\n",
    "   - Database replication\n",
    "\n",
    "### Security Considerations\n",
    "\n",
    "1. **Input Validation**:\n",
    "   - Validate all user input\n",
    "   - Sanitize data to prevent injection\n",
    "   - Use parameterized queries\n",
    "\n",
    "2. **Authentication & Authorization**:\n",
    "   - Use established protocols (OAuth, JWT)\n",
    "   - Hash passwords (bcrypt, argon2)\n",
    "   - Implement rate limiting\n",
    "\n",
    "3. **Data Protection**:\n",
    "   - HTTPS everywhere\n",
    "   - Encrypt sensitive data at rest\n",
    "   - Secure secret management (Vault, AWS Secrets Manager)\n",
    "\n",
    "4. **OWASP Top 10**:\n",
    "   - Familiarize with common vulnerabilities\n",
    "   - SQL injection, XSS, CSRF\n",
    "   - Use security scanners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Exercises - Plan Your Project\n",
    "\n",
    "Complete these exercises to plan your advanced project.\n",
    "\n",
    "### Exercise 1: Project Selection (Difficulty: ★☆☆☆☆)\n",
    "\n",
    "**Task**: Choose 3 projects from this notebook that interest you. For each:\n",
    "1. Rate your current skill level (1-5) in the required technologies\n",
    "2. Estimate total development time\n",
    "3. Identify your primary learning goal\n",
    "4. Write one paragraph explaining why this project interests you\n",
    "\n",
    "**Expected Outcome**: A prioritized list of projects with clear learning objectives.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2: Design Document (Difficulty: ★★★☆☆)\n",
    "\n",
    "**Task**: For your top choice project, write a design document including:\n",
    "1. Problem statement (1 paragraph)\n",
    "2. Goals and non-goals (bullet points)\n",
    "3. Architecture diagram (ASCII art is fine)\n",
    "4. Technology stack with justification\n",
    "5. 3 major technical challenges you anticipate\n",
    "6. Success criteria (measurable)\n",
    "\n",
    "**Expected Outcome**: 2-3 page design document as a planning blueprint.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3: MVP Feature Scoping (Difficulty: ★★☆☆☆)\n",
    "\n",
    "**Task**: List ALL features you want in your project. Then:\n",
    "1. Mark features as \"MVP\" (must-have) or \"V2\" (nice-to-have)\n",
    "2. Ensure MVP has ≤ 5 features\n",
    "3. Estimate development time for each MVP feature\n",
    "4. Create a dependency graph (which features depend on others?)\n",
    "\n",
    "**Expected Outcome**: Focused MVP scope and development timeline.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 4: System Design Trade-offs (Difficulty: ★★★★☆)\n",
    "\n",
    "**Task**: For your chosen project, analyze these trade-offs:\n",
    "1. **Data Storage**: SQL vs NoSQL (when would you use each?)\n",
    "2. **Consistency**: Strong vs eventual (what does your project need?)\n",
    "3. **Scaling**: Vertical vs horizontal (which is appropriate?)\n",
    "4. **Communication**: REST vs GraphQL vs gRPC (which fits best?)\n",
    "5. **Deployment**: Monolith vs microservices (start with which?)\n",
    "\n",
    "For each, justify your choice with 2-3 sentences.\n",
    "\n",
    "**Expected Outcome**: Clear understanding of architectural decisions.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 5: Testing Strategy (Difficulty: ★★★☆☆)\n",
    "\n",
    "**Task**: Design a testing strategy for your project:\n",
    "1. List 5 critical user flows (e.g., \"user uploads image and gets prediction\")\n",
    "2. For each flow, identify:\n",
    "   - Happy path test case\n",
    "   - 2-3 edge cases\n",
    "   - Expected error scenarios\n",
    "3. List 3 integration tests needed\n",
    "4. Describe your performance testing approach (what metrics? what load?)\n",
    "\n",
    "**Expected Outcome**: Comprehensive testing plan before writing code.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 6: Project Timeline (Difficulty: ★★☆☆☆)\n",
    "\n",
    "**Task**: Create a week-by-week timeline:\n",
    "- **Week 1**: Research and design\n",
    "- **Week 2-3**: MVP development\n",
    "- **Week 4-5**: Enhanced features\n",
    "- **Week 6**: Testing and refinement\n",
    "- **Week 7**: Documentation and deployment\n",
    "- **Week 8**: Buffer for unforeseen issues\n",
    "\n",
    "For each week, list 3-5 specific deliverables.\n",
    "\n",
    "**Expected Outcome**: Realistic project timeline with milestones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Self-Check Quiz\n",
    "\n",
    "Test your understanding of advanced project concepts.\n",
    "\n",
    "### Question 1\n",
    "What is the primary benefit of building an MVP (Minimum Viable Product) before adding advanced features?\n",
    "\n",
    "A) It's faster to demo to users  \n",
    "B) It validates core assumptions and provides a working foundation  \n",
    "C) It requires less documentation  \n",
    "D) It's easier to deploy  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) It validates core assumptions and provides a working foundation\n",
    "\n",
    "**Explanation**: MVP lets you validate that your core idea works before investing in advanced features. It provides a solid foundation to build upon and helps you learn what works and what doesn't early.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2\n",
    "In a distributed task queue system, why is retry logic with exponential backoff preferred over immediate retry?\n",
    "\n",
    "A) It's easier to implement  \n",
    "B) It prevents overwhelming the system during temporary failures  \n",
    "C) It uses less memory  \n",
    "D) It guarantees success  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) It prevents overwhelming the system during temporary failures\n",
    "\n",
    "**Explanation**: Exponential backoff gives the system time to recover from temporary issues (network blip, database overload) instead of immediately retrying and potentially making the problem worse.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3\n",
    "When building an ML API, which optimization technique would have the MOST impact on inference latency?\n",
    "\n",
    "A) Using a faster programming language  \n",
    "B) Model quantization and ONNX conversion  \n",
    "C) Better documentation  \n",
    "D) Using more training data  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) Model quantization and ONNX conversion\n",
    "\n",
    "**Explanation**: Model optimization techniques like quantization (reducing precision from float32 to int8) and converting to ONNX for optimized runtime can reduce inference latency by 2-10x, which is far more significant than language choice for deployed models.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4\n",
    "What is the purpose of an Abstract Syntax Tree (AST) in a programming language interpreter?\n",
    "\n",
    "A) To make the code run faster  \n",
    "B) To represent the syntactic structure of source code for interpretation  \n",
    "C) To compress the source code  \n",
    "D) To encrypt the code  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) To represent the syntactic structure of source code for interpretation\n",
    "\n",
    "**Explanation**: AST is a tree representation of the source code's structure. It makes it easier to traverse and execute the program, perform optimizations, and implement language features.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 5\n",
    "In a web framework, what is the primary purpose of middleware?\n",
    "\n",
    "A) To store user data  \n",
    "B) To process requests/responses in a pipeline before/after reaching handlers  \n",
    "C) To manage database connections  \n",
    "D) To render HTML templates  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) To process requests/responses in a pipeline before/after reaching handlers\n",
    "\n",
    "**Explanation**: Middleware intercepts requests before they reach route handlers and responses before they're sent to clients. Common uses: logging, authentication, CORS, compression, rate limiting.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 6\n",
    "When should you use transfer learning instead of training a CNN from scratch?\n",
    "\n",
    "A) When you have millions of training images  \n",
    "B) When you have limited data or compute resources  \n",
    "C) Never, always train from scratch  \n",
    "D) Only for text classification  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) When you have limited data or compute resources\n",
    "\n",
    "**Explanation**: Transfer learning leverages pre-trained models (trained on millions of images like ImageNet) and fine-tunes them for your specific task. This works well with limited data and training time.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 7\n",
    "What is the CAP theorem relevant to distributed databases?\n",
    "\n",
    "A) A database can only guarantee 2 out of 3: Consistency, Availability, Partition tolerance  \n",
    "B) All databases must implement Caching, APIs, and Partitioning  \n",
    "C) Databases must choose between CPU, Memory, or Disk optimization  \n",
    "D) Consistency and Availability are mutually exclusive  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "A) A database can only guarantee 2 out of 3: Consistency, Availability, Partition tolerance\n",
    "\n",
    "**Explanation**: CAP theorem states that in the presence of network partitions, you must choose between consistency (all nodes see same data) and availability (system stays operational). Most systems choose AP (eventually consistent) or CP (strongly consistent but may be unavailable).\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 8\n",
    "What is the main advantage of using Docker for deploying your application?\n",
    "\n",
    "A) It makes the code run faster  \n",
    "B) It ensures consistent environment across development, testing, and production  \n",
    "C) It automatically fixes bugs  \n",
    "D) It provides free hosting  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) It ensures consistent environment across development, testing, and production\n",
    "\n",
    "**Explanation**: Docker containers package your application with all its dependencies, eliminating \"works on my machine\" problems. The same container runs identically everywhere.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 9\n",
    "Why is monitoring and logging critical for production systems?\n",
    "\n",
    "A) It's required by law  \n",
    "B) It allows you to detect, diagnose, and fix issues quickly  \n",
    "C) It makes the system faster  \n",
    "D) It prevents all bugs  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "B) It allows you to detect, diagnose, and fix issues quickly\n",
    "\n",
    "**Explanation**: Production systems will have issues. Good monitoring alerts you when something goes wrong, and comprehensive logging helps you understand why it happened and how to fix it.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 10\n",
    "What should you prioritize when starting a complex project?\n",
    "\n",
    "A) Implementing all features simultaneously  \n",
    "B) Creating perfect documentation first  \n",
    "C) Building a working MVP with core functionality  \n",
    "D) Optimizing performance from day one  \n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "C) Building a working MVP with core functionality\n",
    "\n",
    "**Explanation**: Start with MVP to validate your approach and get something working. Then iterate: add features, improve performance, enhance documentation. Premature optimization and over-engineering waste time on features you might not need.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Start with MVP**: Build the simplest version that works, then iterate\n",
    "2. **Design First**: Invest time in architecture and planning before coding\n",
    "3. **Production Quality**: Testing, monitoring, and documentation are not optional\n",
    "4. **Trade-offs Matter**: Every architectural decision involves trade-offs; understand them\n",
    "5. **Learn by Doing**: Reading about systems is valuable, but building them teaches you more\n",
    "6. **Iterate**: No project is perfect on the first try; refine iteratively\n",
    "7. **Showcase Well**: A great README and demo are as important as the code itself\n",
    "8. **Study Production Systems**: Read code from Django, Flask, PyTorch, etc.\n",
    "9. **Ask for Feedback**: Share your work and incorporate feedback\n",
    "10. **Document Your Journey**: Blog about challenges and solutions; it helps others and demonstrates skills\n",
    "\n",
    "---\n",
    "\n",
    "## Common Mistakes to Avoid\n",
    "\n",
    "1. **Scope Creep**: Adding too many features before MVP is done\n",
    "2. **Premature Optimization**: Optimizing before you know what the bottlenecks are\n",
    "3. **No Testing**: Skipping tests to \"save time\" (you'll lose more time debugging later)\n",
    "4. **Poor Documentation**: Assuming code is self-documenting\n",
    "5. **Analysis Paralysis**: Over-planning instead of starting to build\n",
    "6. **Ignoring Security**: Not considering security until it's too late\n",
    "7. **Tight Coupling**: Not designing for modularity and testability\n",
    "8. **No Monitoring**: Deploying without visibility into system health\n",
    "9. **Perfect Code Syndrome**: Endlessly refactoring instead of shipping\n",
    "10. **Not Using Version Control**: Not committing frequently or writing poor commit messages\n",
    "\n",
    "---\n",
    "\n",
    "## Pro Tips\n",
    "\n",
    "1. **Use Design Patterns**: They're battle-tested solutions to common problems\n",
    "2. **Write Tests First**: TDD helps you design better APIs\n",
    "3. **Commit Often**: Small, focused commits with good messages\n",
    "4. **Automate Everything**: Tests, linting, deployment\n",
    "5. **Measure Performance**: Profile before optimizing; measure after\n",
    "6. **Read the Source**: Study how professional projects structure their code\n",
    "7. **Peer Review**: Get code reviews even for personal projects\n",
    "8. **Use Type Hints**: They catch bugs and improve IDE support\n",
    "9. **Configuration Management**: Use environment variables, config files\n",
    "10. **Keep Learning**: Technologies evolve; stay current with best practices\n",
    "\n",
    "---\n",
    "\n",
    "## Resources for Advanced Projects\n",
    "\n",
    "### Books\n",
    "- **Designing Data-Intensive Applications** (Martin Kleppmann) - Distributed systems\n",
    "- **Deep Learning** (Goodfellow, Bengio, Courville) - ML fundamentals\n",
    "- **Crafting Interpreters** (Robert Nystrom) - Language implementation\n",
    "- **Operating Systems: Three Easy Pieces** (Arpaci-Dusseau) - OS concepts\n",
    "- **Clean Architecture** (Robert Martin) - Software design\n",
    "\n",
    "### Papers\n",
    "- Google: MapReduce, GFS, Bigtable, Spanner\n",
    "- Raft Consensus Algorithm\n",
    "- Attention Is All You Need (Transformers)\n",
    "- Papers With Code (for ML papers)\n",
    "\n",
    "### Courses\n",
    "- MIT 6.824 Distributed Systems\n",
    "- Stanford CS229 Machine Learning\n",
    "- Build Your Own X (github.com/codecrafters-io/build-your-own-x)\n",
    "\n",
    "### Communities\n",
    "- GitHub: Study popular projects\n",
    "- Stack Overflow: Ask and answer questions\n",
    "- Reddit: r/programming, r/MachineLearning\n",
    "- Discord: Python, ML, DevOps communities\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "**You're now ready to build production-quality systems!**\n",
    "\n",
    "1. **Choose Your Project**: Pick something that excites you\n",
    "2. **Create Design Doc**: Plan before coding\n",
    "3. **Build MVP**: Get something working in 1-2 weeks\n",
    "4. **Iterate**: Add features incrementally\n",
    "5. **Deploy**: Make it accessible\n",
    "6. **Share**: GitHub, blog post, demo video\n",
    "7. **Get Feedback**: Learn from others\n",
    "8. **Start Next Project**: Keep building!\n",
    "\n",
    "Remember: The journey from tutorial to production-ready project is challenging but incredibly rewarding. Each project makes you a better engineer.\n",
    "\n",
    "**Good luck building! 🚀**\n",
    "\n",
    "---\n",
    "\n",
    "*Questions? Stuck on your project? The best way to learn is by doing and asking questions when you're blocked. Use Stack Overflow, GitHub discussions, or relevant Discord/Slack communities.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
