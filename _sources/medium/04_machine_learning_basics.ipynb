{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Machine Learning Basics\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Machine Learning is teaching computers to learn from data rather than explicitly programming every rule. It's like teaching a child to recognize animals by showing them pictures instead of describing every detail.\n",
    "\n",
    "**Why Machine Learning Matters:**\n",
    "- **Pattern Recognition**: Find patterns humans can't easily see\n",
    "- **Predictions**: Forecast future events based on historical data\n",
    "- **Automation**: Make decisions without constant human intervention\n",
    "- **Scale**: Process vast amounts of data quickly\n",
    "\n",
    "**What You'll Learn:**\n",
    "- ML fundamentals and terminology\n",
    "- Supervised learning (classification & regression)\n",
    "- Unsupervised learning (clustering)\n",
    "- Data preprocessing and feature engineering\n",
    "- Model evaluation and validation\n",
    "- Cross-validation and hyperparameter tuning\n",
    "- Avoiding overfitting and underfitting\n",
    "- Real-world ML workflows\n",
    "\n",
    "**Prerequisites**: Install scikit-learn: `pip install scikit-learn numpy pandas matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning Fundamentals\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Features (X)**: Input variables used for prediction (like house size, location)\n",
    "- **Labels/Target (y)**: Output variable we want to predict (like house price)\n",
    "- **Training**: Learning patterns from data\n",
    "- **Testing**: Evaluating how well the model learned\n",
    "- **Model**: Mathematical representation of patterns learned from data\n",
    "\n",
    "### Types of Machine Learning\n",
    "\n",
    "**1. Supervised Learning** (Learning with a teacher)\n",
    "- Have labeled examples: input ‚Üí known output\n",
    "- Goal: Learn to predict outputs for new inputs\n",
    "- Examples: Email spam detection, image recognition, price prediction\n",
    "\n",
    "**2. Unsupervised Learning** (Learning without labels)\n",
    "- Have only inputs, no labels\n",
    "- Goal: Find hidden patterns or structure\n",
    "- Examples: Customer segmentation, anomaly detection\n",
    "\n",
    "**3. Reinforcement Learning** (Learning through trial and error)\n",
    "- Learn by interacting with environment\n",
    "- Get rewards or penalties for actions\n",
    "- Examples: Game AI, robotics, recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your First ML Model: Classification\n",
    "\n",
    "Classification assigns inputs to categories. Let's predict flower species!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the famous iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: sepal/petal measurements\n",
    "y = iris.target  # Labels: flower species (0, 1, or 2)\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature names: {iris.feature_names}\")\n",
    "print(f\"Species: {iris.target_names}\")\n",
    "print(f\"\\nFirst 5 samples:\")\n",
    "print(pd.DataFrame(X[:5], columns=iris.feature_names))\n",
    "print(f\"\\nTheir species: {[iris.target_names[i] for i in y[:5]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "**Critical concept**: Never test on training data!\n",
    "\n",
    "- **Training set**: Data the model learns from (typically 70-80%)\n",
    "- **Test set**: Unseen data to evaluate performance (20-30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nClass distribution in training:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for species_id, count in zip(unique, counts):\n",
    "    print(f\"  {iris.target_names[species_id]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree classifier\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=3,  # Limit tree depth to avoid overfitting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Tree depth: {model.get_depth()}\")\n",
    "print(f\"Number of leaves: {model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Show predictions vs actual\n",
    "print(\"Predictions vs Actual (first 10):\")\n",
    "for i in range(10):\n",
    "    pred_species = iris.target_names[y_pred[i]]\n",
    "    actual_species = iris.target_names[y_test[i]]\n",
    "    correct = \"‚úì\" if y_pred[i] == y_test[i] else \"‚úó\"\n",
    "    print(f\"{correct} Predicted: {pred_species:15} Actual: {actual_species}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"Actual {name}\" for name in iris.target_names],\n",
    "    columns=[f\"Pred {name}\" for name in iris.target_names]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression: Predicting Continuous Values\n",
    "\n",
    "Regression predicts numeric values instead of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Simple dataset: house size -> price\n",
    "house_sizes = np.array([1000, 1200, 1500, 1800, 2000, 2200, 2500, 2800, 3000, 3500]).reshape(-1, 1)\n",
    "prices = np.array([150, 180, 210, 240, 280, 300, 340, 380, 420, 500])  # in thousands\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    house_sizes, prices, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "print(\"House Price Predictions:\")\n",
    "for size, actual, pred in zip(X_test.flatten(), y_test, y_pred):\n",
    "    error = abs(actual - pred)\n",
    "    print(f\"Size: {size:4.0f} sq ft | Actual: ${actual:3.0f}k | Predicted: ${pred:3.0f}k | Error: ${error:.1f}k\")\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nMean Squared Error: {mse:.2f}\")\n",
    "print(f\"R¬≤ Score: {r2:.2f} (1.0 is perfect)\")\n",
    "\n",
    "# Model coefficients\n",
    "print(f\"\\nModel equation: Price = {reg_model.intercept_:.2f} + {reg_model.coef_[0]:.4f} √ó Size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Algorithm Comparison\n",
    "\n",
    "Try different algorithms to find the best one for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load iris data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Dictionary of models to compare\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name:25} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Find best model\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"\\nBest model: {best_model} with {results[best_model] * 100:.2f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Creating new features can dramatically improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Original features\n",
    "print(\"Original features:\")\n",
    "print(iris.feature_names)\n",
    "\n",
    "# Create new features\n",
    "# Feature engineering: combine existing features\n",
    "sepal_area = X[:, 0] * X[:, 1]  # sepal length * sepal width\n",
    "petal_area = X[:, 2] * X[:, 3]  # petal length * petal width\n",
    "sepal_to_petal_ratio = (X[:, 0] + X[:, 1]) / (X[:, 2] + X[:, 3])\n",
    "\n",
    "# Combine original and new features\n",
    "X_engineered = np.column_stack([X, sepal_area, petal_area, sepal_to_petal_ratio])\n",
    "\n",
    "print(f\"\\nOriginal features: {X.shape[1]}\")\n",
    "print(f\"Engineered features: {X_engineered.shape[1]}\")\n",
    "\n",
    "# Compare models with and without feature engineering\n",
    "for features, name in [(X, \"Original\"), (X_engineered, \"Engineered\")]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"{name:12} features accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n",
    "\n",
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create data with missing values\n",
    "X_with_missing = np.array([\n",
    "    [1, 2],\n",
    "    [np.nan, 3],\n",
    "    [7, 6],\n",
    "    [5, np.nan]\n",
    "])\n",
    "\n",
    "print(\"Data with missing values:\")\n",
    "print(X_with_missing)\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_with_missing)\n",
    "\n",
    "print(\"\\nAfter imputation (mean):\")\n",
    "print(X_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Many algorithms perform better when features are on similar scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Sample data with different scales\n",
    "data = np.array([\n",
    "    [1000, 2],      # House: size in sq ft, bedrooms\n",
    "    [1500, 3],\n",
    "    [2000, 4]\n",
    "])\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "\n",
    "# Standard scaling (mean=0, std=1)\n",
    "scaler_std = StandardScaler()\n",
    "data_standardized = scaler_std.fit_transform(data)\n",
    "print(\"\\nStandardized (mean=0, std=1):\")\n",
    "print(data_standardized)\n",
    "\n",
    "# Min-Max scaling (range 0-1)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_normalized = scaler_minmax.fit_transform(data)\n",
    "print(\"\\nNormalized (range 0-1):\")\n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation\n",
    "\n",
    "Get more reliable performance estimates by testing on multiple splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Create model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print(\"Cross-Validation Scores (5 folds):\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nMean accuracy: {cv_scores.mean() * 100:.2f}%\")\n",
    "print(f\"Std deviation: {cv_scores.std() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning\n",
    "\n",
    "Find the best settings for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    dt, param_grid, cv=5, scoring='accuracy', verbose=1\n",
    ")\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_ * 100:.2f}%\")\n",
    "\n",
    "# Use best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Overfitting vs Underfitting\n",
    "\n",
    "### Understanding the Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test different tree depths\n",
    "depths = [1, 2, 3, 5, 10, 20]\n",
    "\n",
    "print(\"Tree Depth | Train Acc | Test Acc | Status\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for depth in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    \n",
    "    # Diagnose overfitting/underfitting\n",
    "    if train_acc < 0.85:\n",
    "        status = \"Underfitting\"\n",
    "    elif train_acc - test_acc > 0.1:\n",
    "        status = \"Overfitting\"\n",
    "    else:\n",
    "        status = \"Good fit\"\n",
    "    \n",
    "    print(f\"    {depth:2d}     |  {train_acc:.2f}    |  {test_acc:.2f}   | {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Unsupervised Learning: Clustering\n",
    "\n",
    "Find natural groupings in data without labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Customer data: [age, annual_income_k]\n",
    "customers = np.array([\n",
    "    [25, 40], [27, 45], [30, 48], [32, 50], [35, 52],  # Young, moderate income\n",
    "    [45, 80], [48, 85], [50, 90], [52, 88], [55, 95],  # Middle-age, high income\n",
    "    [60, 30], [62, 32], [65, 35], [67, 28], [70, 25]   # Senior, low income\n",
    "])\n",
    "\n",
    "# Try different numbers of clusters\n",
    "print(\"Finding optimal number of clusters...\\n\")\n",
    "for k in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(customers)\n",
    "    \n",
    "    # Silhouette score: measures cluster quality (-1 to 1, higher is better)\n",
    "    score = silhouette_score(customers, clusters)\n",
    "    print(f\"k={k}: Silhouette Score = {score:.3f}\")\n",
    "\n",
    "# Use 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(customers)\n",
    "\n",
    "print(\"\\nCustomer Segments:\")\n",
    "for i in range(3):\n",
    "    cluster_customers = customers[clusters == i]\n",
    "    avg_age = cluster_customers[:, 0].mean()\n",
    "    avg_income = cluster_customers[:, 1].mean()\n",
    "    print(f\"Cluster {i}: {len(cluster_customers)} customers, Avg Age: {avg_age:.0f}, Avg Income: ${avg_income:.0f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Importance\n",
    "\n",
    "Understand which features matter most for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Train Random Forest (provides feature importance)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort features by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "for i, idx in enumerate(indices, 1):\n",
    "    print(f\"{i}. {iris.feature_names[idx]:20} {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Complete ML Workflow Example\n",
    "\n",
    "Putting it all together with best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Load and explore data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "# 2. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Create pipeline (preprocessing + model)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale features\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Model\n",
    "])\n",
    "\n",
    "# 4. Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# 5. Grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='accuracy'\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate on test set\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Test score: {test_score * 100:.2f}%\")\n",
    "\n",
    "# 7. Make predictions on new data\n",
    "new_flowers = np.array([[5.0, 3.5, 1.5, 0.2], [6.5, 3.0, 5.5, 2.0]])\n",
    "predictions = grid_search.predict(new_flowers)\n",
    "print(f\"\\nPredictions for new flowers: {[iris.target_names[p] for p in predictions]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Binary Classification\n",
    "\n",
    "Create a simple spam classifier:\n",
    "- Features: [word_count, has_money_keywords, has_urgent_keywords, num_links]\n",
    "- Label: 0 (not spam) or 1 (spam)\n",
    "- Create 20 sample emails\n",
    "- Train a model and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Regression Challenge\n",
    "\n",
    "Predict student test scores based on:\n",
    "- Hours studied\n",
    "- Hours slept\n",
    "- Previous test score\n",
    "\n",
    "Create synthetic data for 50 students and build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Customer Segmentation\n",
    "\n",
    "Use K-Means to segment customers based on:\n",
    "- Purchase frequency (purchases per month)\n",
    "- Average purchase value\n",
    "\n",
    "Create 30 synthetic customers and find 3-4 meaningful segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Model Comparison\n",
    "\n",
    "Compare 5 different classification algorithms on the iris dataset:\n",
    "- Use cross-validation\n",
    "- Report mean and std of accuracy\n",
    "- Identify the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Check Quiz\n",
    "\n",
    "**1. What's the difference between supervised and unsupervised learning?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Supervised learning uses labeled data (input-output pairs) to learn predictions. Unsupervised learning finds patterns in unlabeled data.\n",
    "</details>\n",
    "\n",
    "**2. Why do we split data into training and test sets?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "To evaluate how well the model generalizes to new, unseen data. Testing on training data would give overly optimistic results.\n",
    "</details>\n",
    "\n",
    "**3. What is overfitting?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "When a model learns the training data too well, including noise and outliers, resulting in poor performance on new data.\n",
    "</details>\n",
    "\n",
    "**4. What does cross-validation do?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Tests model performance on multiple train-test splits to get a more reliable estimate of how well it will generalize.\n",
    "</details>\n",
    "\n",
    "**5. When should you scale features?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "When features have different scales/units and using distance-based algorithms (KNN, SVM, neural networks) or gradient descent.\n",
    "</details>\n",
    "\n",
    "**6. What's the difference between classification and regression?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Classification predicts categories/classes. Regression predicts continuous numeric values.\n",
    "</details>\n",
    "\n",
    "**7. What is feature engineering?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Creating new features from existing ones to improve model performance (e.g., combining features, extracting information).\n",
    "</details>\n",
    "\n",
    "**8. What does the R¬≤ score measure in regression?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "How well the model explains variance in the data. 1.0 is perfect, 0 means the model is no better than predicting the mean.\n",
    "</details>\n",
    "\n",
    "**9. What is a hyperparameter?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "A setting you configure before training (e.g., tree depth, number of neighbors) that controls how the algorithm learns.\n",
    "</details>\n",
    "\n",
    "**10. What does K-Means clustering do?**\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Groups data into K clusters where points in the same cluster are similar to each other.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "‚úÖ **Supervised learning** uses labeled data; **unsupervised** finds patterns without labels\n",
    "\n",
    "‚úÖ **Always split data** into training and test sets\n",
    "\n",
    "‚úÖ **Classification** predicts categories; **regression** predicts numbers\n",
    "\n",
    "‚úÖ **Cross-validation** provides more reliable performance estimates\n",
    "\n",
    "‚úÖ **Feature engineering** can dramatically improve model performance\n",
    "\n",
    "‚úÖ **Feature scaling** is crucial for distance-based algorithms\n",
    "\n",
    "‚úÖ **Overfitting** happens when model memorizes training data\n",
    "\n",
    "‚úÖ **Hyperparameter tuning** optimizes model settings\n",
    "\n",
    "‚úÖ **Pipelines** combine preprocessing and modeling steps\n",
    "\n",
    "‚úÖ **Compare multiple algorithms** to find the best one for your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pro Tips\n",
    "\n",
    "üí° **Start simple** - Begin with simple models before trying complex ones\n",
    "\n",
    "üí° **More data beats better algorithms** - Focus on getting quality data\n",
    "\n",
    "üí° **Check class balance** - Imbalanced classes need special handling\n",
    "\n",
    "üí° **Use stratified splits** - Maintains class proportions in train/test sets\n",
    "\n",
    "üí° **Feature engineering > model tuning** - Often gives bigger improvements\n",
    "\n",
    "üí° **Set random_state** - Makes results reproducible\n",
    "\n",
    "üí° **Monitor train vs test performance** - Detects overfitting early\n",
    "\n",
    "üí° **Use pipelines** - Prevents data leakage and simplifies code\n",
    "\n",
    "üí° **Understand your metrics** - Accuracy isn't always the right choice\n",
    "\n",
    "üí° **Domain knowledge matters** - Understanding the problem helps feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Mistakes to Avoid\n",
    "\n",
    "‚ùå **Testing on training data** - Always use separate test set\n",
    "‚úÖ Use train_test_split or cross-validation\n",
    "\n",
    "‚ùå **Not scaling features** - Can hurt model performance\n",
    "‚úÖ Use StandardScaler or MinMaxScaler when needed\n",
    "\n",
    "‚ùå **Ignoring class imbalance** - Model biased toward majority class\n",
    "‚úÖ Use stratified sampling, SMOTE, or adjust class weights\n",
    "\n",
    "‚ùå **Using too complex models** - Leads to overfitting\n",
    "‚úÖ Start simple, add complexity only if needed\n",
    "\n",
    "‚ùå **Not handling missing values** - Many models can't handle NaN\n",
    "‚úÖ Use imputation or remove missing data strategically\n",
    "\n",
    "‚ùå **Forgetting to set random_state** - Results not reproducible\n",
    "‚úÖ Always set random_state for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You now understand ML fundamentals! Next topics:\n",
    "\n",
    "1. **Deep Learning** - Neural networks with TensorFlow/PyTorch\n",
    "2. **Natural Language Processing** - Text classification, sentiment analysis\n",
    "3. **Computer Vision** - Image classification, object detection\n",
    "4. **Time Series Analysis** - Forecasting, trend analysis\n",
    "5. **Model Deployment** - Serving models in production\n",
    "\n",
    "**Practice Projects:**\n",
    "- Build a movie recommendation system\n",
    "- Create a sentiment analyzer for product reviews\n",
    "- Predict stock prices using historical data\n",
    "- Build a customer churn prediction model\n",
    "\n",
    "**Resources:**\n",
    "- Scikit-learn documentation: https://scikit-learn.org\n",
    "- Kaggle competitions for practice: https://kaggle.com\n",
    "- Andrew Ng's ML course: https://coursera.org/learn/machine-learning\n",
    "\n",
    "Machine Learning is transforming every industry - keep practicing! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
