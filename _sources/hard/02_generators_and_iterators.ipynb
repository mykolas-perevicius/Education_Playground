{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Lesson 02: Generators and Iterators - Memory-Efficient Data Processing\n",
    "\n",
    "Master the art of memory-efficient data processing using generators, iterators, and coroutines.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "- ‚úÖ Understand the iterator protocol and implement custom iterators\n",
    "- ‚úÖ Create generator functions using `yield` for lazy evaluation\n",
    "- ‚úÖ Build memory-efficient data pipelines with generator expressions\n",
    "- ‚úÖ Use advanced generator patterns: `yield from`, `send()`, `throw()`, `close()`\n",
    "- ‚úÖ Implement coroutines for cooperative multitasking\n",
    "- ‚úÖ Create infinite sequences and bounded iterators\n",
    "- ‚úÖ Apply generators to real-world problems (file processing, data streaming)\n",
    "- ‚úÖ Analyze memory and performance tradeoffs\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Strong understanding of Python functions and scope\n",
    "- Familiarity with decorators and closures\n",
    "- Knowledge of list comprehensions\n",
    "- Understanding of memory management concepts\n",
    "\n",
    "## Why Generators and Iterators Matter\n",
    "\n",
    "**Real-World Applications**:\n",
    "- **Big Data Processing**: Stream terabytes of data without loading into memory\n",
    "- **Web Scraping**: Process paginated results efficiently\n",
    "- **Log Analysis**: Parse multi-gigabyte log files line by line\n",
    "- **Machine Learning**: Generate training batches on-the-fly\n",
    "- **ETL Pipelines**: Transform data streams in real-time\n",
    "- **API Rate Limiting**: Control request timing with generator-based delays\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Iterator Protocol - Building Blocks of Iteration\n",
    "\n",
    "### What is an Iterator?\n",
    "\n",
    "An **iterator** is an object that implements two methods:\n",
    "- `__iter__()`: Returns the iterator object itself\n",
    "- `__next__()`: Returns the next value or raises `StopIteration`\n",
    "\n",
    "This protocol enables the `for` loop and other iteration contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding how iteration works under the hood\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# When you use 'for', Python calls iter() to get an iterator\n",
    "iterator = iter(numbers)\n",
    "print(f\"Iterator object: {iterator}\")\n",
    "print(f\"Type: {type(iterator)}\")\n",
    "\n",
    "# Then repeatedly calls next() until StopIteration\n",
    "print(f\"\\nManual iteration:\")\n",
    "print(next(iterator))  # 1\n",
    "print(next(iterator))  # 2\n",
    "print(next(iterator))  # 3\n",
    "print(next(iterator))  # 4\n",
    "print(next(iterator))  # 5\n",
    "# print(next(iterator))  # Would raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Iterator\n",
    "\n",
    "Let's build a custom iterator from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Countdown:\n",
    "    \"\"\"\n",
    "    Custom iterator that counts down from a number.\n",
    "    \n",
    "    This demonstrates the iterator protocol:\n",
    "    - __iter__() returns self (the iterator object)\n",
    "    - __next__() returns next value or raises StopIteration\n",
    "    \"\"\"\n",
    "    def __init__(self, start):\n",
    "        self.current = start\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Return the iterator object (self).\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        \"\"\"Return the next value or raise StopIteration.\"\"\"\n",
    "        if self.current <= 0:\n",
    "            raise StopIteration\n",
    "        \n",
    "        value = self.current\n",
    "        self.current -= 1\n",
    "        return value\n",
    "\n",
    "# Using the custom iterator\n",
    "print(\"Countdown from 5:\")\n",
    "counter = Countdown(5)\n",
    "for num in counter:\n",
    "    print(num, end=\" \")\n",
    "\n",
    "# Can't iterate again (iterator is exhausted)\n",
    "print(\"\\n\\nTrying to iterate again:\")\n",
    "for num in counter:\n",
    "    print(num, end=\" \")\n",
    "print(\"(Nothing printed - iterator exhausted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterable vs Iterator\n",
    "\n",
    "**Important distinction**:\n",
    "- **Iterable**: Object that can return an iterator (has `__iter__()`)\n",
    "- **Iterator**: Object that produces values (has `__iter__()` and `__next__()`)\n",
    "\n",
    "An iterable can be iterated multiple times, an iterator is single-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountdownIterable:\n",
    "    \"\"\"\n",
    "    An ITERABLE (not iterator) that creates new iterators.\n",
    "    This allows multiple iterations.\n",
    "    \"\"\"\n",
    "    def __init__(self, start):\n",
    "        self.start = start\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Return a NEW iterator each time.\"\"\"\n",
    "        return CountdownIterator(self.start)\n",
    "\n",
    "class CountdownIterator:\n",
    "    \"\"\"The actual iterator.\"\"\"\n",
    "    def __init__(self, start):\n",
    "        self.current = start\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current <= 0:\n",
    "            raise StopIteration\n",
    "        value = self.current\n",
    "        self.current -= 1\n",
    "        return value\n",
    "\n",
    "# Now we can iterate multiple times\n",
    "countdown = CountdownIterable(3)\n",
    "\n",
    "print(\"First iteration:\")\n",
    "for num in countdown:\n",
    "    print(num, end=\" \")\n",
    "\n",
    "print(\"\\n\\nSecond iteration:\")\n",
    "for num in countdown:\n",
    "    print(num, end=\" \")\n",
    "\n",
    "print(\"\\n\\nWorks because each 'for' gets a fresh iterator!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Generator Functions - Elegant Iterators\n",
    "\n",
    "### Why Generators?\n",
    "\n",
    "Writing custom iterator classes is verbose. **Generators** provide a simpler syntax using the `yield` keyword.\n",
    "\n",
    "**Key Benefits**:\n",
    "- **Simple Syntax**: No need for `__iter__()` and `__next__()`\n",
    "- **Automatic State Management**: Local variables are preserved between calls\n",
    "- **Memory Efficient**: Values are generated on-demand\n",
    "- **Lazy Evaluation**: Compute only what's needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdown(n):\n",
    "    \"\"\"\n",
    "    Generator function for counting down.\n",
    "    \n",
    "    Much simpler than the class-based iterator!\n",
    "    \"\"\"\n",
    "    while n > 0:\n",
    "        yield n  # Pause here and return n\n",
    "        n -= 1   # Resume here on next call\n",
    "\n",
    "# Using the generator\n",
    "print(\"Countdown from 5:\")\n",
    "for num in countdown(5):\n",
    "    print(num, end=\" \")\n",
    "\n",
    "# Generators are single-use (like iterators)\n",
    "gen = countdown(3)\n",
    "print(\"\\n\\nFirst iteration:\", list(gen))\n",
    "print(\"Second iteration:\", list(gen))  # Empty!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Generators Work: Execution Flow\n",
    "\n",
    "When you call a generator function:\n",
    "1. It returns a **generator object** (doesn't execute the body)\n",
    "2. Calling `next()` executes until the first `yield`\n",
    "3. `yield` pauses execution and returns a value\n",
    "4. Next `next()` call resumes after the `yield`\n",
    "5. When function ends, raises `StopIteration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_generator():\n",
    "    \"\"\"Demonstrate generator execution flow.\"\"\"\n",
    "    print(\"  [Generator started]\")\n",
    "    \n",
    "    print(\"  [About to yield 1]\")\n",
    "    yield 1\n",
    "    \n",
    "    print(\"  [Resumed after yield 1]\")\n",
    "    print(\"  [About to yield 2]\")\n",
    "    yield 2\n",
    "    \n",
    "    print(\"  [Resumed after yield 2]\")\n",
    "    print(\"  [About to yield 3]\")\n",
    "    yield 3\n",
    "    \n",
    "    print(\"  [Generator ending]\")\n",
    "\n",
    "print(\"Creating generator:\")\n",
    "gen = demo_generator()\n",
    "print(f\"Type: {type(gen)}\\n\")\n",
    "\n",
    "print(\"First next():\")\n",
    "value = next(gen)\n",
    "print(f\"Got value: {value}\\n\")\n",
    "\n",
    "print(\"Second next():\")\n",
    "value = next(gen)\n",
    "print(f\"Got value: {value}\\n\")\n",
    "\n",
    "print(\"Third next():\")\n",
    "value = next(gen)\n",
    "print(f\"Got value: {value}\\n\")\n",
    "\n",
    "print(\"Fourth next() (will raise StopIteration):\")\n",
    "try:\n",
    "    next(gen)\n",
    "except StopIteration:\n",
    "    print(\"StopIteration raised!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic Example: Fibonacci Sequence\n",
    "\n",
    "Generators shine when producing sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    \"\"\"\n",
    "    Generate the first n Fibonacci numbers.\n",
    "    \n",
    "    Memory efficient: doesn't store all numbers in a list.\n",
    "    \"\"\"\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "\n",
    "print(\"First 15 Fibonacci numbers:\")\n",
    "for i, fib in enumerate(fibonacci(15), 1):\n",
    "    print(f\"F({i}) = {fib}\")\n",
    "\n",
    "# Can convert to list if needed\n",
    "print(\"\\nAs a list:\", list(fibonacci(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Memory Efficiency - The Power of Lazy Evaluation\n",
    "\n",
    "### List vs Generator: Memory Comparison\n",
    "\n",
    "Let's see why generators are memory-efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# List approach: stores all values in memory\n",
    "def squares_list(n):\n",
    "    \"\"\"Return list of squares from 0 to n-1.\"\"\"\n",
    "    return [x**2 for x in range(n)]\n",
    "\n",
    "# Generator approach: computes on-demand\n",
    "def squares_generator(n):\n",
    "    \"\"\"Yield squares from 0 to n-1.\"\"\"\n",
    "    for x in range(n):\n",
    "        yield x**2\n",
    "\n",
    "# Compare memory usage\n",
    "n = 100000\n",
    "\n",
    "# List version\n",
    "squares_l = squares_list(n)\n",
    "list_size = sys.getsizeof(squares_l)\n",
    "print(f\"List of {n:,} squares:\")\n",
    "print(f\"  Memory: {list_size:,} bytes ({list_size / 1024 / 1024:.2f} MB)\")\n",
    "print(f\"  First 5: {squares_l[:5]}\")\n",
    "\n",
    "# Generator version\n",
    "squares_g = squares_generator(n)\n",
    "gen_size = sys.getsizeof(squares_g)\n",
    "print(f\"\\nGenerator for {n:,} squares:\")\n",
    "print(f\"  Memory: {gen_size:,} bytes ({gen_size / 1024:.2f} KB)\")\n",
    "print(f\"  First 5: {[next(squares_g) for _ in range(5)]}\")\n",
    "\n",
    "# Memory savings\n",
    "savings = (list_size - gen_size) / list_size * 100\n",
    "print(f\"\\nüéØ Memory savings: {savings:.2f}%\")\n",
    "print(f\"   ({list_size / gen_size:.0f}x smaller)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Expressions\n",
    "\n",
    "Like list comprehensions, but with `()` instead of `[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension - creates entire list\n",
    "list_comp = [x**2 for x in range(10)]\n",
    "print(f\"List comprehension: {list_comp}\")\n",
    "print(f\"Type: {type(list_comp)}\")\n",
    "print(f\"Size: {sys.getsizeof(list_comp)} bytes\\n\")\n",
    "\n",
    "# Generator expression - creates generator\n",
    "gen_exp = (x**2 for x in range(10))\n",
    "print(f\"Generator expression: {gen_exp}\")\n",
    "print(f\"Type: {type(gen_exp)}\")\n",
    "print(f\"Size: {sys.getsizeof(gen_exp)} bytes\")\n",
    "print(f\"Values: {list(gen_exp)}\")\n",
    "\n",
    "# Perfect for operations that don't need the full list\n",
    "print(\"\\nüéØ Use cases for generator expressions:\")\n",
    "\n",
    "# Sum (only needs one value at a time)\n",
    "total = sum(x**2 for x in range(1000000))\n",
    "print(f\"Sum of first million squares: {total:,}\")\n",
    "\n",
    "# Any/all (can short-circuit)\n",
    "has_large = any(x > 50 for x in range(100))\n",
    "print(f\"Has number > 50: {has_large}\")\n",
    "\n",
    "# Max/min\n",
    "largest = max(x**2 for x in range(1000))\n",
    "print(f\"Largest square: {largest:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Example: Processing Large Files\n",
    "\n",
    "Generators excel at processing large files line by line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_file(filename):\n",
    "    \"\"\"\n",
    "    Generator that processes file line by line.\n",
    "    \n",
    "    Memory-efficient: doesn't load entire file into memory.\n",
    "    Useful for multi-gigabyte log files.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:  # File objects are iterators!\n",
    "            # Process each line\n",
    "            cleaned = line.strip()\n",
    "            if cleaned and not cleaned.startswith('#'):\n",
    "                yield cleaned\n",
    "\n",
    "def count_errors_in_log(filename):\n",
    "    \"\"\"Count ERROR lines in a log file (memory-efficient).\"\"\"\n",
    "    return sum(1 for line in process_large_file(filename) \n",
    "               if 'ERROR' in line)\n",
    "\n",
    "# Example simulation (without actual file)\n",
    "def simulate_log_lines():\n",
    "    \"\"\"Simulate log file processing.\"\"\"\n",
    "    logs = [\n",
    "        \"INFO: Application started\",\n",
    "        \"DEBUG: Loading config\",\n",
    "        \"ERROR: Failed to connect to database\",\n",
    "        \"INFO: Retrying connection\",\n",
    "        \"ERROR: Connection timeout\",\n",
    "        \"INFO: Using fallback database\",\n",
    "        \"# This is a comment\",\n",
    "        \"\",\n",
    "        \"ERROR: Invalid user input\",\n",
    "    ]\n",
    "    for log in logs:\n",
    "        yield log.strip()\n",
    "\n",
    "print(\"Processing log file:\")\n",
    "error_count = sum(1 for line in simulate_log_lines() \n",
    "                  if line and not line.startswith('#') and 'ERROR' in line)\n",
    "print(f\"Found {error_count} errors\")\n",
    "\n",
    "print(\"\\nüìä Log summary:\")\n",
    "log_types = {}\n",
    "for line in simulate_log_lines():\n",
    "    if line and not line.startswith('#'):\n",
    "        log_type = line.split(':')[0] if ':' in line else 'UNKNOWN'\n",
    "        log_types[log_type] = log_types.get(log_type, 0) + 1\n",
    "\n",
    "for log_type, count in sorted(log_types.items()):\n",
    "    print(f\"  {log_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Generator Pipelines - Composing Data Transformations\n",
    "\n",
    "### Building Data Pipelines\n",
    "\n",
    "Generators can be chained to create elegant data processing pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(n=20):\n",
    "    \"\"\"Stage 1: Generate data source.\"\"\"\n",
    "    print(\"[Stage 1: Generating data]\")\n",
    "    for i in range(1, n + 1):\n",
    "        yield i\n",
    "\n",
    "def filter_even(numbers):\n",
    "    \"\"\"Stage 2: Filter only even numbers.\"\"\"\n",
    "    print(\"[Stage 2: Filtering even numbers]\")\n",
    "    for num in numbers:\n",
    "        if num % 2 == 0:\n",
    "            print(f\"  ‚úì {num} is even\")\n",
    "            yield num\n",
    "        else:\n",
    "            print(f\"  ‚úó {num} is odd (skipped)\")\n",
    "\n",
    "def square(numbers):\n",
    "    \"\"\"Stage 3: Square each number.\"\"\"\n",
    "    print(\"[Stage 3: Squaring numbers]\")\n",
    "    for num in numbers:\n",
    "        result = num ** 2\n",
    "        print(f\"  {num}¬≤ = {result}\")\n",
    "        yield result\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"\"\"Stage 4: Take only first n items.\"\"\"\n",
    "    print(f\"[Stage 4: Taking first {n} items]\")\n",
    "    for i, item in enumerate(iterable):\n",
    "        if i >= n:\n",
    "            break\n",
    "        yield item\n",
    "\n",
    "# Build the pipeline\n",
    "print(\"Building pipeline: data ‚Üí filter_even ‚Üí square ‚Üí take(5)\\n\")\n",
    "pipeline = take(5, square(filter_even(read_data(20))))\n",
    "\n",
    "print(\"\\nExecuting pipeline (lazy evaluation):\")\n",
    "print(\"=\"*50)\n",
    "result = list(pipeline)\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nFinal result: {result}\")\n",
    "print(f\"\\nüéØ Notice: Each stage processes on-demand!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Pattern: ETL (Extract, Transform, Load)\n",
    "\n",
    "A common pattern in data engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_records():\n",
    "    \"\"\"Extract: Simulate reading from data source.\"\"\"\n",
    "    records = [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\"},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"age\": 25, \"city\": \"LA\"},\n",
    "        {\"id\": 3, \"name\": \"Charlie\", \"age\": 35, \"city\": \"NYC\"},\n",
    "        {\"id\": 4, \"name\": \"David\", \"age\": 28, \"city\": \"SF\"},\n",
    "        {\"id\": 5, \"name\": \"Eve\", \"age\": 32, \"city\": \"NYC\"},\n",
    "    ]\n",
    "    for record in records:\n",
    "        yield record\n",
    "\n",
    "def transform_filter_city(records, city):\n",
    "    \"\"\"Transform: Filter by city.\"\"\"\n",
    "    for record in records:\n",
    "        if record['city'] == city:\n",
    "            yield record\n",
    "\n",
    "def transform_add_category(records):\n",
    "    \"\"\"Transform: Add age category.\"\"\"\n",
    "    for record in records:\n",
    "        if record['age'] < 30:\n",
    "            record['category'] = 'Young'\n",
    "        else:\n",
    "            record['category'] = 'Senior'\n",
    "        yield record\n",
    "\n",
    "def load_to_storage(records):\n",
    "    \"\"\"Load: Simulate saving to database.\"\"\"\n",
    "    results = []\n",
    "    for record in records:\n",
    "        print(f\"Saving: {record}\")\n",
    "        results.append(record)\n",
    "    return results\n",
    "\n",
    "# ETL Pipeline\n",
    "print(\"ETL Pipeline: Extract ‚Üí Filter(NYC) ‚Üí Add Category ‚Üí Load\\n\")\n",
    "pipeline = transform_add_category(\n",
    "    transform_filter_city(\n",
    "        extract_records(),\n",
    "        city='NYC'\n",
    "    )\n",
    ")\n",
    "\n",
    "saved_records = load_to_storage(pipeline)\n",
    "print(f\"\\n‚úÖ Loaded {len(saved_records)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Infinite Generators - Unbounded Sequences\n",
    "\n",
    "### Creating Infinite Sequences\n",
    "\n",
    "Generators can represent infinite sequences (use with caution!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_counter(start=0):\n",
    "    \"\"\"Generate infinite sequence of integers.\"\"\"\n",
    "    n = start\n",
    "    while True:  # Infinite loop!\n",
    "        yield n\n",
    "        n += 1\n",
    "\n",
    "# Safe: use with a limit\n",
    "counter = infinite_counter(100)\n",
    "print(\"First 10 numbers starting from 100:\")\n",
    "for _ in range(10):\n",
    "    print(next(counter), end=\" \")\n",
    "\n",
    "print(\"\\n\\nüîÅ Infinite Fibonacci:\")\n",
    "def fibonacci_infinite():\n",
    "    \"\"\"Generate Fibonacci numbers forever.\"\"\"\n",
    "    a, b = 0, 1\n",
    "    while True:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "\n",
    "# Take only what you need\n",
    "fib = fibonacci_infinite()\n",
    "print(\"First 20 Fibonacci numbers:\")\n",
    "for i, num in enumerate(fib):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(num, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Use: Cycle and Repeat Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle, repeat, islice\n",
    "\n",
    "# Cycle: repeat sequence infinitely\n",
    "colors = cycle(['red', 'green', 'blue'])\n",
    "print(\"Cycling through colors (first 10):\")\n",
    "for i, color in enumerate(colors):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"  {i}: {color}\")\n",
    "\n",
    "# Repeat: repeat single value\n",
    "print(\"\\nRepeat 'X' 5 times:\")\n",
    "for val in repeat('X', 5):\n",
    "    print(val, end=\" \")\n",
    "\n",
    "# Combining with zip for padding\n",
    "print(\"\\n\\nZipping with infinite repeat:\")\n",
    "names = ['Alice', 'Bob', 'Charlie']\n",
    "scores = [95, 87]  # Fewer scores than names\n",
    "\n",
    "# Pad scores with 0\n",
    "padded_scores = islice(iter(scores + [0] * len(names)), len(names))\n",
    "for name, score in zip(names, scores + [0] * len(names)):\n",
    "    print(f\"  {name}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Advanced Generator Features\n",
    "\n",
    "### Generator Methods: send(), throw(), close()\n",
    "\n",
    "Generators can receive values and exceptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_average():\n",
    "    \"\"\"\n",
    "    Coroutine that maintains a running average.\n",
    "    \n",
    "    Uses send() to receive values.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    average = None\n",
    "    \n",
    "    while True:\n",
    "        # Receive value sent via send()\n",
    "        value = yield average\n",
    "        \n",
    "        if value is None:\n",
    "            break\n",
    "        \n",
    "        total += value\n",
    "        count += 1\n",
    "        average = total / count\n",
    "\n",
    "# Create coroutine\n",
    "avg = running_average()\n",
    "\n",
    "# MUST call next() or send(None) to prime the coroutine\n",
    "next(avg)  # Advance to first yield\n",
    "\n",
    "print(\"Running average coroutine:\")\n",
    "print(f\"  Send 10: {avg.send(10)}\")\n",
    "print(f\"  Send 20: {avg.send(20)}\")\n",
    "print(f\"  Send 30: {avg.send(30)}\")\n",
    "print(f\"  Send 40: {avg.send(40)}\")\n",
    "print(f\"\\n‚úÖ Average of [10, 20, 30, 40] = {avg.send(50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using throw() to Send Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_with_exception_handling():\n",
    "    \"\"\"\n",
    "    Generator that can handle exceptions sent via throw().\n",
    "    \"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            value = yield\n",
    "            print(f\"  Received: {value}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Caught ValueError: {e}\")\n",
    "        yield \"Error handled\"\n",
    "    finally:\n",
    "        print(\"  üîö Generator closing\")\n",
    "\n",
    "gen = generator_with_exception_handling()\n",
    "next(gen)  # Prime\n",
    "\n",
    "print(\"Sending values:\")\n",
    "gen.send(10)\n",
    "gen.send(20)\n",
    "\n",
    "print(\"\\nThrowing exception:\")\n",
    "try:\n",
    "    result = gen.throw(ValueError, \"Invalid input!\")\n",
    "    print(f\"  Result after exception: {result}\")\n",
    "except StopIteration:\n",
    "    print(\"  Generator stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using close() to Stop a Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_with_cleanup():\n",
    "    \"\"\"\n",
    "    Generator with cleanup logic.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"  üîß Setting up resources...\")\n",
    "        for i in range(10):\n",
    "            yield i\n",
    "    finally:\n",
    "        print(\"  üßπ Cleaning up resources...\")\n",
    "\n",
    "gen = generator_with_cleanup()\n",
    "print(\"Getting first 3 values:\")\n",
    "for _ in range(3):\n",
    "    print(f\"  Value: {next(gen)}\")\n",
    "\n",
    "print(\"\\nClosing generator early:\")\n",
    "gen.close()\n",
    "\n",
    "print(\"\\nTrying to use closed generator:\")\n",
    "try:\n",
    "    next(gen)\n",
    "except StopIteration:\n",
    "    print(\"  ‚ùå Generator is closed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: yield from - Delegating to Subgenerators\n",
    "\n",
    "### Generator Delegation\n",
    "\n",
    "The `yield from` syntax delegates to another generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator1():\n",
    "    \"\"\"First generator.\"\"\"\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3\n",
    "\n",
    "def generator2():\n",
    "    \"\"\"Second generator.\"\"\"\n",
    "    yield 'a'\n",
    "    yield 'b'\n",
    "    yield 'c'\n",
    "\n",
    "# Without yield from (manual delegation)\n",
    "def combined_manual():\n",
    "    \"\"\"Manually combine generators.\"\"\"\n",
    "    for value in generator1():\n",
    "        yield value\n",
    "    for value in generator2():\n",
    "        yield value\n",
    "\n",
    "# With yield from (cleaner)\n",
    "def combined_yield_from():\n",
    "    \"\"\"Use yield from for delegation.\"\"\"\n",
    "    yield from generator1()\n",
    "    yield from generator2()\n",
    "\n",
    "print(\"Manual delegation:\")\n",
    "print(list(combined_manual()))\n",
    "\n",
    "print(\"\\nUsing yield from:\")\n",
    "print(list(combined_yield_from()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening Nested Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested_list):\n",
    "    \"\"\"\n",
    "    Recursively flatten a nested list.\n",
    "    \n",
    "    Uses yield from for elegant recursion.\n",
    "    \"\"\"\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            # Recursively flatten sublists\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item\n",
    "\n",
    "nested = [1, [2, 3, [4, 5]], 6, [7, [8, 9]]]\n",
    "print(f\"Nested: {nested}\")\n",
    "print(f\"Flattened: {list(flatten(nested))}\")\n",
    "\n",
    "# More complex example\n",
    "complex_nested = [\n",
    "    1,\n",
    "    [2, 3],\n",
    "    [[4, 5], [6]],\n",
    "    [[[7]], 8],\n",
    "    9\n",
    "]\n",
    "print(f\"\\nComplex nested: {complex_nested}\")\n",
    "print(f\"Flattened: {list(flatten(complex_nested))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Real-World Applications\n",
    "\n",
    "### Example 1: Batch Processing for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size):\n",
    "    \"\"\"\n",
    "    Generate batches for training neural networks.\n",
    "    \n",
    "    Memory-efficient: doesn't load all batches at once.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]\n",
    "\n",
    "# Simulate training data\n",
    "training_data = list(range(1, 101))  # 100 samples\n",
    "batch_size = 10\n",
    "\n",
    "print(f\"Training on {len(training_data)} samples in batches of {batch_size}\\n\")\n",
    "\n",
    "for epoch in range(1, 3):  # 2 epochs\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    for batch_num, batch in enumerate(batch_generator(training_data, batch_size), 1):\n",
    "        # Simulate training\n",
    "        avg = sum(batch) / len(batch)\n",
    "        print(f\"  Batch {batch_num}: size={len(batch)}, avg={avg:.1f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: API Pagination Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paginated_api(max_pages=5):\n",
    "    \"\"\"\n",
    "    Simulate fetching paginated API results.\n",
    "    \n",
    "    In real code, this would make HTTP requests.\n",
    "    Generator allows processing results as they arrive.\n",
    "    \"\"\"\n",
    "    page = 1\n",
    "    while page <= max_pages:\n",
    "        # Simulate API response\n",
    "        results = [\n",
    "            {\"id\": (page - 1) * 10 + i, \"value\": f\"Item {(page - 1) * 10 + i}\"}\n",
    "            for i in range(1, 11)\n",
    "        ]\n",
    "        \n",
    "        print(f\"  üì• Fetched page {page}\")\n",
    "        \n",
    "        # Yield each result\n",
    "        for result in results:\n",
    "            yield result\n",
    "        \n",
    "        page += 1\n",
    "        \n",
    "        # Check if there are more pages (in real code, check API response)\n",
    "        if page > max_pages:\n",
    "            print(f\"  ‚úÖ No more pages\\n\")\n",
    "            break\n",
    "\n",
    "print(\"Fetching API results:\\n\")\n",
    "for i, item in enumerate(fetch_paginated_api(max_pages=3), 1):\n",
    "    if i <= 5 or i > 25:  # Show first and last few\n",
    "        print(f\"  Item {i}: {item}\")\n",
    "    elif i == 6:\n",
    "        print(f\"  ... (processing items 6-25) ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Moving Average Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    \"\"\"\n",
    "    Calculate moving average over a sliding window.\n",
    "    \n",
    "    Memory-efficient for large datasets.\n",
    "    \"\"\"\n",
    "    window = deque(maxlen=window_size)\n",
    "    \n",
    "    for value in data:\n",
    "        window.append(value)\n",
    "        if len(window) == window_size:\n",
    "            yield sum(window) / window_size\n",
    "\n",
    "# Stock prices simulation\n",
    "prices = [100, 102, 98, 105, 110, 108, 112, 115, 111, 114]\n",
    "window = 3\n",
    "\n",
    "print(f\"Stock prices: {prices}\")\n",
    "print(f\"\\nMoving average (window={window}):\")\n",
    "\n",
    "for i, avg in enumerate(moving_average(prices, window), window):\n",
    "    print(f\"  Day {i}: ${avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Performance Comparison\n",
    "\n",
    "### Benchmark: List vs Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def benchmark_list_vs_generator():\n",
    "    \"\"\"Compare performance of list vs generator.\"\"\"\n",
    "    n = 1000000\n",
    "    \n",
    "    # List approach\n",
    "    start = time.time()\n",
    "    list_result = [x**2 for x in range(n)]\n",
    "    first_10_list = list_result[:10]\n",
    "    list_time = time.time() - start\n",
    "    list_memory = sys.getsizeof(list_result)\n",
    "    \n",
    "    # Generator approach\n",
    "    start = time.time()\n",
    "    gen_result = (x**2 for x in range(n))\n",
    "    first_10_gen = [next(gen_result) for _ in range(10)]\n",
    "    gen_time = time.time() - start\n",
    "    gen_memory = sys.getsizeof(gen_result)\n",
    "    \n",
    "    print(f\"Computing first 10 squares from {n:,} numbers:\\n\")\n",
    "    \n",
    "    print(\"List Comprehension:\")\n",
    "    print(f\"  Time: {list_time*1000:.2f} ms\")\n",
    "    print(f\"  Memory: {list_memory:,} bytes ({list_memory/1024/1024:.2f} MB)\")\n",
    "    print(f\"  Result: {first_10_list}\")\n",
    "    \n",
    "    print(\"\\nGenerator Expression:\")\n",
    "    print(f\"  Time: {gen_time*1000:.4f} ms\")\n",
    "    print(f\"  Memory: {gen_memory:,} bytes\")\n",
    "    print(f\"  Result: {first_10_gen}\")\n",
    "    \n",
    "    print(\"\\nüìä Comparison:\")\n",
    "    print(f\"  Speed: Generator is {list_time/gen_time:.0f}x faster\")\n",
    "    print(f\"  Memory: Generator uses {list_memory/gen_memory:.0f}x less memory\")\n",
    "\n",
    "benchmark_list_vs_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Custom Range Iterator\n",
    "\n",
    "Implement a custom `MyRange` class that mimics Python's `range()` behavior using the iterator protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class MyRange:\n",
    "    \"\"\"\n",
    "    Custom range implementation.\n",
    "    \n",
    "    Should support:\n",
    "    - MyRange(stop)\n",
    "    - MyRange(start, stop)\n",
    "    - MyRange(start, stop, step)\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        # TODO: Implement __init__\n",
    "        pass\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # TODO: Return iterator\n",
    "        pass\n",
    "    \n",
    "    def __next__(self):\n",
    "        # TODO: Return next value or raise StopIteration\n",
    "        pass\n",
    "\n",
    "# Test your implementation\n",
    "# print(\"MyRange(5):\", list(MyRange(5)))\n",
    "# print(\"MyRange(2, 8):\", list(MyRange(2, 8)))\n",
    "# print(\"MyRange(0, 10, 2):\", list(MyRange(0, 10, 2)))\n",
    "# print(\"MyRange(10, 0, -1):\", list(MyRange(10, 0, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Generator Pipeline for Data Processing\n",
    "\n",
    "Build the generator pipeline from the original exercise:\n",
    "1. Generate random numbers between 1 and 100\n",
    "2. Filter numbers divisible by both 3 and 5 (divisible by 15)\n",
    "3. Transform each number by multiplying by 2\n",
    "4. Stop after finding 10 numbers that meet the criteria\n",
    "\n",
    "Compare memory usage to a list-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# TODO: Implement generator pipeline\n",
    "\n",
    "def generate_random_numbers():\n",
    "    \"\"\"Generate infinite stream of random numbers between 1 and 100.\"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "def filter_divisible_by_15(numbers):\n",
    "    \"\"\"Filter numbers divisible by 15.\"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "def multiply_by_2(numbers):\n",
    "    \"\"\"Multiply each number by 2.\"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "def take_n(iterable, n):\n",
    "    \"\"\"Take first n items from iterable.\"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "# Build pipeline\n",
    "# pipeline = ...\n",
    "# result = list(pipeline)\n",
    "# print(f\"Result: {result}\")\n",
    "\n",
    "# Compare with list-based approach\n",
    "# TODO: Implement list-based version and compare memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: File Processing with Generators\n",
    "\n",
    "Create a generator function that:\n",
    "1. Reads a CSV-like string (simulate file reading)\n",
    "2. Parses each line into a dictionary\n",
    "3. Filters rows where a specific column meets a condition\n",
    "4. Yields the processed records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Sample CSV data\n",
    "csv_data = \"\"\"name,age,city,salary\n",
    "Alice,30,NYC,80000\n",
    "Bob,25,LA,65000\n",
    "Charlie,35,NYC,95000\n",
    "David,28,SF,75000\n",
    "Eve,32,NYC,88000\n",
    "Frank,29,LA,70000\"\"\"\n",
    "\n",
    "def parse_csv_lines(csv_string):\n",
    "    \"\"\"\n",
    "    Generator that parses CSV string into dictionaries.\n",
    "    \n",
    "    Yields one dictionary per row.\n",
    "    \"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "def filter_records(records, column, condition):\n",
    "    \"\"\"\n",
    "    Filter records based on condition.\n",
    "    \n",
    "    Args:\n",
    "        records: Generator of dictionaries\n",
    "        column: Column name to check\n",
    "        condition: Function that returns True/False\n",
    "    \"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "# Test your implementation\n",
    "# records = parse_csv_lines(csv_data)\n",
    "# high_earners = filter_records(records, 'salary', lambda x: int(x) > 75000)\n",
    "# for record in high_earners:\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Coroutine-Based Logger\n",
    "\n",
    "Create a coroutine that receives log messages via `send()` and:\n",
    "- Categorizes them by level (INFO, WARNING, ERROR)\n",
    "- Maintains counts for each level\n",
    "- Returns summary statistics when receiving `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def log_analyzer():\n",
    "    \"\"\"\n",
    "    Coroutine that analyzes log messages.\n",
    "    \n",
    "    Send log messages like: \"ERROR: Connection failed\"\n",
    "    Send None to get summary statistics.\n",
    "    \"\"\"\n",
    "    pass  # TODO\n",
    "\n",
    "# Test your implementation\n",
    "# logger = log_analyzer()\n",
    "# next(logger)  # Prime the coroutine\n",
    "\n",
    "# logger.send(\"INFO: Application started\")\n",
    "# logger.send(\"ERROR: Connection failed\")\n",
    "# logger.send(\"WARNING: High memory usage\")\n",
    "# logger.send(\"ERROR: Timeout occurred\")\n",
    "# logger.send(\"INFO: Request completed\")\n",
    "\n",
    "# summary = logger.send(None)\n",
    "# print(f\"Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pro Tips\n",
    "\n",
    "### üéØ Best Practices\n",
    "\n",
    "1. **Use generators for large datasets**: When data doesn't fit in memory\n",
    "2. **Prefer generator expressions**: More concise than generator functions for simple transformations\n",
    "3. **Prime coroutines**: Always call `next()` or `send(None)` before using `send()`\n",
    "4. **Be careful with infinite generators**: Always use limiting mechanisms (take_n, islice, break)\n",
    "5. **Use `yield from` for delegation**: Cleaner than manual for-loop delegation\n",
    "6. **Consider itertools**: Built-in module with powerful generator utilities\n",
    "7. **Document generator state**: Make clear if generator is single-use or reusable\n",
    "8. **Use generators for pipelines**: Chain operations for readable, efficient code\n",
    "\n",
    "### ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "1. **Forgetting generators are single-use**: Can't iterate twice without recreating\n",
    "2. **Not priming coroutines**: Must call `next()` before `send()`\n",
    "3. **Converting to list unnecessarily**: Defeats the purpose of lazy evaluation\n",
    "4. **Infinite generators without limits**: Can cause infinite loops\n",
    "5. **Ignoring StopIteration**: Should be handled in manual iteration\n",
    "6. **Mixing iteration protocols**: Don't mix `__iter__`/`__next__` with `yield` in same class\n",
    "7. **Not using `yield from`**: Manual delegation is more error-prone\n",
    "8. **Forgetting cleanup**: Use try/finally or context managers for resource cleanup\n",
    "\n",
    "### üîç When to Use What\n",
    "\n",
    "**Use Lists When**:\n",
    "- Data fits comfortably in memory\n",
    "- Need random access or indexing\n",
    "- Need to iterate multiple times\n",
    "- Want to modify elements in-place\n",
    "\n",
    "**Use Generators When**:\n",
    "- Data is very large or infinite\n",
    "- Only need to iterate once\n",
    "- Processing data in a pipeline\n",
    "- Want to minimize memory usage\n",
    "- Implementing iteration protocol\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Iterators** implement `__iter__()` and `__next__()` for custom iteration logic\n",
    "2. **Generators** provide elegant iterator creation using `yield` keyword\n",
    "3. **Lazy evaluation** means values are computed on-demand, saving memory\n",
    "4. **Generator expressions** offer memory-efficient alternative to list comprehensions\n",
    "5. **Pipelines** chain generators for readable, efficient data processing\n",
    "6. **Infinite sequences** are possible with generators (use carefully)\n",
    "7. **Coroutines** use `send()`, `throw()`, and `close()` for bidirectional communication\n",
    "8. **`yield from`** simplifies generator delegation and subgenerator handling\n",
    "9. **Performance**: Generators often faster and always more memory-efficient for large data\n",
    "10. **Real-world**: Essential for big data, streaming, ETL, ML batching, and API handling\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Explore itertools**: Study `itertools` module (chain, product, permutations, etc.)\n",
    "2. **Async generators**: Learn about `async def` and `async for` for asynchronous iteration\n",
    "3. **Context managers**: Combine generators with context managers using `contextlib.contextmanager`\n",
    "4. **Data streaming**: Build real-time data processing pipelines\n",
    "5. **Performance profiling**: Use `timeit` and `memory_profiler` to measure improvements\n",
    "6. **Practice with large datasets**: Process real CSV files, logs, or API data\n",
    "\n",
    "**Resources**:\n",
    "- [PEP 255 - Simple Generators](https://www.python.org/dev/peps/pep-0255/)\n",
    "- [PEP 342 - Coroutines via Enhanced Generators](https://www.python.org/dev/peps/pep-0342/)\n",
    "- [PEP 380 - Syntax for Delegating to a Subgenerator](https://www.python.org/dev/peps/pep-0380/)\n",
    "- [itertools documentation](https://docs.python.org/3/library/itertools.html)\n",
    "\n",
    "---\n",
    "\n",
    "*Continue to the next lesson on **Algorithms and Complexity** to apply these concepts to algorithm design!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
