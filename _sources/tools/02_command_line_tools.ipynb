{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Tools\n",
    "\n",
    "## The Power of Unix Tools\n",
    "\n",
    "**Real-world analogy:** Think of command-line tools as a Swiss Army knife for working with files and data. Each tool does one thing extremely well, and when combined together, they become incredibly powerful.\n",
    "\n",
    "Modern developers spend significant time working with text files: code, logs, configuration files, data exports. Mastering command-line tools makes you 10x more efficient at these tasks.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Essential text processing tools (grep, sed, awk)\n",
    "- File finding and manipulation\n",
    "- Data transformation and analysis\n",
    "- Pipeline composition\n",
    "- Real-world automation workflows\n",
    "\n",
    "**Time investment:** 60-90 minutes  \n",
    "**Difficulty:** Intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Finding Files: `find`\n",
    "\n",
    "The `find` command searches for files and directories based on various criteria.\n",
    "\n",
    "### Basic Syntax\n",
    "```bash\n",
    "find [path] [options] [expression]\n",
    "```\n",
    "\n",
    "### Common Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test files for examples\n",
    "!mkdir -p test_files/subdir\n",
    "!touch test_files/file1.txt test_files/file2.py test_files/file3.js\n",
    "!touch test_files/subdir/nested.txt test_files/README.md\n",
    "\n",
    "# Find all files in current directory and subdirectories\n",
    "!find test_files -type f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files by name pattern\n",
    "!find test_files -name \"*.txt\"\n",
    "\n",
    "# Case-insensitive name search\n",
    "!find test_files -iname \"readme*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files modified in last 7 days\n",
    "!find test_files -type f -mtime -7\n",
    "\n",
    "# Find files larger than 1MB\n",
    "!find test_files -type f -size +1M\n",
    "\n",
    "# Find and execute command on each file\n",
    "!find test_files -name \"*.txt\" -exec wc -l {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Pro Tips for `find`\n",
    "\n",
    "```bash\n",
    "# Delete all .pyc files (Python cache)\n",
    "find . -name \"*.pyc\" -delete\n",
    "\n",
    "# Find empty directories\n",
    "find . -type d -empty\n",
    "\n",
    "# Find files with specific permissions\n",
    "find . -type f -perm 644\n",
    "\n",
    "# Find and count files by extension\n",
    "find . -type f -name \"*.py\" | wc -l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Searching Text: `grep`\n",
    "\n",
    "`grep` (Global Regular Expression Print) searches for patterns in text files.\n",
    "\n",
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample file\n",
    "sample_text = \"\"\"Python is awesome\n",
    "python is easy to learn\n",
    "Java is verbose\n",
    "JavaScript is everywhere\n",
    "Error: File not found\n",
    "Warning: Deprecated function\n",
    "INFO: Server started on port 8080\n",
    "\"\"\"\n",
    "\n",
    "with open('test_files/sample.log', 'w') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "# Basic search\n",
    "!grep \"Python\" test_files/sample.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case-insensitive search\n",
    "!grep -i \"python\" test_files/sample.log\n",
    "\n",
    "# Show line numbers\n",
    "!grep -n \"is\" test_files/sample.log\n",
    "\n",
    "# Count matches\n",
    "!grep -c \"is\" test_files/sample.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert match (lines NOT containing pattern)\n",
    "!grep -v \"Python\" test_files/sample.log\n",
    "\n",
    "# Search recursively in directories\n",
    "!grep -r \"Python\" test_files/\n",
    "\n",
    "# Show context (lines before and after)\n",
    "!grep -A 1 -B 1 \"Error\" test_files/sample.log  # 1 line after, 1 before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions with grep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match lines starting with specific text\n",
    "!grep \"^Error\" test_files/sample.log\n",
    "\n",
    "# Match lines ending with specific text\n",
    "!grep \"8080$\" test_files/sample.log\n",
    "\n",
    "# Match either pattern (OR)\n",
    "!grep -E \"Error|Warning\" test_files/sample.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Real-World grep Examples\n",
    "\n",
    "```bash\n",
    "# Find all TODO comments in Python files\n",
    "grep -rn \"TODO\" --include=\"*.py\" .\n",
    "\n",
    "# Find IP addresses in logs\n",
    "grep -E \"[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\" access.log\n",
    "\n",
    "# Find error messages (case insensitive)\n",
    "grep -i \"error\\|exception\\|failed\" app.log\n",
    "\n",
    "# Find functions in Python code\n",
    "grep -n \"^def \" *.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Stream Editing: `sed`\n",
    "\n",
    "`sed` (Stream EDitor) performs text transformations on input streams.\n",
    "\n",
    "### Basic Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test file\n",
    "!echo -e \"Hello World\\nHello Universe\\nHello Everyone\" > test_files/greetings.txt\n",
    "\n",
    "# Replace first occurrence on each line\n",
    "!sed 's/Hello/Hi/' test_files/greetings.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ALL occurrences (global flag)\n",
    "!echo \"foo bar foo baz foo\" | sed 's/foo/FOO/g'\n",
    "\n",
    "# Case-insensitive replacement\n",
    "!echo \"Hello hello HELLO\" | sed 's/hello/hi/gI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete lines matching pattern\n",
    "!sed '/World/d' test_files/greetings.txt\n",
    "\n",
    "# Delete empty lines\n",
    "!echo -e \"line1\\n\\nline2\\n\\nline3\" | sed '/^$/d'\n",
    "\n",
    "# Print only lines matching pattern\n",
    "!sed -n '/Universe/p' test_files/greetings.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced sed Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-place editing (modify file)\n",
    "!cp test_files/greetings.txt test_files/greetings_backup.txt\n",
    "!sed -i 's/Hello/Greetings/' test_files/greetings_backup.txt\n",
    "!cat test_files/greetings_backup.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple commands\n",
    "!echo \"foo bar\" | sed 's/foo/FOO/; s/bar/BAR/'\n",
    "\n",
    "# Line number ranges\n",
    "!sed -n '1,2p' test_files/greetings.txt  # Print lines 1-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Real-World sed Examples\n",
    "\n",
    "```bash\n",
    "# Remove trailing whitespace\n",
    "sed 's/[[:space:]]*$//' file.txt\n",
    "\n",
    "# Add line numbers\n",
    "sed = file.txt | sed 'N;s/\\n/\\t/'\n",
    "\n",
    "# Comment out lines containing pattern\n",
    "sed '/DEBUG/s/^/# /' config.py\n",
    "\n",
    "# Replace date format: 2024-01-15 â†’ 01/15/2024\n",
    "sed 's/\\([0-9]\\{4\\}\\)-\\([0-9]\\{2\\}\\)-\\([0-9]\\{2\\}\\)/\\2\\/\\3\\/\\1/'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Pattern Scanning: `awk`\n",
    "\n",
    "`awk` is a powerful text processing language, perfect for structured data.\n",
    "\n",
    "### Basic awk Structure\n",
    "\n",
    "```bash\n",
    "awk 'pattern { action }' file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "data = \"\"\"Alice 25 Engineer\n",
    "Bob 30 Designer\n",
    "Charlie 35 Manager\n",
    "Diana 28 Developer\n",
    "\"\"\"\n",
    "\n",
    "with open('test_files/employees.txt', 'w') as f:\n",
    "    f.write(data)\n",
    "\n",
    "# Print entire file\n",
    "!awk '{print}' test_files/employees.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print specific columns (fields)\n",
    "!awk '{print $1, $3}' test_files/employees.txt  # Name and job title\n",
    "\n",
    "# Print with custom separator\n",
    "!awk '{print $1 \" is a \" $3}' test_files/employees.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern matching\n",
    "!awk '/Developer/ {print}' test_files/employees.txt\n",
    "\n",
    "# Conditional logic\n",
    "!awk '$2 > 28 {print $1, \"is over 28\"}' test_files/employees.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NR = Record Number (line number)\n",
    "!awk '{print NR, $0}' test_files/employees.txt\n",
    "\n",
    "# NF = Number of Fields\n",
    "!awk '{print $1, \"has\", NF, \"fields\"}' test_files/employees.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN and END blocks\n",
    "!awk 'BEGIN {print \"Employee Report\"} {print $1} END {print \"Total:\", NR}' test_files/employees.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced awk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV data\n",
    "csv_data = \"\"\"name,age,salary\n",
    "Alice,25,75000\n",
    "Bob,30,85000\n",
    "Charlie,35,95000\n",
    "\"\"\"\n",
    "\n",
    "with open('test_files/salaries.csv', 'w') as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "# Process CSV (custom field separator)\n",
    "!awk -F',' 'NR>1 {print $1, \"earns\", $3}' test_files/salaries.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum\n",
    "!awk -F',' 'NR>1 {sum+=$3} END {print \"Total salary:\", sum}' test_files/salaries.csv\n",
    "\n",
    "# Calculate average\n",
    "!awk -F',' 'NR>1 {sum+=$3; count++} END {print \"Average:\", sum/count}' test_files/salaries.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Real-World awk Examples\n",
    "\n",
    "```bash\n",
    "# Print unique values from column\n",
    "awk '{print $3}' employees.txt | sort | uniq\n",
    "\n",
    "# Format output as table\n",
    "awk '{printf \"%-10s %-5s %-15s\\n\", $1, $2, $3}' employees.txt\n",
    "\n",
    "# Parse Apache access logs\n",
    "awk '{print $1}' access.log | sort | uniq -c | sort -rn | head -10\n",
    "\n",
    "# Extract JSON-like values\n",
    "awk -F'\"' '{print $4}' data.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Text Manipulation: `cut`, `paste`, `sort`, `uniq`\n",
    "\n",
    "### `cut` - Extract Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific characters\n",
    "!echo \"Hello World\" | cut -c 1-5\n",
    "\n",
    "# Extract fields (default delimiter: tab)\n",
    "!echo -e \"A\\tB\\tC\\tD\" | cut -f 1,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom delimiter\n",
    "!echo \"Alice,25,Engineer\" | cut -d',' -f1,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sort` - Sort Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unsorted data\n",
    "!echo -e \"banana\\napple\\ncherry\\napricot\" > test_files/fruits.txt\n",
    "\n",
    "# Alphabetical sort\n",
    "!sort test_files/fruits.txt\n",
    "\n",
    "# Reverse sort\n",
    "!sort -r test_files/fruits.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric sort\n",
    "!echo -e \"10\\n2\\n100\\n20\" | sort -n\n",
    "\n",
    "# Sort by specific column\n",
    "!sort -k2 -n test_files/employees.txt  # Sort by age (column 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `uniq` - Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with duplicates\n",
    "!echo -e \"apple\\napple\\nbanana\\napple\\ncherry\\nbanana\" > test_files/duplicates.txt\n",
    "\n",
    "# Remove adjacent duplicates (must sort first!)\n",
    "!sort test_files/duplicates.txt | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "!sort test_files/duplicates.txt | uniq -c\n",
    "\n",
    "# Show only duplicates\n",
    "!sort test_files/duplicates.txt | uniq -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Pipelines: Combining Tools\n",
    "\n",
    "The true power comes from combining tools with pipes (`|`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log file\n",
    "log_data = \"\"\"2024-01-15 ERROR Database connection failed\n",
    "2024-01-15 INFO Server started\n",
    "2024-01-15 ERROR File not found: config.json\n",
    "2024-01-15 WARN Deprecated function used\n",
    "2024-01-15 ERROR Connection timeout\n",
    "2024-01-15 INFO Request processed\n",
    "\"\"\"\n",
    "\n",
    "with open('test_files/app.log', 'w') as f:\n",
    "    f.write(log_data)\n",
    "\n",
    "# Find and count errors\n",
    "!grep \"ERROR\" test_files/app.log | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique error messages\n",
    "!grep \"ERROR\" test_files/app.log | cut -d' ' -f4- | sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex pipeline: Find most common log levels\n",
    "!cat test_files/app.log | awk '{print $3}' | sort | uniq -c | sort -rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Pipeline Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which Python files have the most lines\n",
    "!find . -name \"*.py\" -type f -exec wc -l {} \\; 2>/dev/null | sort -rn | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Pro Pipeline Patterns\n",
    "\n",
    "```bash\n",
    "# Find largest files in directory\n",
    "du -ah . | sort -rh | head -20\n",
    "\n",
    "# Find most frequently used commands in bash history\n",
    "history | awk '{print $2}' | sort | uniq -c | sort -rn | head -10\n",
    "\n",
    "# Count TODO comments per file\n",
    "find . -name \"*.py\" -exec grep -c \"TODO\" {} \\; -print | paste - -\n",
    "\n",
    "# Extract email addresses from files\n",
    "grep -roh \"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\" . | sort | uniq\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Data Processing: `jq` and Modern Tools\n",
    "\n",
    "### `jq` - JSON Processor\n",
    "\n",
    "`jq` is like `sed` for JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON test data\n",
    "import json\n",
    "\n",
    "data = {\n",
    "    \"users\": [\n",
    "        {\"name\": \"Alice\", \"age\": 25, \"role\": \"Engineer\"},\n",
    "        {\"name\": \"Bob\", \"age\": 30, \"role\": \"Designer\"},\n",
    "        {\"name\": \"Charlie\", \"age\": 35, \"role\": \"Manager\"}\n",
    "    ],\n",
    "    \"company\": \"Tech Corp\"\n",
    "}\n",
    "\n",
    "with open('test_files/data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "!cat test_files/data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print JSON\n",
    "!jq '.' test_files/data.json 2>/dev/null || echo \"jq not installed (optional tool)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific field\n",
    "!jq '.company' test_files/data.json 2>/dev/null || echo \"jq not installed\"\n",
    "\n",
    "# Extract array elements\n",
    "!jq '.users[0].name' test_files/data.json 2>/dev/null || echo \"jq not installed\"\n",
    "\n",
    "# Map over array\n",
    "!jq '.users[] | .name' test_files/data.json 2>/dev/null || echo \"jq not installed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Alternative for JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python for JSON processing (always available)\n",
    "import json\n",
    "\n",
    "with open('test_files/data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract names\n",
    "names = [user['name'] for user in data['users']]\n",
    "print(\"Names:\", names)\n",
    "\n",
    "# Filter users over 25\n",
    "senior = [u for u in data['users'] if u['age'] > 25]\n",
    "print(\"\\nSenior users:\", senior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Text Statistics: `wc`, `head`, `tail`\n",
    "\n",
    "### `wc` - Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count lines, words, characters\n",
    "!wc test_files/sample.log\n",
    "\n",
    "# Count only lines\n",
    "!wc -l test_files/sample.log\n",
    "\n",
    "# Count only words\n",
    "!wc -w test_files/sample.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `head` and `tail` - First/Last Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 3 lines\n",
    "!head -n 3 test_files/sample.log\n",
    "\n",
    "# Last 3 lines\n",
    "!tail -n 3 test_files/sample.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow file (live updates) - useful for logs\n",
    "# tail -f /var/log/syslog  # Would continuously show new lines\n",
    "\n",
    "# Skip first N lines\n",
    "!tail -n +2 test_files/salaries.csv  # Skip header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Process Substitution and Advanced Techniques\n",
    "\n",
    "### Compare Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two files\n",
    "!echo -e \"apple\\nbanana\\ncherry\" > test_files/list1.txt\n",
    "!echo -e \"banana\\ncherry\\ndate\" > test_files/list2.txt\n",
    "\n",
    "# Show lines unique to first file\n",
    "!comm -23 <(sort test_files/list1.txt) <(sort test_files/list2.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xargs` - Build Command Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and process files\n",
    "!find test_files -name \"*.txt\" | head -3 | xargs wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "!echo -e \"test1\\ntest2\\ntest3\" | xargs -I {} echo \"Processing: {}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Modern Alternatives\n",
    "\n",
    "### Fast Modern Tools\n",
    "\n",
    "| Classic | Modern Alternative | Why Better |\n",
    "|---------|-------------------|------------|\n",
    "| `grep` | `ripgrep (rg)` | 10-100x faster, respects .gitignore |\n",
    "| `find` | `fd` | Simpler syntax, faster |\n",
    "| `cat` | `bat` | Syntax highlighting, line numbers |\n",
    "| `ls` | `exa` | Better formatting, git aware |\n",
    "| `du` | `dust` | Visual tree, faster |\n",
    "\n",
    "### Example: `ripgrep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripgrep syntax (if installed)\n",
    "# Much faster than grep, respects .gitignore automatically\n",
    "\n",
    "# rg \"TODO\"                    # Search current directory\n",
    "# rg \"TODO\" -t py             # Only Python files\n",
    "# rg \"TODO\" -g '!tests'       # Exclude tests directory\n",
    "# rg \"function\" -A 3          # Show 3 lines after match\n",
    "\n",
    "print(\"Install ripgrep: cargo install ripgrep\")\n",
    "print(\"Or: apt install ripgrep (Ubuntu)\")\n",
    "print(\"Or: brew install ripgrep (macOS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Hands-On Exercises\n",
    "\n",
    "### Exercise 1: Log Analysis\n",
    "\n",
    "You have a web server log file. Extract useful statistics:\n",
    "- Count total requests\n",
    "- Find most common status codes\n",
    "- List top 5 most accessed URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample access log\n",
    "access_log = \"\"\"192.168.1.1 - - [15/Jan/2024:10:15:30] \"GET /home 200\n",
    "192.168.1.2 - - [15/Jan/2024:10:15:31] \"GET /about 200\n",
    "192.168.1.1 - - [15/Jan/2024:10:15:32] \"GET /home 200\n",
    "192.168.1.3 - - [15/Jan/2024:10:15:33] \"GET /contact 404\n",
    "192.168.1.2 - - [15/Jan/2024:10:15:34] \"POST /api/login 200\n",
    "192.168.1.4 - - [15/Jan/2024:10:15:35] \"GET /admin 403\n",
    "192.168.1.1 - - [15/Jan/2024:10:15:36] \"GET /home 200\n",
    "\"\"\"\n",
    "\n",
    "with open('test_files/access.log', 'w') as f:\n",
    "    f.write(access_log)\n",
    "\n",
    "# TODO: Your solution here\n",
    "# Count total requests:\n",
    "\n",
    "# Most common status codes:\n",
    "\n",
    "# Top URLs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: CSV Processing\n",
    "\n",
    "Process a sales CSV file to find:\n",
    "- Total sales amount\n",
    "- Average sale price\n",
    "- Top 3 products by quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sales data\n",
    "sales_csv = \"\"\"product,quantity,price\n",
    "Laptop,5,1200\n",
    "Mouse,15,25\n",
    "Keyboard,10,75\n",
    "Monitor,8,300\n",
    "Laptop,3,1200\n",
    "Mouse,20,25\n",
    "\"\"\"\n",
    "\n",
    "with open('test_files/sales.csv', 'w') as f:\n",
    "    f.write(sales_csv)\n",
    "\n",
    "# TODO: Your solution here\n",
    "# Total sales:\n",
    "\n",
    "# Average price:\n",
    "\n",
    "# Top products:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Code Analysis\n",
    "\n",
    "Analyze Python source files:\n",
    "- Count total lines of code (excluding comments and blanks)\n",
    "- Find all function definitions\n",
    "- List files with TODO comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Python file\n",
    "py_code = '''# Calculate factorial\n",
    "def factorial(n):\n",
    "    \"\"\"Calculate factorial recursively\"\"\"\n",
    "    # TODO: Add input validation\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * factorial(n-1)\n",
    "\n",
    "def fibonacci(n):\n",
    "    \"\"\"Calculate nth Fibonacci number\"\"\"\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "'''\n",
    "\n",
    "with open('test_files/math_utils.py', 'w') as f:\n",
    "    f.write(py_code)\n",
    "\n",
    "# TODO: Your solution here\n",
    "# Count LOC:\n",
    "\n",
    "# Find functions:\n",
    "\n",
    "# Find TODOs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Data Transformation\n",
    "\n",
    "Transform a space-separated file to CSV format with headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data (space-separated)\n",
    "!echo -e \"Alice 25 Engineer\\nBob 30 Designer\\nCharlie 35 Manager\" > test_files/input.txt\n",
    "\n",
    "# TODO: Convert to CSV with headers: name,age,role\n",
    "# Your solution here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Pipeline Challenge\n",
    "\n",
    "Create a one-liner pipeline to:\n",
    "1. Find all `.txt` files\n",
    "2. Count words in each\n",
    "3. Show only files with more than 10 words\n",
    "4. Sort by word count (descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your one-liner here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ Self-Check Quiz\n",
    "\n",
    "Test your understanding:\n",
    "\n",
    "1. **What's the difference between `grep -E` and regular `grep`?**\n",
    "   - Extended regex support vs basic regex\n",
    "\n",
    "2. **Why must you `sort` before `uniq`?**\n",
    "   - `uniq` only removes *adjacent* duplicates\n",
    "\n",
    "3. **What does `awk '{print $NF}'` do?**\n",
    "   - Prints the last field of each line\n",
    "\n",
    "4. **How to replace text in a file in-place with `sed`?**\n",
    "   - `sed -i 's/old/new/g' file.txt`\n",
    "\n",
    "5. **What's the difference between `>` and `>>`?**\n",
    "   - `>` overwrites, `>>` appends\n",
    "\n",
    "6. **How to search case-insensitively with `grep`?**\n",
    "   - `grep -i pattern file`\n",
    "\n",
    "7. **What does `2>&1` do?**\n",
    "   - Redirects stderr to stdout\n",
    "\n",
    "8. **How to process CSV with `awk`?**\n",
    "   - `awk -F',' '{print $1}' file.csv`\n",
    "\n",
    "9. **What's a pipeline?**\n",
    "   - Chaining commands with `|` to pass output as input\n",
    "\n",
    "10. **How to follow a log file in real-time?**\n",
    "    - `tail -f logfile`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ Key Takeaways\n",
    "\n",
    "1. **Unix Philosophy**: Do one thing well, compose tools\n",
    "2. **`find`**: Search for files by name, type, size, time\n",
    "3. **`grep`**: Search text patterns, supports regex\n",
    "4. **`sed`**: Stream editor for text transformation\n",
    "5. **`awk`**: Pattern scanning and processing language\n",
    "6. **Pipelines**: Chain tools with `|` for powerful workflows\n",
    "7. **Modern tools**: `ripgrep`, `fd`, `bat` are faster alternatives\n",
    "8. **Practice**: Master these tools through daily use\n",
    "\n",
    "**Remember:** These tools are 40+ years old and still dominant because they're incredibly powerful and composable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "1. **Practice daily**: Use these tools in your workflow\n",
    "2. **Read man pages**: `man grep`, `man awk` for deep dives\n",
    "3. **Install modern tools**: Try `ripgrep`, `fd`, `bat`\n",
    "4. **Next lesson**: `03_git_essentials.ipynb` - Version control mastery\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Additional Resources\n",
    "\n",
    "- [The Art of Command Line](https://github.com/jlevy/the-art-of-command-line)\n",
    "- [Awk Tutorial](https://www.grymoire.com/Unix/Awk.html)\n",
    "- [Sed Tutorial](https://www.grymoire.com/Unix/Sed.html)\n",
    "- [Ripgrep User Guide](https://github.com/BurntSushi/ripgrep/blob/master/GUIDE.md)\n",
    "- [explainshell.com](https://explainshell.com/) - Explains shell commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup test files\n",
    "!rm -rf test_files/\n",
    "print(\"âœ… Test files cleaned up!\")\n",
    "print(\"\\nðŸŽ‰ Congratulations on completing Command Line Tools!\")\n",
    "print(\"You now have powerful text processing skills.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
